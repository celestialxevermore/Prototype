import matplotlib.pyplot as plt
import numpy as np
import os
from datetime import datetime
import pdb
import torch
import logging



import matplotlib.pyplot as plt
import networkx as nx
import numpy as np
from matplotlib.colors import LinearSegmentedColormap
import os
import networkx as nx
import matplotlib.pyplot as plt
import numpy as np
import torch
logger = logging.getLogger(__name__)
import torch
import matplotlib.pyplot as plt
import networkx as nx
import numpy as np
import os
import logging

logger = logging.getLogger(__name__)

def visualize_cluster_centroids(clustering_info, clustering_dir, epoch, feature_names):
    """
    ê° í´ëŸ¬ìŠ¤í„°ì˜ centroid attention mapì„ íˆíŠ¸ë§µìœ¼ë¡œ ì‹œê°í™”
    í´ëŸ¬ìŠ¤í„°ë³„ í´ë” êµ¬ì¡°ë¡œ ì •ë¦¬
    """
    if clustering_info['cluster_centroids'] is None:
        return
    
    # visualizations í´ë” ìƒì„±
    visualizations_dir = os.path.join(clustering_dir, 'visualizations')
    os.makedirs(visualizations_dir, exist_ok=True)
        
    for cluster_id, centroid in enumerate(clustering_info['cluster_centroids']):
        # í´ëŸ¬ìŠ¤í„°ë³„ í´ë” ìƒì„± (visualizations í•˜ìœ„ì—)
        cluster_folder = os.path.join(visualizations_dir, f'cluster_{cluster_id}')
        os.makedirs(cluster_folder, exist_ok=True)
        
        fig, ax = plt.subplots(1, 1, figsize=(10, 8))
        
        centroid_np = centroid.detach().cpu().numpy()
        all_node_names = ["CLS"] + feature_names
        
        im = ax.imshow(centroid_np, cmap='viridis', interpolation='nearest')
        ax.set_title(f'Cluster {cluster_id} Centroid - Epoch {epoch}', fontsize=14)
        plt.colorbar(im, ax=ax)
        
        # ì¶• ë¼ë²¨ ì„¤ì •
        ax.set_xticks(np.arange(len(all_node_names)))
        ax.set_yticks(np.arange(len(all_node_names)))
        ax.set_xticklabels(all_node_names, rotation=90, fontsize=8)
        ax.set_yticklabels(all_node_names, fontsize=8)
        
        # ê°’ í‘œì‹œ
        for i in range(len(all_node_names)):
            for j in range(len(all_node_names)):
                ax.text(j, i, f"{centroid_np[i,j]:.2f}", 
                       ha="center", va="center", 
                       color="white" if centroid_np[i,j] > 0.5 else "black", 
                       fontsize=6)
        
        # visualizations í´ë”ì˜ í´ëŸ¬ìŠ¤í„°ë³„ í´ë”ì— ì €ì¥
        centroid_viz_path = os.path.join(cluster_folder, f'epoch_{epoch}.png')
        fig.savefig(centroid_viz_path, dpi=300, bbox_inches='tight')
        plt.close(fig)
        logger.info(f"Saved centroid visualization for cluster {cluster_id}: {centroid_viz_path}")



def visualize_model_structure(model, data_loader, device, args, mode, experiment_id, epoch, max_samples=10):
    """
    ëª¨ë¸ì˜ ë‚´ë¶€ êµ¬ì¡°(ì–´í…ì…˜, ê·¸ë˜í”„ êµ¬ì¡° ë“±)ë¥¼ ì‹œê°í™”í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        model: ì‹œê°í™”í•  ëª¨ë¸
        data_loader: ì‹œê°í™”ì— ì‚¬ìš©í•  ë°ì´í„° ë¡œë”
        device: ê³„ì‚°ì— ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤
        args: ì‹¤í—˜ ì„¤ì • ì¸ì (args.viz_heatmap, args.viz_graph í”Œë˜ê·¸ ì‚¬ìš©)
        mode: 'train' ë˜ëŠ” 'val' ëª¨ë“œ
        experiment_id: í˜„ì¬ ì‹¤í—˜ ID
        epoch: í˜„ì¬ ì—í¬í¬
        max_samples: ì‹œê°í™”í•  ìµœëŒ€ ìƒ˜í”Œ ìˆ˜
    """

    
    base_viz_dir = os.path.join(f"/storage/personal/eungyeop/experiments/visualization/{args.llm_model}/{args.source_dataset_name}/{mode}/{experiment_id}")
    os.makedirs(base_viz_dir, exist_ok=True)

    # ìƒ˜í”Œë³„ ë””ë ‰í† ë¦¬ ë¯¸ë¦¬ ìƒì„±
    sample_dirs = []
    for i in range(max_samples):
        # ê° ìƒ˜í”Œ ë””ë ‰í† ë¦¬
        sample_dir = os.path.join(base_viz_dir, f'sample_{i}')
        os.makedirs(sample_dir, exist_ok=True)
        sample_dirs.append(sample_dir)
        
        # ê° ìƒ˜í”Œ ë‚´ì— heatmapê³¼ graph í´ë” ìƒì„±
        heatmap_dir = os.path.join(sample_dir, 'heatmap')
        graph_dir = os.path.join(sample_dir, 'graph')
        os.makedirs(heatmap_dir, exist_ok=True)
        os.makedirs(graph_dir, exist_ok=True)
        
        # ê° í´ë” ë‚´ì— ë ˆì´ì–´ë³„ ì„œë¸Œí´ë” ìƒì„±
        for layer_idx in range(len(model.layers)):
            heatmap_layer_dir = os.path.join(heatmap_dir, f'layer_{layer_idx}')
            graph_layer_dir = os.path.join(graph_dir, f'layer_{layer_idx}')
            os.makedirs(heatmap_layer_dir, exist_ok=True)
            os.makedirs(graph_layer_dir, exist_ok=True)

    with torch.no_grad():
        model.eval()
        
        sample_count = 0
        
        for batch_idx, batch in enumerate(data_loader):
            batch_on_device = {
                k: v.to(device) if isinstance(v, torch.Tensor) else v
                for k, v in batch.items()
            }
            prediction = model.predict(batch_on_device)
            
            # ë°°ì¹˜ í¬ê¸° í™•ì¸
            batch_size = model.layers[0].attn_weights.shape[0]
            
            for sample_idx in range(batch_size):
                # íŠ¹ì„± ì´ë¦„ ì •ë¦¬ (ëª¨ë“  ë ˆì´ì–´ì—ì„œ ê³µí†µìœ¼ë¡œ ì‚¬ìš©)
                feature_names = []
                if 'cat_desc_texts' in batch_on_device:
                    for feature in batch_on_device['cat_desc_texts']:
                        if isinstance(feature, tuple):
                            clean_name = str(feature[0])
                        else:
                            try:
                                clean_name = feature.split("'")[1] if "'" in feature else feature
                                clean_name = clean_name.split(',')[0]
                            except:
                                clean_name = str(feature)
                        feature_names.append(clean_name)

                if 'num_desc_texts' in batch_on_device:
                    for feature in batch_on_device['num_desc_texts']:
                        if isinstance(feature, tuple):
                            clean_name = str(feature[0])
                        else:
                            try:
                                clean_name = feature.split("'")[1] if "'" in feature else feature
                                clean_name = clean_name.split(',')[0]
                            except:
                                clean_name = str(feature)
                        feature_names.append(clean_name)
                        
                # ì¤‘ë³µ ì œê±° (ìˆœì„œ ìœ ì§€)
                seen = set()
                unique_features = []
                for feat in feature_names:
                    if feat not in seen:
                        seen.add(feat)
                        unique_features.append(feat)
                feature_names = unique_features
                
                # 1. íˆíŠ¸ë§µ ì‹œê°í™” (ì›ë˜ ì½”ë“œ ê·¸ëŒ€ë¡œ)
                if args.viz_heatmap:
                    # ì‹œê°í™” ì‹œì ì—ì„œë§Œ í´ëŸ¬ìŠ¤í„°ë§ ë¦¬ì…‹ (ì²« ë²ˆì§¸ ìƒ˜í”Œì—ì„œë§Œ)
                    if sample_count == 0:
                        model.reset_epoch_clustering()
                        
                        # í˜„ì¬ ì—í¬í¬ì˜ ë°ì´í„° ìˆ˜ì§‘ì„ ìœ„í•´ data_loader ìˆœíšŒ
                        model.train()  # attention ìˆ˜ì§‘ìš©
                        with torch.no_grad():
                            for batch in data_loader:
                                batch_on_device = {
                                    k: v.to(device) if isinstance(v, torch.Tensor) else v
                                    for k, v in batch.items()
                                }
                                _ = model.predict(batch_on_device)  # attention maps ìˆ˜ì§‘
                        
                        model.stop_attention_collection()
                        model.eval()
                    
                    # ìˆ˜ì§‘ ì™„ë£Œ í›„ í´ëŸ¬ìŠ¤í„°ë§ ì—…ë°ì´íŠ¸
                    clustering_updated = model.update_attention_clustering()
                    
                    # í´ëŸ¬ìŠ¤í„°ë§ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                    clustering_info = model.get_clustering_info()
                    
                    # 1. ê¸°ì¡´: ê° ë ˆì´ì–´ë³„ ì‹œê°í™” (sample_*/heatmap/layer_*/ì— ì €ì¥)
                    for layer_idx in range(len(model.layers)):
                        fig, axes = plt.subplots(1, 2, figsize=(20, 8))
                        
                        # 1. Attention Map íˆíŠ¸ë§µ 
                        batch_size = model.layers[layer_idx].attn_weights.shape[0]
                        actual_sample_idx = min(sample_idx, batch_size - 1)  # ë°°ì¹˜ í¬ê¸° ì´ˆê³¼ ë°©ì§€
                        attn_weights = model.layers[layer_idx].attn_weights[actual_sample_idx]  # [n_heads, seq, seq]
                        attn_weights_mean = attn_weights.mean(dim=0).cpu().numpy()  # í—¤ë“œë³„ í‰ê· 
                        
                        # CLS í† í° í¬í•¨í•œ feature names
                        all_node_names = ["CLS"] + feature_names 
                        
                        im1 = axes[0].imshow(attn_weights_mean, cmap='viridis', interpolation='nearest')
                        axes[0].set_title(f'Attention Map - Layer {layer_idx}', fontsize=14)
                        fig.colorbar(im1, ax=axes[0])
                        
                        # ì¶• ë¼ë²¨ ì„¤ì •
                        axes[0].set_xticks(np.arange(len(all_node_names)))
                        axes[0].set_yticks(np.arange(len(all_node_names)))
                        axes[0].set_xticklabels(all_node_names, rotation=90, fontsize=8)
                        axes[0].set_yticklabels(all_node_names, fontsize=8)
                        
                        # ê° ì…€ì— ê°’ í‘œì‹œ
                        for i in range(len(all_node_names)):
                            for j in range(len(all_node_names)):
                                axes[0].text(j, i, f"{attn_weights_mean[i,j]:.2f}", 
                                        ha="center", va="center", 
                                        color="white" if attn_weights_mean[i,j] > 0.5 else "black", 
                                        fontsize=7)
                        
                        # 2. ì˜¤ë¥¸ìª½: í•´ë‹¹í•˜ëŠ” í´ëŸ¬ìŠ¤í„° centroid í‘œì‹œ
                        if (layer_idx == len(model.layers) - 1 and  # ë§ˆì§€ë§‰ ë ˆì´ì–´(Layer 2)ì´ê³ 
                            clustering_info['cluster_centroids'] is not None and 
                            len(clustering_info['cluster_assignments']) > 0):
                            
                            # í˜„ì¬ ìƒ˜í”Œì˜ attention mapì´ ì–´ëŠ í´ëŸ¬ìŠ¤í„°ì— ì†í•˜ëŠ”ì§€ ì°¾ê¸°
                            sample_attention = attn_weights_mean  # í˜„ì¬ ìƒ˜í”Œì˜ attention map
                            
                            # ëª¨ë“  centroidì™€ì˜ ê±°ë¦¬ ê³„ì‚°
                            min_distance = float('inf')
                            assigned_cluster = 0
                            
                            for cluster_id, centroid in enumerate(clustering_info['cluster_centroids']):
                                centroid_np = centroid.detach().cpu().numpy()
                                # Frobenius norm ê±°ë¦¬ ê³„ì‚°
                                distance = np.linalg.norm(sample_attention - centroid_np, 'fro')
                                if distance < min_distance:
                                    min_distance = distance
                                    assigned_cluster = cluster_id
                            
                            # í•´ë‹¹ í´ëŸ¬ìŠ¤í„°ì˜ centroid í‘œì‹œ
                            assigned_centroid = clustering_info['cluster_centroids'][assigned_cluster].detach().cpu().numpy()
                            
                            im2 = axes[1].imshow(assigned_centroid, cmap='viridis', interpolation='nearest')
                            axes[1].set_title(f'Closest Cluster Centroid - Cluster {assigned_cluster}\n(Distance: {min_distance:.3f})', fontsize=14)
                            fig.colorbar(im2, ax=axes[1])
                            
                            # ì¶• ë¼ë²¨ ì„¤ì •
                            axes[1].set_xticks(np.arange(len(all_node_names)))
                            axes[1].set_yticks(np.arange(len(all_node_names)))
                            axes[1].set_xticklabels(all_node_names, rotation=90, fontsize=8)
                            axes[1].set_yticklabels(all_node_names, fontsize=8)
                            
                            # ê° ì…€ì— ê°’ í‘œì‹œ
                            for i in range(len(all_node_names)):
                                for j in range(len(all_node_names)):
                                    axes[1].text(j, i, f"{assigned_centroid[i,j]:.2f}", 
                                            ha="center", va="center", 
                                            color="white" if assigned_centroid[i,j] > 0.5 else "black", 
                                            fontsize=7)
                        else:
                            # ë§ˆì§€ë§‰ ë ˆì´ì–´ê°€ ì•„ë‹ˆê±°ë‚˜ í´ëŸ¬ìŠ¤í„°ë§ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ê¸°ì¡´ ë°©ì‹
                            axes[1].text(0.5, 0.5, f'Layer {layer_idx} Attention Pattern\n\nFull clustering results\navailable in clustering/ folder\n\nLayer 2 = Final clustering layer', 
                                    ha='center', va='center', transform=axes[1].transAxes, fontsize=14,
                                    bbox=dict(boxstyle="round,pad=0.5", facecolor="lightcyan", alpha=0.8))
                            axes[1].set_title(f'Layer {layer_idx} - See clustering/ for full results', fontsize=14)
                            axes[1].axis('off')
                        
                        # ì „ì²´ íƒ€ì´í‹€
                        fig.suptitle(f'Layer {layer_idx} Attention Analysis - Epoch {epoch} - Sample {sample_count}', fontsize=16)
                        plt.tight_layout()
                        
                        # ê¸°ì¡´ ê²½ë¡œì— ì €ì¥
                        heatmap_path = os.path.join(sample_dirs[sample_count], 'heatmap', f'layer_{layer_idx}', f'epoch_{epoch}.png')
                        fig.savefig(heatmap_path, dpi=300, bbox_inches='tight')
                        plt.close(fig)
                        logger.info(f"Epoch {epoch} - ìƒ˜í”Œ {sample_count} ë ˆì´ì–´ {layer_idx} íˆíŠ¸ë§µ ì €ì¥: {heatmap_path}")

                    # 2. ì „ì²´ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ (clustering/ í´ë”ì— ì €ì¥) - ì²« ë²ˆì§¸ ìƒ˜í”Œì—ì„œë§Œ ìƒì„±
                    if sample_count == 0:  # ì¤‘ë³µ ë°©ì§€: ì²« ë²ˆì§¸ ìƒ˜í”Œì—ì„œë§Œ í´ëŸ¬ìŠ¤í„°ë§ ì‹œê°í™” ìƒì„±
                        # clustering í´ë” ìƒì„±
                        clustering_dir = os.path.join(base_viz_dir, 'clustering')
                        os.makedirs(clustering_dir, exist_ok=True)
                        model.save_cluster_centroids(clustering_dir, epoch)
                        if clustering_info['cluster_centroids'] is not None:
                            visualize_cluster_centroids(clustering_info, clustering_dir, epoch, feature_names)
    
                        # ğŸ†• ì „ì²´ ë°ì´í„°ì…‹ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ì‹œê°í™” (Label ì •ë³´ í¬í•¨)
                        if (clustering_info['cluster_centroids'] is not None and 
                            len(clustering_info['cluster_assignments']) > 0):
                            
                            cluster_assignments = clustering_info['cluster_assignments']
                            attention_maps = clustering_info['attention_maps']
                            attention_labels = clustering_info['attention_labels']  # ğŸ†• label ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                            
                            if len(cluster_assignments) > 0 and len(attention_maps) > 0:
                                fig, ax = plt.subplots(1, 1, figsize=(12, 10))
                                
                                cluster_assignments = np.array(cluster_assignments)
                                attention_labels = np.array(attention_labels)  # ğŸ†• label ë°°ì—´ë¡œ ë³€í™˜
                                
                                try:
                                    from sklearn.manifold import TSNE
                                    
                                    # attention mapsë¥¼ numpyë¡œ ë³€í™˜ (ì‹œê°í™”ìš©)
                                    attention_np = torch.stack(attention_maps).detach().cpu().numpy()
                                    n_maps, seq_len, seq_len2 = attention_np.shape
                                    
                                    # í‰íƒ„í™”í•´ì„œ t-SNE ì ìš©
                                    flattened_maps = attention_np.reshape(n_maps, -1)
                                    
                                    if n_maps >= 2:
                                        perplexity = min(30, n_maps-1, max(1, n_maps//3))
                                        
                                        # Centroid ì²˜ë¦¬ ì¶”ê°€
                                        if clustering_info['cluster_centroids'] is not None:
                                            cluster_centroids = clustering_info['cluster_centroids']
                                            
                                            # Centroidë¥¼ numpyë¡œ ë³€í™˜ (íƒ€ì… í™•ì¸)
                                            if isinstance(cluster_centroids, torch.Tensor):
                                                centroids_np = cluster_centroids.detach().cpu().numpy()
                                            else:
                                                # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° stack
                                                centroids_np = torch.stack(cluster_centroids).detach().cpu().numpy()
                                            
                                            centroids_flat = centroids_np.reshape(len(centroids_np), -1)
                                            
                                            # ì „ì²´ ë°ì´í„°(attention maps + centroids)ë¥¼ í•¨ê»˜ t-SNE ë³€í™˜
                                            all_data = np.vstack([flattened_maps, centroids_flat])
                                            tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity)
                                            tsne_all_embeddings = tsne.fit_transform(all_data)
                                            
                                            # ì›ë³¸ ë°ì´í„°ì™€ centroid ë¶„ë¦¬
                                            tsne_embeddings = tsne_all_embeddings[:n_maps]
                                            centroid_embeddings = tsne_all_embeddings[n_maps:]
                                        else:
                                            # Centroidê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹
                                            tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity)
                                            tsne_embeddings = tsne.fit_transform(flattened_maps)
                                            centroid_embeddings = None
                                        
                                        # ğŸ†• í´ëŸ¬ìŠ¤í„°ë³„ë¡œ ë‹¤ë¥¸ ìƒ‰ìƒ, labelë³„ë¡œ ëª…ë„ ì¡°ì ˆ
                                        unique_clusters = np.unique(cluster_assignments)
                                        unique_labels = np.unique(attention_labels)
                                        
                                        # í´ëŸ¬ìŠ¤í„°ë³„ ê¸°ë³¸ ìƒ‰ìƒ ì„¤ì •
                                        base_colors = plt.cm.Set3(np.linspace(0, 1, max(len(unique_clusters), 1)))
                                        
                                        for i, cluster_id in enumerate(unique_clusters):
                                            cluster_mask = cluster_assignments == cluster_id
                                            cluster_points = tsne_embeddings[cluster_mask]
                                            cluster_labels = attention_labels[cluster_mask]
                                            
                                            if len(cluster_points) > 0:
                                                # ğŸ†• labelë³„ë¡œ ëª¨ì–‘ êµ¬ë¶„: Label 0=ì›í˜•, Label 1=ë„¤ëª¨
                                                for label in unique_labels:
                                                    label_mask = cluster_labels == label
                                                    if np.any(label_mask):
                                                        label_points = cluster_points[label_mask]
                                                        
                                                        # ëª¨ì–‘ êµ¬ë¶„: label 0ì€ ì›í˜•, label 1ì€ ë„¤ëª¨
                                                        if label == 0:
                                                            marker = 'o'  # ì›í˜•
                                                            marker_name = 'Label 0'
                                                        else:
                                                            marker = 's'  # ë„¤ëª¨
                                                            marker_name = 'Label 1'
                                                        
                                                        ax.scatter(label_points[:, 0], label_points[:, 1], 
                                                                c=base_colors[i], 
                                                                label=f'Cluster {cluster_id} ({marker_name})', 
                                                                alpha=0.7, s=50, marker=marker)
                                        
                                        # Centroidë¥¼ ë³„í‘œë¡œ í‘œì‹œ
                                        if centroid_embeddings is not None:
                                            for i, cluster_id in enumerate(unique_clusters):
                                                if i < len(centroid_embeddings):
                                                    ax.scatter(centroid_embeddings[i, 0], centroid_embeddings[i, 1], 
                                                            marker='*', s=300, c='black', 
                                                            edgecolors=base_colors[i], linewidth=3,
                                                            label='Centroids' if i == 0 else "", zorder=5)
                                        
                                        ax.set_title(f'Dataset-wide Final Layer Clustering (Epoch {epoch})\nCumulative Layer 2 Attention Maps', fontsize=16)
                                        ax.set_xlabel('t-SNE Dimension 1', fontsize=12)
                                        ax.set_ylabel('t-SNE Dimension 2', fontsize=12)
                                        
                                        if len(unique_clusters) > 0:
                                            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
                                        ax.grid(True, alpha=0.3)
                                        
                                        # ğŸ†• í´ëŸ¬ìŠ¤í„° ë° label í†µê³„ ì •ë³´
                                        cluster_stats = []
                                        for cluster_id in unique_clusters:
                                            cluster_mask = cluster_assignments == cluster_id
                                            cluster_labels_subset = attention_labels[cluster_mask]
                                            total_count = np.sum(cluster_mask)
                                            total_percentage = (total_count / len(cluster_assignments)) * 100
                                            
                                            label_counts = {}
                                            for label in unique_labels:
                                                count = np.sum(cluster_labels_subset == label)
                                                label_counts[int(label)] = count
                                            
                                            label_str = ", ".join([f"L{k}:{v}" for k, v in label_counts.items()])
                                            cluster_stats.append(f"Cluster {cluster_id}: {total_count} maps ({total_percentage:.1f}%) [{label_str}]")
                                        
                                        if cluster_stats:
                                            stats_text = "\n".join(cluster_stats)
                                            ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, 
                                                fontsize=10, verticalalignment='top',
                                                bbox=dict(boxstyle="round,pad=0.4", facecolor="lightgray", alpha=0.9))
                                        
                                        # ì „ì²´ í†µê³„
                                        total_samples_processed = n_maps
                                        ax.text(0.02, 0.02, f"Total Layer 2 Maps: {total_samples_processed}\nEpoch: {epoch}\nUpdate Freq: {model.clustering_update_freq}\nCircle=Label 0, Square=Label 1", 
                                            transform=ax.transAxes, fontsize=10, verticalalignment='bottom',
                                            bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.8))
                                        
                                        plt.tight_layout()
                                        
                                        # clustering í´ë”ì— ì €ì¥
                                        clustering_path = os.path.join(clustering_dir, f'epoch_{epoch}.png')
                                        fig.savefig(clustering_path, dpi=300, bbox_inches='tight')
                                        plt.close(fig)
                                        logger.info(f"Epoch {epoch} - ì „ì²´ ë°ì´í„°ì…‹ í´ëŸ¬ìŠ¤í„°ë§ ì €ì¥: {clustering_path}")
                                        
                                    else:
                                        # ë°ì´í„° ë¶€ì¡±í•œ ê²½ìš°
                                        fig, ax = plt.subplots(1, 1, figsize=(10, 8))
                                        ax.text(0.5, 0.5, f'Dataset-wide Clustering (Epoch {epoch})\n\nNeed more data for t-SNE\nCurrent maps: {n_maps}\nMinimum required: 2', 
                                            ha='center', va='center', transform=ax.transAxes, fontsize=14,
                                            bbox=dict(boxstyle="round,pad=0.5", facecolor="lightyellow", alpha=0.8))
                                        ax.set_title(f'Dataset-wide Final Layer Clustering (Epoch {epoch})', fontsize=16)
                                        ax.axis('off')
                                        
                                        clustering_path = os.path.join(clustering_dir, f'epoch_{epoch}.png')
                                        fig.savefig(clustering_path, dpi=300, bbox_inches='tight')
                                        plt.close(fig)
                                        logger.info(f"Epoch {epoch} - í´ëŸ¬ìŠ¤í„°ë§ ëŒ€ê¸° ìƒíƒœ ì €ì¥: {clustering_path}")
                                        
                                except Exception as e:
                                    logger.error(f"Clustering visualization error: {e}")
                                    
                            else:
                                # í´ëŸ¬ìŠ¤í„°ë§ ë°ì´í„° ì—†ëŠ” ê²½ìš°
                                fig, ax = plt.subplots(1, 1, figsize=(10, 8))
                                total_maps = clustering_info.get('attention_count', 0)
                                ax.text(0.5, 0.5, f'Dataset-wide Clustering (Epoch {epoch})\n\nNo clustering data available\nTotal maps collected: {total_maps}\nRequired: {model.num_clusters}', 
                                    ha='center', va='center', transform=ax.transAxes, fontsize=14,
                                    bbox=dict(boxstyle="round,pad=0.5", facecolor="lightcoral", alpha=0.8))
                                ax.set_title(f'Dataset-wide Final Layer Clustering (Epoch {epoch})', fontsize=16)
                                ax.axis('off')
                                
                                clustering_path = os.path.join(clustering_dir, f'epoch_{epoch}.png')
                                fig.savefig(clustering_path, dpi=300, bbox_inches='tight')
                                plt.close(fig)
                                logger.info(f"Epoch {epoch} - í´ëŸ¬ìŠ¤í„°ë§ ì—†ìŒ ìƒíƒœ ì €ì¥: {clustering_path}")


                # 2. ê·¸ë˜í”„ êµ¬ì¡° ì‹œê°í™”
                if args.viz_graph:
                    # ê° ë ˆì´ì–´ë³„ë¡œ ì‹œê°í™” ìˆ˜í–‰
                    for layer_idx in range(len(model.layers)):
                        # 1) Attention ê°€ì¤‘ì¹˜(í—¤ë“œ í‰ê· )
                        attn_weights = model.layers[layer_idx].attn_weights[sample_idx]  # [n_heads, seq, seq]
                        attn_weights_mean = attn_weights.mean(dim=0).cpu()

                        # ì›ë³¸ adjacency ì‚¬ìš© (íˆíŠ¸ë§µê³¼ ì¼ì¹˜í•˜ëŠ” ê°’)
                        adjacency = model.layers[layer_idx].adjacency[sample_idx].cpu()
                        # adj_row_sums = adjacency.sum(axis=1, keepdims=True) + 1e-9
                        # adjacency = adjacency / adj_row_sums
                        new_seq = attn_weights_mean.shape[0]
                        graph_matrix = torch.zeros((new_seq, new_seq), device=attn_weights_mean.device, dtype = torch.float)

                        graph_matrix[1:, 1:] = adjacency  # ë³€ìˆ˜ ê°„ ì—°ê²°ì€ ì›ë³¸ adjacency ì‚¬ìš©
                        graph_matrix[0, 1:] = 1.0  # CLS->ë³€ìˆ˜ ì—°ê²°
                        graph_matrix[1:, 0] = 0.0  # ë³€ìˆ˜->CLS ì—°ê²°
                        
                        mask = (graph_matrix == 0)
                        final_graph_matrix = (attn_weights_mean * graph_matrix).numpy()
                        final_graph_matrix[mask.numpy()] = 0.0
                        # row_sums = final_graph_matrix.sum(axis=1, keepdims=True)
                        # final_graph_matrix = final_graph_matrix / (row_sums + 1e-9)  # stability ìœ„í•´ 1e-9 ë”í•¨ 
                        n_nodes = final_graph_matrix.shape[0]
                        
                        # 2) Edge ë¦¬ìŠ¤íŠ¸(ëª¨ë“  i->j) ìˆ˜ì§‘ (Barplotìš©)
                        cls_edges_info = []  # CLSì—ì„œ ë‚˜ê°€ëŠ” ì—£ì§€
                        var_edges_info = []  # ë‚˜ë¨¸ì§€ ì—£ì§€
                        
                        for i in range(n_nodes):
                            for j in range(n_nodes):
                                if i != j:
                                    w = final_graph_matrix[i, j]
                                    if i == 0:
                                        cls_edges_info.append((f"{i}->{j}", w))
                                    else:
                                        var_edges_info.append((f"{i}->{j}", w))
                        
                        # topK ì ìš©
                        top_k = min(10, len(var_edges_info))
                        var_edges_info.sort(key=lambda x: x[1], reverse=True)
                        var_edges_info = var_edges_info[:top_k]
                        
                        # ì „ì²´ í•©ì¹˜ê¸°
                        edges_info = cls_edges_info + var_edges_info
                        edges_info.sort(key=lambda x: x[1], reverse=True)
                        edge_labels = [x[0] for x in edges_info]
                        edge_weights = [x[1] for x in edges_info]
                        
                        # CLS ì—£ì§€ì™€ ì¼ë°˜ ì—£ì§€ êµ¬ë¶„ì„ ìœ„í•œ ìƒ‰ìƒ ë¦¬ìŠ¤íŠ¸
                        bar_colors = []
                        for label in edge_labels:
                            if label.startswith("0->"):
                                bar_colors.append("crimson")  # CLS ì—£ì§€ëŠ” ë¹¨ê°„ìƒ‰
                            else:
                                bar_colors.append("cornflowerblue")  # ì¼ë°˜ ì—£ì§€ëŠ” íŒŒë€ìƒ‰
                        
                        # ë…¸ë“œ ì´ë¦„ ë§¤í•‘
                        node_name_map = {0: "CLS"}
                        for i in range(1, n_nodes):
                            idx_feat = i - 1
                            if idx_feat < len(feature_names):
                                node_name_map[i] = feature_names[idx_feat]
                            else:
                                node_name_map[i] = f"feature_{i}"
                                
                        # xì¶• ë¼ë²¨ì— ì‚¬ìš©í•  ì´ë¦„ ë³€í™˜
                        display_edge_labels = []
                        for label in edge_labels:
                            i, j = map(int, label.split('->'))
                            display_edge_labels.append(f"{node_name_map[i]}->{node_name_map[j]}")
                        
                        # Figure & 2 Subplots ìƒì„±
                        fig, axes = plt.subplots(2, 2, figsize=(24, 20))
                        ax_bar = axes[0, 0]
                        
                        # -----(A) Left Subplot: Barplot)-----
                        bars = ax_bar.bar(range(len(edge_weights)), edge_weights, color=bar_colors)
                        
                        # ê° ë°” ìœ„ì— attention score ê°’ í‘œì‹œ
                        for i, (weight, label) in enumerate(zip(edge_weights, edge_labels)):
                            ax_bar.text(i, weight + 0.01, f"{weight:.3f}", 
                                      ha='center', va='bottom', rotation=45, 
                                      fontsize=7, color='black')
                        
                        ax_bar.set_title(f'Top Edge Weights - Layer {layer_idx}', fontsize=12)
                        ax_bar.set_xlabel('Edge (i->j)')
                        ax_bar.set_ylabel('Attention Weight')
                        # xì¶• ë¼ë²¨ (ë„ˆë¬´ ë§ìœ¼ë©´ íšŒì „)
                        ax_bar.set_xticks(range(len(edge_labels)))
                        ax_bar.set_xticklabels(display_edge_labels, rotation=90, fontsize=8)
                        
                        # -----(B) Right Subplot: Network Graph)-----
                        ax_graph = axes[0, 1]
                        G = nx.DiGraph()
                        node_labels = {}

                        for i in range(n_nodes):
                            if i == 0:
                                node_name = "CLS"
                                node_color = "red"
                            else:
                                idx_feat = i - 1
                                if idx_feat < len(feature_names):
                                    node_name = feature_names[idx_feat]
                                    node_color = "blue"
                                else:
                                    node_name = f"feature_{i}"
                                    node_color = "blue"

                            G.add_node(i, name=node_name, color=node_color)
                            node_labels[i] = node_name

                        # CLS->Var / Var->Var êµ¬ë¶„í•´ì„œ ê·¸ë¦¬ê¸°
                        cls_min_edge_weight = 0.001
                        min_edge_weight = 0.001
                        for i in range(n_nodes):
                            for j in range(n_nodes):
                                if i == j:
                                    continue

                                w = final_graph_matrix[i, j]
                                if i == 0 and j != 0:
                                    # CLS->Var
                                    if w > cls_min_edge_weight:
                                        G.add_edge(i, j, weight=w, cls_to_var=True)
                                elif j == 0:
                                    # Var->CLSëŠ” í‘œì‹œ ì•ˆ í•¨
                                    continue
                                else:
                                    if w > min_edge_weight:
                                        # Var->Var
                                        G.add_edge(i, j, weight=w, cls_to_var=False)

                        pos = {}
                        pos[0] = np.array([0, 0])
                        non_center_nodes = n_nodes - 1
                        radius = 1.0
                        for i_ in range(1, n_nodes):
                            angle_ = 2 * np.pi * (i_ - 1) / non_center_nodes
                            pos[i_] = np.array([radius * np.cos(angle_), radius * np.sin(angle_)])

                        # ë°°ê²½ ê·¸ë¦¬ë“œ
                        for r_ in [0.25, 0.5, 0.75, 1.0]:
                            circle = plt.Circle((0, 0), r_, fill=False, color='lightgray', linestyle='--', alpha=0.5)
                            ax_graph.add_patch(circle)
                        for i_ in range(1, n_nodes):
                            angle__ = 2 * np.pi * (i_ - 1) / non_center_nodes
                            x_ = 1.1 * np.cos(angle__)
                            y_ = 1.1 * np.sin(angle__)
                            ax_graph.plot([0, x_], [0, y_], color='lightgray', linestyle='--', alpha=0.5)

                        node_colors = [d["color"] for _, d in G.nodes(data=True)]
                        nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=800, ax=ax_graph, edgecolors='gray')

                        cls_edges = [(u, v) for u, v, d in G.edges(data=True) if d.get('cls_to_var')]
                        var_edges = [(u, v) for u, v, d in G.edges(data=True) if not d.get('cls_to_var')]

                        cls_weights = [G[u][v]['weight'] for (u, v) in cls_edges]
                        var_weights = [G[u][v]['weight'] for (u, v) in var_edges]

                        # CLS->Var: ë¹¨ê°• êµµì€ì„ 
                        if cls_edges:
                            nx.draw_networkx_edges(
                                G, pos,
                                edgelist=cls_edges,
                                width=[2 + w * 5 for w in cls_weights],
                                alpha=0.7,
                                edge_color='crimson',
                                connectionstyle='arc3,rad=0.1',  
                                arrowstyle='-|>',  # í™”ì‚´í‘œ ìŠ¤íƒ€ì¼ ë³€ê²½
                                arrowsize=15,      # í™”ì‚´í‘œ í¬ê¸° í‚¤ìš°ê¸° (ê¸°ë³¸ê°’ë³´ë‹¤ í¬ê²Œ)
                                node_size=800,
                                ax=ax_graph
                            )

                        # Var->Var: íŒŒë‘ ì ì„ 
                        if var_edges:
                            nx.draw_networkx_edges(
                                G, pos,
                                edgelist=var_edges,
                                width=[1 + w * 2 for w in var_weights],
                                edge_color='blue',
                                style='dashed',
                                arrowstyle='-|>',
                                arrowsize=30,
                                alpha=0.5,
                                ax=ax_graph,
                                arrows=True
                            )

                        label_options = {
                            "font_size": 9,
                            "font_color": "black",
                            "bbox": dict(boxstyle="round,pad=0.3", fc="white", ec="gray", alpha=0.8)
                        }
                        nx.draw_networkx_labels(G, pos, labels=node_labels, ax=ax_graph, **label_options)

                        ax_graph.set_title(f'Graph Structure - Layer {layer_idx} - Epoch {epoch} - Sample {sample_count}', fontsize=12)
                        ax_graph.axis('off')
                        ax_graph.set_aspect('equal')
                        ax_graph.set_xlim([-1.2, 1.2])
                        ax_graph.set_ylim([-1.2, 1.2])

                        # 3. í™•ì¥ëœ graph matrix heatmap
                        ax_graph_matrix = axes[1, 0]
                        graph_matrix_np = graph_matrix.cpu().numpy() 
                        im_graph = ax_graph_matrix.imshow(graph_matrix_np, cmap="Blues", interpolation='nearest')
                        ax_graph_matrix.set_title("Graph Matrix (with CLS)", fontsize=14)
                        fig.colorbar(im_graph, ax=ax_graph_matrix)

                        all_node_names = ["CLS"] + feature_names 
                        ax_graph_matrix.set_xticks(np.arange(len(all_node_names)))
                        ax_graph_matrix.set_yticks(np.arange(len(all_node_names)))
                        ax_graph_matrix.set_xticklabels(all_node_names, rotation=90, fontsize=8)
                        ax_graph_matrix.set_yticklabels(all_node_names, fontsize=8)

                        for i in range(len(all_node_names)):
                            for j in range(len(all_node_names)):
                                ax_graph_matrix.text(j, i, f"{graph_matrix_np[i,j]:.2f}", ha="center", va="center", color="black" if graph_matrix_np[i,j] < 0.5 else "white", fontsize=8)

                        ax_final = axes[1, 1]
                        vmax = final_graph_matrix.max()
                        vmin = 0.0  # 0ë¶€í„° ì‹œì‘í•˜ë„ë¡ ì„¤ì •

                        # ë‹¤ë¥¸ ì»¬ëŸ¬ë§µ ì‚¬ìš© ë° ë²”ìœ„ ì¡°ì •
                        im_final = ax_final.imshow(final_graph_matrix, 
                                                cmap='YlOrRd',  # 'YlOrRd', 'hot', 'OrRd' ë“± ì‹œë„í•´ë³¼ ìˆ˜ ìˆìŒ
                                                interpolation='nearest',
                                                vmin=vmin, 
                                                vmax=vmax)
                        ax_final.set_title("Final Graph Matrix (Attention * Graph_matrix)", fontsize=14)
                        fig.colorbar(im_final, ax=ax_final)
                        
                        ax_final.set_xticks(np.arange(len(all_node_names)))
                        ax_final.set_yticks(np.arange(len(all_node_names)))
                        ax_final.set_xticklabels(all_node_names, rotation=90, fontsize=8)
                        ax_final.set_yticklabels(all_node_names, fontsize=8)
                        
                        # ê° ì…€ì— ê°’ í‘œì‹œ
                        for i in range(len(all_node_names)):
                            for j in range(len(all_node_names)):
                                # ìƒëŒ€ì ì¸ ê°’ì— ë”°ë¼ í…ìŠ¤íŠ¸ ìƒ‰ìƒ ê²°ì • (0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ê²€ì •, ìµœëŒ€ê°’ì— ê°€ê¹Œìš¸ìˆ˜ë¡ í°ìƒ‰)
                                relative_value = final_graph_matrix[i,j] / vmax if vmax > 0 else 0
                                text_color = "black" if relative_value < 0.7 else "white"
                                
                                # ê°’ì´ 0ì¼ ê²½ìš° ë¹ˆ ë¬¸ìì—´ í‘œì‹œí•  ìˆ˜ë„ ìˆìŒ
                                value_text = f"{final_graph_matrix[i,j]:.3f}"
                                
                                ax_final.text(j, i, value_text, 
                                            ha="center", va="center", 
                                            color=text_color, 
                                            fontsize=7)
                        
                        # ì „ì²´ ì œëª© ì„¤ì •
                        fig.suptitle(f'Layer {layer_idx} - Epoch {epoch} - Sample {sample_count}', fontsize=18)
                        fig.tight_layout(rect=[0, 0.03, 1, 0.97])  # suptitleì„ ìœ„í•œ ì—¬ë°± í™•ë³´
                        
                        # # ë ˆì´ì–´ë³„ í´ë”ì— ì €ì¥
                        # layer_dir = os.path.join(sample_dirs[sample_count], f'layer_{layer_idx}')
                        # graph_path = os.path.join(layer_dir, f'epoch_{epoch}_complete.png')
                        # fig.savefig(graph_path, dpi=300, bbox_inches='tight')
                        # plt.close(fig)
                        
                        # logger.info(f"ìƒ˜í”Œ {sample_count} - ë ˆì´ì–´ {layer_idx} - ì—í¬í¬ {epoch} ì¢…í•© ì‹œê°í™” ì €ì¥: {graph_path}")
                        graph_path = os.path.join(sample_dirs[sample_count], 'graph', f'layer_{layer_idx}', f'epoch_{epoch}_complete.png')
                        fig.savefig(graph_path, dpi=300, bbox_inches='tight')
                        plt.close(fig)
                        logger.info(f"ìƒ˜í”Œ {sample_count} - ë ˆì´ì–´ {layer_idx} - ì—í¬í¬ {epoch} ê·¸ë˜í”„ ì‹œê°í™” ì €ì¥: {graph_path}")
                sample_count += 1
                if sample_count >= max_samples:
                    break

            if sample_count >= max_samples:
                break




def visualize_gmm_clusters(gmm, embeddings, output_dir="visualizations/gmm_clusters", step=None, filename=None):
    """
    t-SNE ì‹œê°í™”ë§Œ ì œê³µí•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.
    
    Args:
        gmm: GMM ë˜ëŠ” GMM2 ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
        embeddings: ì…ë ¥ ì„ë² ë”© [batch_size, input_dim]
        output_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        step: ìŠ¤í… ë²ˆí˜¸ (íŒŒì¼ëª…ìš©)
        filename: ì‚¬ìš©ì ì§€ì • íŒŒì¼ëª… (ì„ íƒì‚¬í•­)
    """
    try:
        import os
        import numpy as np
        import matplotlib.pyplot as plt
        from sklearn.manifold import TSNE
        
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
            
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        device = embeddings.device
        
        # GMMìœ¼ë¡œ í´ëŸ¬ìŠ¤í„° í• ë‹¹ í™•ë¥  ê³„ì‚°
        if hasattr(gmm, 'forward'):
            with torch.no_grad():
                if 'GMM2' in gmm.__class__.__name__:
                    r, _, _ = gmm(embeddings, is_train=False)
                else:
                    r, _ = gmm(embeddings, is_train=False)
                
                # ê°€ì¥ í™•ë¥ ì´ ë†’ì€ í´ëŸ¬ìŠ¤í„° í• ë‹¹
                cluster_assignments = torch.argmax(r, dim=1).cpu().numpy()
                # í• ë‹¹ í™•ë¥  (ì‹ ë¢°ë„)
                confidences = torch.max(r, dim=1)[0].cpu().numpy()
                # í”„ë¡œí† íƒ€ì… ê°€ì ¸ì˜¤ê¸°
                prototypes = gmm.running_prototypes.detach().cpu().numpy()
        else:
            # GMM ê°ì²´ê°€ ì•„ë‹Œ ê²½ìš° (ë””ë²„ê¹…ìš©)
            prototypes = np.random.randn(32, embeddings.shape[1])
            cluster_assignments = np.random.randint(0, 32, size=embeddings.shape[0])
            confidences = np.random.rand(embeddings.shape[0])
        
        # ì„ë² ë”©ì„ CPUë¡œ ì´ë™
        embeddings_np = embeddings.detach().cpu().numpy()
        
        # prototypesê°€ 3ì°¨ì›ì¸ ê²½ìš° 2ì°¨ì›ìœ¼ë¡œ ë³€í™˜
        if prototypes.ndim == 3:  # [1, num_prototypes, input_dim] í˜•íƒœì¸ ê²½ìš°
            prototypes = prototypes.squeeze(0)  # [num_prototypes, input_dim] í˜•íƒœë¡œ ë³€í™˜
        
        # t-SNEë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë¡œí† íƒ€ì…ê³¼ ì„ë² ë”©ì„ 2Dë¡œ íˆ¬ì˜
        combined_data = np.vstack([prototypes, embeddings_np])
        
        # t-SNE ì°¨ì› ì¶•ì†Œ (perplexity ì¡°ì •)
        tsne = TSNE(n_components=2, perplexity=min(30, len(combined_data)-1), 
                   random_state=42, learning_rate=200)
        combined_reduced = tsne.fit_transform(combined_data)
        
        # í”„ë¡œí† íƒ€ì…ê³¼ ì„ë² ë”©ìœ¼ë¡œ ë‹¤ì‹œ ë¶„ë¦¬
        reduced_prototypes = combined_reduced[:len(prototypes)]
        reduced_embeddings = combined_reduced[len(prototypes):]
        
        # ===== t-SNE ì‹œê°í™”ë§Œ ìƒì„± =====
        plt.figure(figsize=(12, 10))
        
        # ì£¼ìš” í”„ë¡œí† íƒ€ì… ì¶”ì  (ì‹œê°í™”ìš©)
        key_prototypes = set(cluster_assignments)
        
        # í´ëŸ¬ìŠ¤í„° í†µê³„ ê³„ì‚°
        cluster_counts = {}
        for c in cluster_assignments:
            cluster_counts[c] = cluster_counts.get(c, 0) + 1
        
        largest_cluster = max(cluster_counts.items(), key=lambda x: x[1]) if cluster_counts else (-1, 0)
        empty_clusters = len(prototypes) - len(cluster_counts)
        
        # í”„ë¡œí† íƒ€ì… ì‹œê°í™”
        for i, (x, y) in enumerate(reduced_prototypes):
            # ì£¼ìš” í”„ë¡œí† íƒ€ì… ê°•ì¡° (ìƒ˜í”Œì´ í• ë‹¹ëœ ê²ƒë“¤)
            if i in key_prototypes:
                marker_size = 250
                edge_width = 2.5
                zorder = 10
                marker_style = '*'
                plt.scatter(x, y, s=marker_size, c=f'C{i % 10}', marker=marker_style, 
                           edgecolors='black', linewidths=edge_width, alpha=0.9,
                           zorder=zorder, label=f'P{i+1} (Main)')
                
                # í”„ë¡œí† íƒ€ì… ë ˆì´ë¸” (ëˆˆì— ë„ê²Œ)
                plt.annotate(f'P{i+1}', (x, y), fontsize=14, fontweight='bold',
                            ha='center', va='center', color='white',
                            bbox=dict(boxstyle='round,pad=0.4', fc=f'C{i % 10}', alpha=0.8),
                            zorder=zorder+1)
            else:
                # ë¹„í™œì„± í”„ë¡œí† íƒ€ì… (ìƒ˜í”Œì´ í• ë‹¹ë˜ì§€ ì•Šì€ ê²ƒë“¤)
                marker_size = 100
                plt.scatter(x, y, s=marker_size, c=f'C{i % 10}', marker='o', 
                           alpha=0.4, zorder=5)
                plt.annotate(f'P{i+1}', (x, y), fontsize=9, ha='center', va='center', 
                            zorder=6)
        
        # ìƒ˜í”Œ ì‹œê°í™” (ë‹¤ì´ì•„ëª¬ë“œ ëª¨ì–‘)
        for j, (x, y) in enumerate(reduced_embeddings):
            cluster_id = cluster_assignments[j]
            confidence = confidences[j]
            
            # ìƒ˜í”Œ ë§ˆì»¤
            plt.scatter(x, y, s=250, c='white', marker='D', edgecolors='black', 
                       linewidths=2, alpha=0.9, zorder=15)
            
            # ìƒ˜í”Œ ID
            plt.annotate(f'S{j+1}', (x, y), fontsize=12, fontweight='bold', 
                        ha='center', va='center', zorder=16)
            
            for i, (proto_x, proto_y) in enumerate(reduced_prototypes):
                if i == cluster_id:
                    # í• ë‹¹ í™•ë¥ ì— ë¹„ë¡€í•˜ëŠ” ì„  ë‘ê»˜
                    line_width = 1.5 + 5 * confidence
                    plt.plot([x, proto_x], [y, proto_y], '--', 
                            linewidth=line_width, alpha=0.7, 
                            c=f'C{i % 10}', zorder=1)
                    
                    # í• ë‹¹ í™•ë¥  í‘œì‹œ
                    mid_x = (x + proto_x) * 0.6 + (proto_x + x) * 0.4
                    mid_y = (y + proto_y) * 0.6 + (proto_y + y) * 0.4
                    plt.annotate(f'{confidence:.2f}', (mid_x, mid_y), 
                                fontsize=11, fontweight='bold',
                                bbox=dict(boxstyle='round,pad=0.3', fc='white', alpha=0.9),
                                zorder=7)
        
        # í´ëŸ¬ìŠ¤í„°ë§ í†µê³„ ì •ë³´ ì¶”ê°€
        info_text = f"Largest cluster: {largest_cluster[1]} samples (P{largest_cluster[0]+1})\n"
        info_text += f"Empty clusters: {empty_clusters}\n"
        
        for c, count in sorted(cluster_counts.items()):
            info_text += f"Cluster {c+1}: {count} samples\n"
        
        plt.figtext(0.02, 0.02, info_text, fontsize=10,
                  bbox=dict(boxstyle='round', fc='whitesmoke', alpha=0.9))
        
        # ê·¸ë˜í”„ ì œëª© ë° ë ˆì´ë¸”
        plt.title('t-SNE Visualization of Sample-Prototype Assignments', fontsize=14)
        plt.xlabel('t-SNE Dimension 1', fontsize=12)
        plt.ylabel('t-SNE Dimension 2', fontsize=12)
        plt.grid(True, linestyle='--', alpha=0.7)
        
        if key_prototypes:
            plt.legend(loc='upper right', fontsize=10)
        
        plt.tight_layout()
        
        # íŒŒì¼ ì €ì¥
        if filename is None:
            if step is not None:
                filename = f"tsne_only_{step}.png"
            else:
                filename = "tsne_only.png"
                
        plt.savefig(os.path.join(output_dir, filename), dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"t-SNE visualization saved to {os.path.join(output_dir, filename)}")
        
        return {
            'cluster_assignments': cluster_assignments,
            'confidences': confidences,
            'prototypes': reduced_prototypes,
            'embeddings': reduced_embeddings
        }
    
    except Exception as e:
        print(f"ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        print(traceback.format_exc())
        return None





def visualize_results(args, results, exp_dir):
    os.makedirs(exp_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # few-shotì´ 8 ì´ìƒì¼ ë•ŒëŠ” few-shot ê²°ê³¼ë§Œ ì‹œê°í™”
    if args.few_shot > 4:
        fig, (ax3, ax4) = plt.subplots(1, 2, figsize=(15, 6))
        
        # Few-shotì˜ Train vs Valid
        ax3.plot(results["Full_results"]["Ours_few"]["Ours_train_few_losses"], label='Train Loss')
        ax3.plot(results["Full_results"]["Ours_few"]["Ours_val_few_losses"], label='Valid Loss')
        ax3.set_xlabel('Epochs')
        ax3.set_ylabel('Loss')
        ax3.set_title('Few-shot: Train vs Valid Loss')
        ax3.legend()
        ax3.grid(True)

        ax4.plot(results["Full_results"]["Ours_few"]["Ours_train_few_auc"], label='Train AUC')
        ax4.plot(results["Full_results"]["Ours_few"]["Ours_val_few_auc"], label='Valid AUC')
        ax4.set_xlabel('Epochs')
        ax4.set_ylabel('AUC')
        ax4.set_title('Few-shot: Train vs Valid AUC')
        ax4.legend()
        ax4.grid(True)

    # few-shotì´ 4ì¼ ë•ŒëŠ” fullê³¼ few-shot ëª¨ë‘ ì‹œê°í™”
    else:
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
        
        # Full datasetì˜ Train vs Valid
        ax1.plot(results["Full_results"]["Ours"]["Ours_train_full_losses"], label='Train Loss')
        ax1.plot(results["Full_results"]["Ours"]["Ours_val_full_losses"], label='Valid Loss')
        ax1.set_xlabel('Epochs')
        ax1.set_ylabel('Loss')
        ax1.set_title('Full Dataset: Train vs Valid Loss')
        ax1.legend()
        ax1.grid(True)

        ax2.plot(results["Full_results"]["Ours"]["Ours_train_full_auc"], label='Train AUC')
        ax2.plot(results["Full_results"]["Ours"]["Ours_val_full_auc"], label='Valid AUC')
        ax2.set_xlabel('Epochs')
        ax2.set_ylabel('AUC')
        ax2.set_title('Full Dataset: Train vs Valid AUC')
        ax2.legend()
        ax2.grid(True)
        
        # Few-shotì˜ Train vs Valid
        ax3.plot(results["Full_results"]["Ours_few"]["Ours_train_few_losses"], label='Train Loss')
        ax3.plot(results["Full_results"]["Ours_few"]["Ours_val_few_losses"], label='Valid Loss')
        ax3.set_xlabel('Epochs')
        ax3.set_ylabel('Loss')
        ax3.set_title('Few-shot: Train vs Valid Loss')
        ax3.legend()
        ax3.grid(True)

        ax4.plot(results["Full_results"]["Ours_few"]["Ours_train_few_auc"], label='Train AUC')
        ax4.plot(results["Full_results"]["Ours_few"]["Ours_val_few_auc"], label='Valid AUC')
        ax4.set_xlabel('Epochs')
        ax4.set_ylabel('AUC')
        ax4.set_title('Few-shot: Train vs Valid AUC')
        ax4.legend()
        ax4.grid(True)

    plt.suptitle(f'Training Progress - {args.source_dataset_name} (K={args.few_shot})', y=1.02, fontsize=16)
    plt.tight_layout()
    metrics_plot_path = os.path.join(exp_dir, f"f{args.few_shot}_b{args.batch_size}_l{args.num_layers}_h{args.n_heads}_{timestamp}.png")
    plt.savefig(metrics_plot_path)
    plt.close()

    print(f"Metrics plot saved as {metrics_plot_path}")
"""
Comprehensive Clustering Metrics Analysis

ê¸°ì¡´ ì‹¤ë£¨ì—£ ë¶„ì„ê³¼ ë™ì¼í•œ ê²°ê³¼ë¥¼ ë³´ì¥í•˜ë©´ì„œ 
within/between variance ë“± ë‹¤ì–‘í•œ í´ëŸ¬ìŠ¤í„°ë§ ë©”íŠ¸ë¦­ì„ ë¶„ì„í•©ë‹ˆë‹¤.

Usage:
    python analysis3.py --checkpoint_dir /path/to/checkpoint.pt --mode Full
"""

import os
# CUDA deterministic ì„¤ì •ì„ ê°€ì¥ ë¨¼ì € ì„¤ì •
os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'
from scipy.signal import find_peaks
from scipy.ndimage import gaussian_filter1d
import torch
import argparse
import numpy as np
import logging
from pathlib import Path
import json
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, silhouette_samples, calinski_harabasz_score, davies_bouldin_score
from sklearn.manifold import TSNE
import seaborn as sns
from scipy.spatial.distance import cdist

# ê¸°ì¡´ ëª¨ë“ˆë“¤ import
from models.TabularFLM import Model
from dataset.data_dataloaders import prepare_embedding_dataloaders, get_few_shot_embedding_samples
from utils.util import setup_logger, fix_seed

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def ensure_deterministic():
    """ì™„ì „í•œ deterministic ì„¤ì •"""
    # Random seeds
    np.random.seed(42)
    torch.manual_seed(42)
    torch.cuda.manual_seed(42)
    torch.cuda.manual_seed_all(42)
    
    # CUDA deterministic
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    torch.use_deterministic_algorithms(True)
    
    # Environment variables
    os.environ['PYTHONHASHSEED'] = '42'
    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'
    
    logger.info("âœ… Deterministic mode enabled")

class ComprehensiveClusteringAnalyzer:
    def __init__(self, checkpoint_dir, device='cuda'):
        """
        Args:
            checkpoint_dir (str): ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ
            device (str): 'cuda' ë˜ëŠ” 'cpu'
        """
        # Deterministic ì„¤ì • ë¨¼ì €
        ensure_deterministic()
        
        self.checkpoint_dir = checkpoint_dir
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        
        # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
        self.checkpoint = torch.load(checkpoint_dir, map_location=self.device)
        self.args = self.checkpoint['args']
        
        logger.info(f"Loaded checkpoint from {checkpoint_dir}")
        logger.info(f"Checkpoint epoch: {self.checkpoint['epoch']}, Val AUC: {self.checkpoint['val_auc']:.4f}")
        
        # ëª¨ë¸ ì´ˆê¸°í™” ë° ë¡œë“œ
        self._load_model()
        
        # ë°ì´í„°ë¡œë” ì¤€ë¹„
        self._prepare_dataloaders()
        
    def _load_model(self):
        """ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ ë¡œë“œ"""
        experiment_id = "comprehensive_analysis"
        mode = "analysis"
        
        self.model = Model(
            self.args, 
            self.args.input_dim, 
            self.args.hidden_dim, 
            self.args.output_dim, 
            self.args.num_layers, 
            self.args.dropout_rate, 
            self.args.llm_model,
            experiment_id,
            mode
        ).to(self.device)
        
        # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
        self.model.load_state_dict(self.checkpoint['model_state_dict'])
        self.model.eval()
        
        logger.info("Model loaded and set to evaluation mode")
    
    def _prepare_dataloaders(self):
        """ë°ì´í„°ë¡œë” ì¤€ë¹„ (deterministic)"""
        fix_seed(self.args.random_seed)
        
        # ì „ì²´ ë°ì´í„°ì…‹ ë¡œë” ì¤€ë¹„
        results = prepare_embedding_dataloaders(self.args, self.args.source_data)
        self.train_loader, self.val_loader, self.test_loader = results['loaders']
        self.num_classes = results['num_classes']
        from torch.utils.data import ConcatDataset, DataLoader
        
        combined_dataset = ConcatDataset([
            self.train_loader.dataset,
            self.val_loader.dataset, 
            self.test_loader.dataset
        ])
        
        self.combined_loader = DataLoader(
            combined_dataset,
            batch_size=self.train_loader.batch_size,
            shuffle=False,
            num_workers=getattr(self.train_loader, 'num_workers', 0)
        )
        # Few-shot ë¡œë” ì¤€ë¹„ (í•„ìš”í•œ ê²½ìš°)
        if hasattr(self.args, 'few_shot') and self.args.few_shot > 0:
            self.train_loader_few = get_few_shot_embedding_samples(self.train_loader, self.args)
        
        logger.info(f"Dataloaders prepared for dataset: {self.args.source_data}")
    
    def extract_attention_maps(self, data_loader):
        """
        ë°ì´í„°ë¡œë”ì—ì„œ attention maps ì¶”ì¶œ (deterministic)
        
        Args:
            data_loader: ë°ì´í„°ë¡œë”
            
        Returns:
            dict: ë ˆì´ì–´ë³„ attention mapsì™€ ë©”íƒ€ë°ì´í„°
        """
        attention_data = {
            'layer_0': [],
            'layer_1': [], 
            'layer_2': [],
            'labels': [],
            'sample_ids': [],
            'feature_names': None
        }
        
        sample_count = 0
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(data_loader):
                # ë°°ì¹˜ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
                batch_on_device = {
                    k: v.to(self.device) if isinstance(v, torch.Tensor) else v
                    for k, v in batch.items()
                }
                
                # ëª¨ë¸ forward (attention weights ì¶”ì¶œ)
                pred, attention_weights = self._extract_attention_from_model(batch_on_device)
                
                # Feature names ì¶”ì¶œ (ì²« ë²ˆì§¸ ë°°ì¹˜ì—ì„œë§Œ)
                if attention_data['feature_names'] is None:
                    feature_names = self.model.extract_feature_names(batch_on_device)
                    attention_data['feature_names'] = ["CLS"] + feature_names
                
                # ë°°ì¹˜ í¬ê¸° í™•ì¸
                batch_size = attention_weights[0].shape[0]
                
                for sample_idx in range(batch_size):
                    # ê° ë ˆì´ì–´ë³„ attention map ì €ì¥
                    for layer_idx, layer_attention in enumerate(attention_weights):
                        # Multi-head attentionì„ í‰ê· ë‚´ì–´ ë‹¨ì¼ attention mapìœ¼ë¡œ ë³€í™˜
                        attention_map = layer_attention[sample_idx].mean(dim=0)  # [seq_len, seq_len]
                        attention_numpy = attention_map.detach().cpu().numpy()
                        attention_data[f'layer_{layer_idx}'].append(attention_numpy)
                    
                    # ë¼ë²¨ê³¼ ìƒ˜í”Œ ID ì €ì¥
                    if 'y' in batch:
                        label = batch['y'][sample_idx].item()
                    else:
                        label = -1  # ë¼ë²¨ì´ ì—†ëŠ” ê²½ìš°
                    attention_data['labels'].append(label)
                    
                    # ìƒ˜í”Œ ID (ì‹¤ì œ ë°ì´í„°ì…‹ì˜ ì¸ë±ìŠ¤ ë˜ëŠ” ì¹´ìš´í„°)
                    if 'sample_ids' in batch:
                        sample_id = batch['sample_ids'][sample_idx]
                    else:
                        sample_id = sample_count
                    attention_data['sample_ids'].append(sample_id)
                    
                    sample_count += 1
                
                if batch_idx % 10 == 0:
                    logger.info(f"Processed {sample_count} samples...")
        
        logger.info(f"Extracted attention maps for {sample_count} samples")
        return attention_data
    
    def _extract_attention_from_model(self, batch):
        """
        ëª¨ë¸ì—ì„œ attention weightsì™€ ì˜ˆì¸¡ê°’ì„ ì¶”ì¶œ
        """
        # ëª¨ë¸ì˜ predict ë¡œì§ì„ ë³µì‚¬í•˜ë˜ attention_weightsë„ ë°˜í™˜
        label_description_embeddings = batch['label_description_embeddings'].to(self.device)
        desc_embeddings = [] 
        name_value_embeddings = [] 
        
        if all(k in batch for k in ['cat_name_value_embeddings', 'cat_desc_embeddings']):
            cat_name_value_embeddings = batch['cat_name_value_embeddings'].to(self.device).squeeze(-2)
            cat_desc_embeddings = batch['cat_desc_embeddings'].to(self.device).squeeze(-2)
            
            name_value_embeddings.append(cat_name_value_embeddings)
            desc_embeddings.append(cat_desc_embeddings)
            
        if all(k in batch for k in ['num_prompt_embeddings', 'num_desc_embeddings']):
            num_prompt_embeddings = batch['num_prompt_embeddings'].to(self.device).squeeze(-2)
            num_desc_embeddings = batch['num_desc_embeddings'].to(self.device).squeeze(-2)
            name_value_embeddings.append(num_prompt_embeddings)
            desc_embeddings.append(num_desc_embeddings)
            
        if not desc_embeddings or not name_value_embeddings:
            raise ValueError("No categorical or numerical features found in batch")

        desc_embeddings = torch.cat(desc_embeddings, dim = 1)
        name_value_embeddings = torch.cat(name_value_embeddings, dim = 1)
        
        # [CLS] Token ì¶”ê°€
        attention_weights = [] 
        cls_token = self.model.cls.expand(name_value_embeddings.size(0), -1, -1)
        name_value_embeddings = torch.cat([cls_token, name_value_embeddings], dim=1)
        x = name_value_embeddings
        
        # Graph Attention Layers
        for i, layer in enumerate(self.model.layers):
            norm_x = self.model.layer_norms[i](x)
            attn_output, attn_weights = layer(desc_embeddings, norm_x)
            attention_weights.append(attn_weights)
            x = x + attn_output
        
        # ì˜ˆì¸¡ê°’ ê³„ì‚°
        pred = x[:, 0, :]
        pred = self.model.predictor(pred)

        return pred, attention_weights

    def calculate_within_between_variance(self, data, cluster_labels):
        """
        Within-cluster Sum of Squares (WCSS)ì™€ Between-cluster Sum of Squares (BCSS) ê³„ì‚°
        
        Args:
            data: í´ëŸ¬ìŠ¤í„°ë§ ë°ì´í„° [n_samples, n_features]
            cluster_labels: í´ëŸ¬ìŠ¤í„° í• ë‹¹ ë¼ë²¨ [n_samples]
            
        Returns:
            dict: WCSS, BCSS, Total SS, ë¹„ìœ¨ ë“±ì˜ ë©”íŠ¸ë¦­
        """
        n_samples = len(data)
        k = len(np.unique(cluster_labels))
        
        # ì „ì²´ ë°ì´í„°ì˜ ì¤‘ì‹¬ì  (Grand Centroid)
        grand_centroid = np.mean(data, axis=0)
        
        # Total Sum of Squares (TSS)
        tss = np.sum((data - grand_centroid) ** 2)
        
        # Within-cluster Sum of Squares (WCSS)
        wcss = 0
        cluster_centroids = []
        cluster_sizes = []
        
        for cluster_id in np.unique(cluster_labels):
            cluster_mask = cluster_labels == cluster_id
            cluster_data = data[cluster_mask]
            cluster_centroid = np.mean(cluster_data, axis=0)
            cluster_centroids.append(cluster_centroid)
            cluster_sizes.append(len(cluster_data))
            
            # í´ëŸ¬ìŠ¤í„° ë‚´ ë¶„ì‚° ê³„ì‚°
            cluster_wcss = np.sum((cluster_data - cluster_centroid) ** 2)
            wcss += cluster_wcss
        
        cluster_centroids = np.array(cluster_centroids)
        cluster_sizes = np.array(cluster_sizes)
        
        # Between-cluster Sum of Squares (BCSS)
        bcss = 0
        for i, centroid in enumerate(cluster_centroids):
            bcss += cluster_sizes[i] * np.sum((centroid - grand_centroid) ** 2)
        
        # ê²€ì¦: TSS = WCSS + BCSS (ë°˜ë“œì‹œ ì„±ë¦½í•´ì•¼ í•¨)
        tss_check = wcss + bcss
        
        return {
            'wcss': float(wcss),
            'bcss': float(bcss),
            'tss': float(tss),
            'tss_check': float(tss_check),
            'bcss_wcss_ratio': float(bcss / wcss) if wcss > 0 else float('inf'),
            'explained_variance_ratio': float(bcss / tss) if tss > 0 else 0.0,
            'n_clusters': int(k),
            'n_samples': int(n_samples),
            'cluster_sizes': cluster_sizes.tolist(),
            'verification_error': float(abs(tss - tss_check))
        }

    def calculate_comprehensive_metrics(self, data, cluster_labels):
        """
        ëª¨ë“  í´ëŸ¬ìŠ¤í„°ë§ ë©”íŠ¸ë¦­ì„ ì¢…í•©ì ìœ¼ë¡œ ê³„ì‚°
        
        Args:
            data: í´ëŸ¬ìŠ¤í„°ë§ ë°ì´í„°
            cluster_labels: í´ëŸ¬ìŠ¤í„° í• ë‹¹ ë¼ë²¨
            
        Returns:
            dict: ëª¨ë“  ë©”íŠ¸ë¦­ ê²°ê³¼
        """
        metrics = {}
        
        # 1. Silhouette Metrics
        silhouette_avg = silhouette_score(data, cluster_labels)
        silhouette_samples_scores = silhouette_samples(data, cluster_labels)
        
        metrics['silhouette'] = {
            'average_score': float(silhouette_avg),
            'sample_scores': silhouette_samples_scores.tolist(),
            'min_score': float(np.min(silhouette_samples_scores)),
            'max_score': float(np.max(silhouette_samples_scores)),
            'std_score': float(np.std(silhouette_samples_scores))
        }
        
        # 2. Within/Between Variance Analysis
        variance_metrics = self.calculate_within_between_variance(data, cluster_labels)
        metrics['variance_analysis'] = variance_metrics
        
        # 3. Calinski-Harabasz Index (ë¶„ì‚°ë¹„ ê¸°ì¤€)
        ch_score = calinski_harabasz_score(data, cluster_labels)
        metrics['calinski_harabasz'] = {
            'score': float(ch_score),
            'interpretation': 'higher_is_better'
        }
        
        # 4. Davies-Bouldin Index
        db_score = davies_bouldin_score(data, cluster_labels)
        metrics['davies_bouldin'] = {
            'score': float(db_score),
            'interpretation': 'lower_is_better'
        }
        
        # 5. Inertia (K-means WCSS)
        kmeans_temp = KMeans(n_clusters=len(np.unique(cluster_labels)), random_state=42, n_init=1)
        kmeans_temp.fit(data)
        metrics['inertia'] = {
            'score': float(kmeans_temp.inertia_),
            'interpretation': 'lower_is_better'
        }
        
        # 6. Dunn Index (ìµœì†Œ inter-cluster distance / ìµœëŒ€ intra-cluster distance)
        dunn_score = self._calculate_dunn_index(data, cluster_labels)
        metrics['dunn_index'] = {
            'score': float(dunn_score),
            'interpretation': 'higher_is_better'
        }
        
        # 7. í´ëŸ¬ìŠ¤í„°ë³„ í†µê³„
        cluster_stats = self._calculate_cluster_statistics(data, cluster_labels)
        metrics['cluster_statistics'] = cluster_stats
        
        return metrics

    def _calculate_dunn_index(self, data, cluster_labels):
        """Dunn Index ê³„ì‚°"""
        unique_labels = np.unique(cluster_labels)
        
        # Inter-cluster distances (í´ëŸ¬ìŠ¤í„° ê°„ ìµœì†Œ ê±°ë¦¬)
        inter_cluster_distances = []
        for i in range(len(unique_labels)):
            for j in range(i + 1, len(unique_labels)):
                cluster_i = data[cluster_labels == unique_labels[i]]
                cluster_j = data[cluster_labels == unique_labels[j]]
                
                # ë‘ í´ëŸ¬ìŠ¤í„° ê°„ ëª¨ë“  ì ë“¤ì˜ ìµœì†Œ ê±°ë¦¬
                distances = cdist(cluster_i, cluster_j, metric='euclidean')
                min_distance = np.min(distances)
                inter_cluster_distances.append(min_distance)
        
        # Intra-cluster distances (í´ëŸ¬ìŠ¤í„° ë‚´ ìµœëŒ€ ê±°ë¦¬)
        intra_cluster_distances = []
        for label in unique_labels:
            cluster_data = data[cluster_labels == label]
            if len(cluster_data) > 1:
                distances = cdist(cluster_data, cluster_data, metric='euclidean')
                # ëŒ€ê°ì„  ì œì™¸í•˜ê³  ìµœëŒ€ ê±°ë¦¬
                np.fill_diagonal(distances, 0)
                max_distance = np.max(distances)
                intra_cluster_distances.append(max_distance)
        
        if len(inter_cluster_distances) == 0 or len(intra_cluster_distances) == 0:
            return 0.0
        
        min_inter = np.min(inter_cluster_distances)
        max_intra = np.max(intra_cluster_distances)
        
        return min_inter / max_intra if max_intra > 0 else 0.0

    def _calculate_cluster_statistics(self, data, cluster_labels):
        """í´ëŸ¬ìŠ¤í„°ë³„ ì„¸ë¶€ í†µê³„ ê³„ì‚°"""
        unique_labels = np.unique(cluster_labels)
        cluster_stats = {}
        
        for label in unique_labels:
            cluster_data = data[cluster_labels == label]
            centroid = np.mean(cluster_data, axis=0)
            
            # í´ëŸ¬ìŠ¤í„° ë‚´ ê±°ë¦¬ë“¤
            if len(cluster_data) > 1:
                distances_to_centroid = np.linalg.norm(cluster_data - centroid, axis=1)
                intra_cluster_distances = cdist(cluster_data, cluster_data, metric='euclidean')
                np.fill_diagonal(intra_cluster_distances, np.inf)  # ìê¸° ìì‹  ì œì™¸
                
                cluster_stats[f'cluster_{label}'] = {
                    'size': int(len(cluster_data)),
                    'centroid': centroid.tolist(),
                    'mean_distance_to_centroid': float(np.mean(distances_to_centroid)),
                    'max_distance_to_centroid': float(np.max(distances_to_centroid)),
                    'std_distance_to_centroid': float(np.std(distances_to_centroid)),
                    'min_intra_distance': float(np.min(intra_cluster_distances)),
                    'mean_intra_distance': float(np.mean(intra_cluster_distances[intra_cluster_distances != np.inf])),
                    'max_intra_distance': float(np.max(intra_cluster_distances[intra_cluster_distances != np.inf]))
                }
            else:
                cluster_stats[f'cluster_{label}'] = {
                    'size': 1,
                    'centroid': centroid.tolist(),
                    'mean_distance_to_centroid': 0.0,
                    'max_distance_to_centroid': 0.0,
                    'std_distance_to_centroid': 0.0,
                    'min_intra_distance': 0.0,
                    'mean_intra_distance': 0.0,
                    'max_intra_distance': 0.0
                }
        
        return cluster_stats

    def perform_comprehensive_analysis(self, attention_data, layer_idx, k_range=(2, 15), output_dir=None):
        """
        íŠ¹ì • ë ˆì´ì–´ì— ëŒ€í•´ ì¢…í•©ì ì¸ í´ëŸ¬ìŠ¤í„°ë§ ë©”íŠ¸ë¦­ ë¶„ì„ ìˆ˜í–‰
        
        Args:
            attention_data (dict): attention maps ë°ì´í„°
            layer_idx (int): ë¶„ì„í•  ë ˆì´ì–´ ì¸ë±ìŠ¤
            k_range (tuple): í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ ë²”ìœ„ (min_k, max_k)
            output_dir (str, optional): ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        
        Returns:
            dict: ì¢…í•© ë¶„ì„ ê²°ê³¼
        """
        if output_dir:
            output_dir = Path(output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)
        
        # íŠ¹ì • ë ˆì´ì–´ì˜ attention maps ì¶”ì¶œ
        attention_maps = np.stack(attention_data[f'layer_{layer_idx}'])
        labels = np.array(attention_data['labels'])
        feature_names = attention_data['feature_names']
        
        logger.info(f"Performing comprehensive analysis on layer {layer_idx} with {len(attention_maps)} samples")
        logger.info(f"Testing cluster range: {k_range[0]} to {k_range[1]}")
        
        # í‰íƒ„í™” (ë²¡í„°í™”)
        flattened_maps = attention_maps.reshape(len(attention_maps), -1)
        
        min_k, max_k = k_range
        k_values = list(range(min_k, max_k + 1))
        
        # ê° kê°’ì— ëŒ€í•´ ëª¨ë“  ë©”íŠ¸ë¦­ ê³„ì‚°
        comprehensive_results = {
            'layer_idx': layer_idx,
            'k_values': k_values,
            'feature_names': feature_names,
            'results_by_k': {}
        }
        
        for k in k_values:
            logger.info(f"Testing k={k}...")
            
            # Deterministic K-means
            np.random.seed(42)  # KMeans ë‚´ë¶€ ì´ˆê¸°í™”ë¥¼ ìœ„í•œ ì¶”ê°€ ì‹œë“œ
            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10, algorithm='lloyd')
            cluster_labels = kmeans.fit_predict(flattened_maps)
            
            # ëª¨ë“  ë©”íŠ¸ë¦­ ê³„ì‚°
            all_metrics = self.calculate_comprehensive_metrics(flattened_maps, cluster_labels)
            
            # ê²°ê³¼ ì €ì¥
            comprehensive_results['results_by_k'][k] = {
                'cluster_assignments': cluster_labels.tolist(),
                'metrics': all_metrics,
                'kmeans_centers': kmeans.cluster_centers_.tolist()
            }
            
            # ì£¼ìš” ë©”íŠ¸ë¦­ ë¡œê·¸ ì¶œë ¥
            silhouette = all_metrics['silhouette']['average_score']
            ch_score = all_metrics['calinski_harabasz']['score']
            db_score = all_metrics['davies_bouldin']['score']
            wcss = all_metrics['variance_analysis']['wcss']
            bcss = all_metrics['variance_analysis']['bcss']
            
            logger.info(f"k={k}: Silhouette={silhouette:.4f}, CH={ch_score:.2f}, DB={db_score:.4f}, WCSS={wcss:.2f}, BCSS={bcss:.2f}")
        
        # ìµœì  k ê²°ì • (ì‹¤ë£¨ì—£ ê¸°ì¤€ìœ¼ë¡œ ê¸°ì¡´ê³¼ ë™ì¼)
        silhouette_scores = [comprehensive_results['results_by_k'][k]['metrics']['silhouette']['average_score'] for k in k_values]
        best_k_idx = np.argmax(silhouette_scores)
        best_k = k_values[best_k_idx]
        best_score = silhouette_scores[best_k_idx]
        
        comprehensive_results['best_k_silhouette'] = best_k
        comprehensive_results['best_silhouette_score'] = best_score
        
        # ë‹¤ë¥¸ ë©”íŠ¸ë¦­ ê¸°ì¤€ ìµœì  kë„ ê³„ì‚°
        ch_scores = [comprehensive_results['results_by_k'][k]['metrics']['calinski_harabasz']['score'] for k in k_values]
        db_scores = [comprehensive_results['results_by_k'][k]['metrics']['davies_bouldin']['score'] for k in k_values]
        
        comprehensive_results['best_k_calinski_harabasz'] = k_values[np.argmax(ch_scores)]
        comprehensive_results['best_k_davies_bouldin'] = k_values[np.argmin(db_scores)]
        
        logger.info(f"ğŸ¯ Best k for layer {layer_idx}:")
        logger.info(f"   Silhouette: k={comprehensive_results['best_k_silhouette']} (score: {best_score:.4f})")
        logger.info(f"   Calinski-Harabasz: k={comprehensive_results['best_k_calinski_harabasz']} (score: {max(ch_scores):.2f})")
        logger.info(f"   Davies-Bouldin: k={comprehensive_results['best_k_davies_bouldin']} (score: {min(db_scores):.4f})")
        
        # ì‹œê°í™” ìƒì„±
        if output_dir:
            self._create_comprehensive_visualizations(comprehensive_results, flattened_maps, labels, output_dir)
            
            # ê²°ê³¼ JSON ì €ì¥
            results_json = comprehensive_results.copy()
            results_json['feature_names'] = list(feature_names)  # numpy arrayë¥¼ listë¡œ ë³€í™˜
            
            with open(output_dir / f'layer_{layer_idx}_comprehensive_results.json', 'w') as f:
                json.dump(results_json, f, indent=2)
            
            logger.info(f"âœ… Comprehensive analysis results saved to {output_dir}")
        
        return comprehensive_results

    def _create_comprehensive_visualizations(self, results, flattened_maps, labels, output_dir):
        """ì¢…í•©ì ì¸ ì‹œê°í™” ìƒì„±"""
        layer_idx = results['layer_idx']
        k_values = results['k_values']
        
        # 1. ëª¨ë“  ë©”íŠ¸ë¦­ ë¹„êµ í”Œë¡¯
        self._plot_all_metrics_comparison(results, output_dir)
        
        # 2. Within/Between Variance ìƒì„¸ ë¶„ì„
        self._plot_variance_analysis(results, output_dir)
        
        # 3. ì‹¤ë£¨ì—£ ë¶„ì„ ìƒì„¸ (ê¸°ì¡´ê³¼ ë™ì¼í•œ ìŠ¤íƒ€ì¼)
        self._plot_detailed_silhouette_analysis(results, flattened_maps, output_dir)
        
        # 4. ìµœì  kì— ëŒ€í•œ í´ëŸ¬ìŠ¤í„° ë¶„í¬ ì‹œê°í™”
        self._plot_optimal_clustering_comparison(results, flattened_maps, labels, output_dir)

    def _plot_all_metrics_comparison(self, results, output_dir):
        """ëª¨ë“  ë©”íŠ¸ë¦­ ë¹„êµ í”Œë¡¯"""
        k_values = results['k_values']
        layer_idx = results['layer_idx']
        
        # ë©”íŠ¸ë¦­ ë°ì´í„° ì¶”ì¶œ
        silhouette_scores = [results['results_by_k'][k]['metrics']['silhouette']['average_score'] for k in k_values]
        ch_scores = [results['results_by_k'][k]['metrics']['calinski_harabasz']['score'] for k in k_values]
        db_scores = [results['results_by_k'][k]['metrics']['davies_bouldin']['score'] for k in k_values]
        wcss_scores = [results['results_by_k'][k]['metrics']['variance_analysis']['wcss'] for k in k_values]
        bcss_scores = [results['results_by_k'][k]['metrics']['variance_analysis']['bcss'] for k in k_values]
        dunn_scores = [results['results_by_k'][k]['metrics']['dunn_index']['score'] for k in k_values]
        
        # 2x3 ì„œë¸Œí”Œë¡¯
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        
        # 1. Silhouette Score
        ax = axes[0, 0]
        ax.plot(k_values, silhouette_scores, 'bo-', linewidth=2, markersize=8)
        best_k_sil = results['best_k_silhouette']
        best_idx = k_values.index(best_k_sil)
        ax.plot(best_k_sil, silhouette_scores[best_idx], 'ro', markersize=12, markerfacecolor='red')
        ax.set_title('Silhouette Score')
        ax.set_xlabel('Number of Clusters (k)')
        ax.set_ylabel('Silhouette Score')
        ax.grid(True, alpha=0.3)
        ax.axvline(x=best_k_sil, color='red', linestyle='--', alpha=0.7)
        
        # 2. Calinski-Harabasz Index
        ax = axes[0, 1]
        ax.plot(k_values, ch_scores, 'go-', linewidth=2, markersize=8)
        best_k_ch = results['best_k_calinski_harabasz']
        best_idx_ch = k_values.index(best_k_ch)
        ax.plot(best_k_ch, ch_scores[best_idx_ch], 'ro', markersize=12, markerfacecolor='red')
        ax.set_title('Calinski-Harabasz Index')
        ax.set_xlabel('Number of Clusters (k)')
        ax.set_ylabel('CH Score')
        ax.grid(True, alpha=0.3)
        ax.axvline(x=best_k_ch, color='red', linestyle='--', alpha=0.7)
        
        # 3. Davies-Bouldin Index
        ax = axes[0, 2]
        ax.plot(k_values, db_scores, 'mo-', linewidth=2, markersize=8)
        best_k_db = results['best_k_davies_bouldin']
        best_idx_db = k_values.index(best_k_db)
        ax.plot(best_k_db, db_scores[best_idx_db], 'ro', markersize=12, markerfacecolor='red')
        ax.set_title('Davies-Bouldin Index (Lower is Better)')
        ax.set_xlabel('Number of Clusters (k)')
        ax.set_ylabel('DB Score')
        ax.grid(True, alpha=0.3)
        ax.axvline(x=best_k_db, color='red', linestyle='--', alpha=0.7)
        
        # 4. WCSS (Within-cluster Sum of Squares)
        ax = axes[1, 0]
        ax.plot(k_values, wcss_scores, 'co-', linewidth=2, markersize=8)
        ax.set_title('Within-Cluster Sum of Squares (WCSS)')
        ax.set_xlabel('Number of Clusters (k)')
        ax.set_ylabel('WCSS')
        ax.grid(True, alpha=0.3)
        # WCSSëŠ” í•­ìƒ ê°ì†Œí•˜ë¯€ë¡œ íŠ¹ì • ìµœì ì  í‘œì‹œ ì•ˆí•¨
        
        # 5. BCSS (Between-cluster Sum of Squares)
        ax = axes[1, 1]
        ax.plot(k_values, bcss_scores, 'yo-', linewidth=2, markersize=8)
        ax.set_title('Between-Cluster Sum of Squares (BCSS)')
        ax.set_xlabel('Number of Clusters (k)')
        ax.set_ylabel('BCSS')
        ax.grid(True, alpha=0.3)
        
        # 6. Dunn Index
        ax = axes[1, 2]
        ax.plot(k_values, dunn_scores, 'ko-', linewidth=2, markersize=8)
        ax.set_title('Dunn Index (Higher is Better)')
        ax.set_xlabel('Number of Clusters (k)')
        ax.set_ylabel('Dunn Index')
        ax.grid(True, alpha=0.3)
        
        # ì „ì²´ ì œëª©
        plt.suptitle(f'Layer {layer_idx}: Comprehensive Clustering Metrics Comparison', 
                    fontsize=16, y=0.98)
        plt.tight_layout()
        plt.savefig(output_dir / f'layer_{layer_idx}_all_metrics_comparison.png', 
                   dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_variance_analysis(self, results, output_dir):
        """Within/Between Variance ìƒì„¸ ë¶„ì„ í”Œë¡¯"""
        k_values = results['k_values']
        layer_idx = results['layer_idx']
        
        # ë¶„ì‚° ê´€ë ¨ ë°ì´í„° ì¶”ì¶œ
        wcss_scores = [results['results_by_k'][k]['metrics']['variance_analysis']['wcss'] for k in k_values]
        bcss_scores = [results['results_by_k'][k]['metrics']['variance_analysis']['bcss'] for k in k_values]
        tss_scores = [results['results_by_k'][k]['metrics']['variance_analysis']['tss'] for k in k_values]
        bcss_wcss_ratios = [results['results_by_k'][k]['metrics']['variance_analysis']['bcss_wcss_ratio'] for k in k_values]
        explained_variance_ratios = [results['results_by_k'][k]['metrics']['variance_analysis']['explained_variance_ratio'] for k in k_values]
        
        # 2x2 ì„œë¸Œí”Œë¡¯
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # 1. WCSS vs BCSS
        ax = axes[0, 0]
        ax.plot(k_values, wcss_scores, 'b-', label='WCSS (Within)', linewidth=2, marker='o')
        ax.plot(k_values, bcss_scores, 'r-', label='BCSS (Between)', linewidth=2, marker='s')
        ax.plot(k_values, tss_scores, 'g--', label='TSS (Total)', linewidth=2, marker='^')
        ax.set_title('Variance Decomposition: WCSS vs BCSS vs TSS')
        ax.set_xlabel('Number of Clusters (k)')
        ax.set_ylabel('Sum of Squares')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 2. BCSS/WCSS ë¹„ìœ¨
        ax = axes[0, 1]
        ax.plot(k_values, bcss_wcss_ratios, 'mo-', linewidth=2, markersize=8)
        ax.set_title('BCSS/WCSS Ratio (Higher is Better)')
        ax.set_xlabel('Number of Clusters (k)')
        ax.set_ylabel('BCSS/WCSS Ratio')
        ax.grid(True, alpha=0.3)
        
        # ìµœëŒ€ ë¹„ìœ¨ ì§€ì  í‘œì‹œ
        max_ratio_idx = np.argmax(bcss_wcss_ratios)
        max_ratio_k = k_values[max_ratio_idx]
        ax.plot(max_ratio_k, bcss_wcss_ratios[max_ratio_idx], 'ro', markersize=12)
        ax.axvline(x=max_ratio_k, color='red', linestyle='--', alpha=0.7)
        
        # 3. Explained Variance Ratio
        ax = axes[1, 0]
        ax.plot(k_values, explained_variance_ratios, 'co-', linewidth=2, markersize=8)
        ax.set_title('Explained Variance Ratio (BCSS/TSS)')
        ax.set_xlabel('Number of Clusters (k)')
        ax.set_ylabel('Explained Variance Ratio')
        ax.grid(True, alpha=0.3)
        ax.set_ylim(0, 1)
        
        # 4. Variance í†µê³„ ìš”ì•½
        ax = axes[1, 1]
        ax.axis('off')
        
        # í†µê³„ í…ìŠ¤íŠ¸ ìƒì„±
        best_k_sil = results['best_k_silhouette']
        best_k_idx = k_values.index(best_k_sil)
        
        variance_stats = results['results_by_k'][best_k_sil]['metrics']['variance_analysis']
        
        stats_text = f"Variance Analysis Summary (Best k={best_k_sil})\n\n"
        stats_text += f"WCSS (Within-cluster): {variance_stats['wcss']:.2f}\n"
        stats_text += f"BCSS (Between-cluster): {variance_stats['bcss']:.2f}\n"
        stats_text += f"TSS (Total): {variance_stats['tss']:.2f}\n"
        stats_text += f"BCSS/WCSS Ratio: {variance_stats['bcss_wcss_ratio']:.3f}\n"
        stats_text += f"Explained Variance: {variance_stats['explained_variance_ratio']:.3f}\n\n"
        
        # ë‹¤ë¥¸ kê°’ë“¤ê³¼ ë¹„êµ
        max_ratio_k = k_values[np.argmax(bcss_wcss_ratios)]
        max_explained_k = k_values[np.argmax(explained_variance_ratios)]
        
        stats_text += f"Best BCSS/WCSS Ratio: k={max_ratio_k} ({max(bcss_wcss_ratios):.3f})\n"
        stats_text += f"Best Explained Variance: k={max_explained_k} ({max(explained_variance_ratios):.3f})\n\n"
        
        # í•´ì„
        stats_text += "Interpretation:\n"
        stats_text += "â€¢ Higher BCSS/WCSS = Better separation\n"
        stats_text += "â€¢ Higher Explained Variance = Better clustering\n"
        stats_text += "â€¢ WCSS â†“, BCSS â†‘ = Ideal clustering"
        
        ax.text(0.1, 0.9, stats_text, transform=ax.transAxes, fontsize=11,
                verticalalignment='top', fontfamily='monospace',
                bbox=dict(boxstyle="round,pad=0.5", facecolor="lightblue", alpha=0.8))
        
        plt.suptitle(f'Layer {layer_idx}: Within/Between Variance Analysis', 
                    fontsize=16, y=0.98)
        plt.tight_layout()
        plt.savefig(output_dir / f'layer_{layer_idx}_variance_analysis.png', 
                   dpi=300, bbox_inches='tight')
        plt.close()
    # ê¸°ì¡´ ComprehensiveClusteringAnalyzer í´ë˜ìŠ¤ì— ì¶”ê°€í•  ë©”ì„œë“œë“¤

    import numpy as np
    from scipy.signal import find_peaks
    from scipy.ndimage import gaussian_filter1d

    def calculate_elbow_point(self, k_values, wcss_scores, method='knee'):
        """
        WCSS ê°’ì—ì„œ elbow pointë¥¼ ìë™ìœ¼ë¡œ ì°¾ëŠ” í•¨ìˆ˜
        
        Args:
            k_values: í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ ë¦¬ìŠ¤íŠ¸
            wcss_scores: ê° kì— ëŒ€í•œ WCSS ê°’
            method: 'knee', 'derivative', 'variance' ì¤‘ ì„ íƒ
        
        Returns:
            dict: elbow point ì •ë³´
        """
        k_values = np.array(k_values)
        wcss_scores = np.array(wcss_scores)
        
        if method == 'knee':
            # Knee detection using the "knee/elbow" method
            # ì²« ë²ˆì§¸ ì ê³¼ ë§ˆì§€ë§‰ ì ì„ ì‡ëŠ” ì§ì„ ìœ¼ë¡œë¶€í„°ì˜ ê±°ë¦¬ê°€ ìµœëŒ€ì¸ ì  ì°¾ê¸°
            
            # Normalize data to [0,1] for better knee detection
            k_norm = (k_values - k_values.min()) / (k_values.max() - k_values.min())
            wcss_norm = (wcss_scores - wcss_scores.min()) / (wcss_scores.max() - wcss_scores.min())
            
            # ì²« ì ê³¼ ë§ˆì§€ì ì„ ì‡ëŠ” ì§ì„ 
            line_start = np.array([k_norm[0], wcss_norm[0]])
            line_end = np.array([k_norm[-1], wcss_norm[-1]])
            
            # ê° ì ì—ì„œ ì§ì„ ê¹Œì§€ì˜ ê±°ë¦¬ ê³„ì‚°
            distances = []
            for i in range(len(k_norm)):
                point = np.array([k_norm[i], wcss_norm[i]])
                # ì ì—ì„œ ì§ì„ ê¹Œì§€ì˜ ê±°ë¦¬ ê³µì‹
                distance = np.abs(np.cross(line_end - line_start, line_start - point)) / np.linalg.norm(line_end - line_start)
                distances.append(distance)
            
            elbow_idx = np.argmax(distances)
            elbow_k = k_values[elbow_idx]
            elbow_score = wcss_scores[elbow_idx]
            max_distance = distances[elbow_idx]
            
            return {
                'method': 'knee',
                'elbow_k': int(elbow_k),
                'elbow_wcss': float(elbow_score),
                'confidence': float(max_distance),
                'all_distances': distances
            }
        
        elif method == 'derivative':
            # Second derivative method
            if len(wcss_scores) < 3:
                return {'method': 'derivative', 'elbow_k': k_values[0], 'elbow_wcss': wcss_scores[0], 'confidence': 0.0}
            
            # 1ì°¨ ë¯¸ë¶„ (ê¸°ìš¸ê¸°)
            first_derivative = np.diff(wcss_scores)
            # 2ì°¨ ë¯¸ë¶„ (ê¸°ìš¸ê¸°ì˜ ë³€í™”)
            second_derivative = np.diff(first_derivative)
            
            # 2ì°¨ ë¯¸ë¶„ì´ ìµœëŒ€ì¸ ì§€ì  (ê°€ì¥ ê¸‰ê²©í•˜ê²Œ ê¸°ìš¸ê¸°ê°€ ë³€í•˜ëŠ” ì§€ì )
            elbow_idx = np.argmax(second_derivative) + 1  # +1 because of diff operations
            elbow_k = k_values[elbow_idx]
            elbow_score = wcss_scores[elbow_idx]
            
            return {
                'method': 'derivative',
                'elbow_k': int(elbow_k),
                'elbow_wcss': float(elbow_score),
                'confidence': float(second_derivative[elbow_idx-1]),
                'first_derivative': first_derivative.tolist(),
                'second_derivative': second_derivative.tolist()
            }
        
        elif method == 'variance':
            # Variance-based method: ê¸°ìš¸ê¸°ì˜ ë¶„ì‚°ì´ ì¤„ì–´ë“œëŠ” ì§€ì 
            if len(wcss_scores) < 4:
                return {'method': 'variance', 'elbow_k': k_values[0], 'elbow_wcss': wcss_scores[0], 'confidence': 0.0}
            
            # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ê¸°ìš¸ê¸°ì˜ ë¶„ì‚° ê³„ì‚°
            window_size = min(3, len(wcss_scores) // 2)
            variances = []
            
            for i in range(window_size, len(wcss_scores) - window_size):
                window_slopes = []
                for j in range(i - window_size, i + window_size):
                    if j < len(wcss_scores) - 1:
                        slope = (wcss_scores[j+1] - wcss_scores[j]) / (k_values[j+1] - k_values[j])
                        window_slopes.append(slope)
                variances.append(np.var(window_slopes))
            
            # ë¶„ì‚°ì´ ìµœì†Œì¸ ì§€ì  (ê¸°ìš¸ê¸°ê°€ ì•ˆì •í™”ë˜ëŠ” ì§€ì )
            elbow_idx = np.argmin(variances) + window_size
            elbow_k = k_values[elbow_idx]
            elbow_score = wcss_scores[elbow_idx]
            
            return {
                'method': 'variance',
                'elbow_k': int(elbow_k),
                'elbow_wcss': float(elbow_score),
                'confidence': float(1.0 / (variances[elbow_idx - window_size] + 1e-10)),
                'variances': variances
            }

    def perform_comprehensive_analysis_with_elbow(self, attention_data, layer_idx, k_range=(2, 15), output_dir=None):
        """
        Elbow methodê°€ í¬í•¨ëœ ì¢…í•©ì ì¸ í´ëŸ¬ìŠ¤í„°ë§ ë©”íŠ¸ë¦­ ë¶„ì„ ìˆ˜í–‰
        """
        if output_dir:
            output_dir = Path(output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)
        
        # íŠ¹ì • ë ˆì´ì–´ì˜ attention maps ì¶”ì¶œ
        attention_maps = np.stack(attention_data[f'layer_{layer_idx}'])
        labels = np.array(attention_data['labels'])
        feature_names = attention_data['feature_names']
        
        logger.info(f"Performing comprehensive analysis (with Elbow) on layer {layer_idx} with {len(attention_maps)} samples")
        logger.info(f"Testing cluster range: {k_range[0]} to {k_range[1]}")
        
        # í‰íƒ„í™” (ë²¡í„°í™”)
        flattened_maps = attention_maps.reshape(len(attention_maps), -1)
        
        min_k, max_k = k_range
        k_values = list(range(min_k, max_k + 1))
        
        # ê° kê°’ì— ëŒ€í•´ ëª¨ë“  ë©”íŠ¸ë¦­ ê³„ì‚°
        comprehensive_results = {
            'layer_idx': layer_idx,
            'k_values': k_values,
            'feature_names': feature_names,
            'results_by_k': {}
        }
        
        wcss_scores = []
        
        for k in k_values:
            logger.info(f"Testing k={k}...")
            
            # Deterministic K-means
            np.random.seed(42)
            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10, algorithm='lloyd')
            cluster_labels = kmeans.fit_predict(flattened_maps)
            
            # ëª¨ë“  ë©”íŠ¸ë¦­ ê³„ì‚°
            all_metrics = self.calculate_comprehensive_metrics(flattened_maps, cluster_labels)
            
            # WCSS ì €ì¥
            wcss_scores.append(all_metrics['variance_analysis']['wcss'])
            
            # ê²°ê³¼ ì €ì¥
            comprehensive_results['results_by_k'][k] = {
                'cluster_assignments': cluster_labels.tolist(),
                'metrics': all_metrics,
                'kmeans_centers': kmeans.cluster_centers_.tolist()
            }
            
            # ì£¼ìš” ë©”íŠ¸ë¦­ ë¡œê·¸ ì¶œë ¥
            silhouette = all_metrics['silhouette']['average_score']
            ch_score = all_metrics['calinski_harabasz']['score']
            db_score = all_metrics['davies_bouldin']['score']
            wcss = all_metrics['variance_analysis']['wcss']
            bcss = all_metrics['variance_analysis']['bcss']
            
            logger.info(f"k={k}: Silhouette={silhouette:.4f}, CH={ch_score:.2f}, DB={db_score:.4f}, WCSS={wcss:.2f}, BCSS={bcss:.2f}")
        
        # Elbow method ì ìš©
        elbow_knee = self.calculate_elbow_point(k_values, wcss_scores, method='knee')
        elbow_derivative = self.calculate_elbow_point(k_values, wcss_scores, method='derivative')
        elbow_variance = self.calculate_elbow_point(k_values, wcss_scores, method='variance')
        
        comprehensive_results['elbow_analysis'] = {
            'knee_method': elbow_knee,
            'derivative_method': elbow_derivative,
            'variance_method': elbow_variance,
            'wcss_scores': wcss_scores
        }
        
        # ê¸°ì¡´ ë©”íŠ¸ë¦­ ê¸°ì¤€ ìµœì  k
        silhouette_scores = [comprehensive_results['results_by_k'][k]['metrics']['silhouette']['average_score'] for k in k_values]
        ch_scores = [comprehensive_results['results_by_k'][k]['metrics']['calinski_harabasz']['score'] for k in k_values]
        db_scores = [comprehensive_results['results_by_k'][k]['metrics']['davies_bouldin']['score'] for k in k_values]
        
        comprehensive_results['best_k_silhouette'] = k_values[np.argmax(silhouette_scores)]
        comprehensive_results['best_silhouette_score'] = max(silhouette_scores)
        comprehensive_results['best_k_calinski_harabasz'] = k_values[np.argmax(ch_scores)]
        comprehensive_results['best_k_davies_bouldin'] = k_values[np.argmin(db_scores)]
        
        # Elbow method ê¸°ì¤€ ìµœì  k (ê°€ì¥ ì‹ ë¢°ë„ ë†’ì€ ë°©ë²• ì„ íƒ)
        elbow_methods = [elbow_knee, elbow_derivative, elbow_variance]
        best_elbow = max(elbow_methods, key=lambda x: x['confidence'])
        comprehensive_results['best_k_elbow'] = best_elbow['elbow_k']
        comprehensive_results['best_elbow_method'] = best_elbow['method']
        
        logger.info(f"ğŸ¯ Best k for layer {layer_idx}:")
        logger.info(f"   Silhouette: k={comprehensive_results['best_k_silhouette']} (score: {max(silhouette_scores):.4f})")
        logger.info(f"   Calinski-Harabasz: k={comprehensive_results['best_k_calinski_harabasz']} (score: {max(ch_scores):.2f})")
        logger.info(f"   Davies-Bouldin: k={comprehensive_results['best_k_davies_bouldin']} (score: {min(db_scores):.4f})")
        logger.info(f"   ğŸ”¥ Elbow Method: k={comprehensive_results['best_k_elbow']} (method: {comprehensive_results['best_elbow_method']})")
        
        # ì‹œê°í™” ìƒì„±
        if output_dir:
            self._create_comprehensive_visualizations_with_elbow(comprehensive_results, flattened_maps, labels, output_dir)
            
            # ê²°ê³¼ JSON ì €ì¥
            results_json = comprehensive_results.copy()
            results_json['feature_names'] = list(feature_names)
            
            with open(output_dir / f'layer_{layer_idx}_comprehensive_results_with_elbow.json', 'w') as f:
                json.dump(results_json, f, indent=2)
            
            logger.info(f"âœ… Comprehensive analysis (with Elbow) results saved to {output_dir}")
        
        return comprehensive_results

    def _create_comprehensive_visualizations_with_elbow(self, results, flattened_maps, labels, output_dir):
        """Elbow methodê°€ í¬í•¨ëœ ì¢…í•©ì ì¸ ì‹œê°í™” ìƒì„±"""
        layer_idx = results['layer_idx']
        
        # 1. ëª¨ë“  ë©”íŠ¸ë¦­ + Elbow ë¹„êµ í”Œë¡¯
        self._plot_all_metrics_with_elbow_comparison(results, output_dir)
        
        # 2. Elbow method ìƒì„¸ ë¶„ì„
        self._plot_detailed_elbow_analysis(results, output_dir)
        
        # 3. Within/Between Variance ìƒì„¸ ë¶„ì„ (ê¸°ì¡´)
        self._plot_variance_analysis(results, output_dir)
        
        # 4. ëª¨ë“  ìµœì  k ë¹„êµ í´ëŸ¬ìŠ¤í„°ë§ ì‹œê°í™”
        self._plot_all_optimal_clustering_comparison(results, flattened_maps, labels, output_dir)

    def _plot_all_metrics_with_elbow_comparison(self, results, output_dir):
        """ëª¨ë“  ë©”íŠ¸ë¦­ê³¼ Elbow method ë¹„êµ í”Œë¡¯"""
        k_values = results['k_values']
        layer_idx = results['layer_idx']
        
        # ë©”íŠ¸ë¦­ ë°ì´í„° ì¶”ì¶œ
        silhouette_scores = [results['results_by_k'][k]['metrics']['silhouette']['average_score'] for k in k_values]
        ch_scores = [results['results_by_k'][k]['metrics']['calinski_harabasz']['score'] for k in k_values]
        db_scores = [results['results_by_k'][k]['metrics']['davies_bouldin']['score'] for k in k_values]
        wcss_scores = results['elbow_analysis']['wcss_scores']
        
        # Elbow ê²°ê³¼
        elbow_knee = results['elbow_analysis']['knee_method']
        elbow_derivative = results['elbow_analysis']['derivative_method']
        elbow_variance = results['elbow_analysis']['variance_method']
        
        # 2x3 ì„œë¸Œí”Œë¡¯
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        
        # 1. Silhouette Score
        ax = axes[0, 0]
        ax.plot(k_values, silhouette_scores, 'bo-', linewidth=2, markersize=8)
        best_k_sil = results['best_k_silhouette']
        best_idx = k_values.index(best_k_sil)
        ax.plot(best_k_sil, silhouette_scores[best_idx], 'ro', markersize=12, markerfacecolor='red')
        ax.set_title('Silhouette Score')
        ax.set_xlabel('Number of Clusters (k)')
        ax.set_ylabel('Silhouette Score')
        ax.grid(True, alpha=0.3)
        ax.axvline(x=best_k_sil, color='red', linestyle='--', alpha=0.7, label=f'Best k={best_k_sil}')
        ax.legend()
        
        # 2. Calinski-Harabasz Index
        ax = axes[0, 1]
        ax.plot(k_values, ch_scores, 'go-', linewidth=2, markersize=8)
        best_k_ch = results['best_k_calinski_harabasz']
        best_idx_ch = k_values.index(best_k_ch)
        ax.plot(best_k_ch, ch_scores[best_idx_ch], 'ro', markersize=12, markerfacecolor='red')
        ax.set_title('Calinski-Harabasz Index')
        ax.set_xlabel('Number of Clusters (k)')
        ax.set_ylabel('CH Score')
        ax.grid(True, alpha=0.3)
        ax.axvline(x=best_k_ch, color='red', linestyle='--', alpha=0.7, label=f'Best k={best_k_ch}')
        ax.legend()
        
        # 3. Davies-Bouldin Index
        ax = axes[0, 2]
        ax.plot(k_values, db_scores, 'mo-', linewidth=2, markersize=8)
        best_k_db = results['best_k_davies_bouldin']
        best_idx_db = k_values.index(best_k_db)
        ax.plot(best_k_db, db_scores[best_idx_db], 'ro', markersize=12, markerfacecolor='red')
        ax.set_title('Davies-Bouldin Index (Lower is Better)')
        ax.set_xlabel('Number of Clusters (k)')
        ax.set_ylabel('DB Score')
        ax.grid(True, alpha=0.3)
        ax.axvline(x=best_k_db, color='red', linestyle='--', alpha=0.7, label=f'Best k={best_k_db}')
        ax.legend()
        
        # 4. WCSS with Elbow Points
        ax = axes[1, 0]
        ax.plot(k_values, wcss_scores, 'co-', linewidth=2, markersize=8, label='WCSS')
        
        # Elbow points í‘œì‹œ
        ax.axvline(x=elbow_knee['elbow_k'], color='red', linestyle='-', alpha=0.8, linewidth=2, label=f'Knee: k={elbow_knee["elbow_k"]}')
        ax.axvline(x=elbow_derivative['elbow_k'], color='orange', linestyle='--', alpha=0.8, linewidth=2, label=f'Derivative: k={elbow_derivative["elbow_k"]}')
        ax.axvline(x=elbow_variance['elbow_k'], color='purple', linestyle=':', alpha=0.8, linewidth=2, label=f'Variance: k={elbow_variance["elbow_k"]}')
        
        # Best elbow ê°•ì¡°
        best_elbow_k = results['best_k_elbow']
        best_elbow_idx = k_values.index(best_elbow_k)
        ax.plot(best_elbow_k, wcss_scores[best_elbow_idx], 'rs', markersize=15, markerfacecolor='red', markeredgecolor='darkred', markeredgewidth=2)
        
        ax.set_title('WCSS with Elbow Points')
        ax.set_xlabel('Number of Clusters (k)')
        ax.set_ylabel('WCSS')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 5. ëª¨ë“  ìµœì  k ë¹„êµ
        ax = axes[1, 1]
        optimal_ks = {
            'Silhouette': results['best_k_silhouette'],
            'Calinski-H': results['best_k_calinski_harabasz'],
            'Davies-B': results['best_k_davies_bouldin'],
            'Elbow': results['best_k_elbow']
        }
        
        methods = list(optimal_ks.keys())
        k_vals = list(optimal_ks.values())
        colors = ['blue', 'green', 'magenta', 'red']
        
        bars = ax.bar(methods, k_vals, color=colors, alpha=0.7)
        for i, (method, k_val) in enumerate(zip(methods, k_vals)):
            ax.text(bars[i].get_x() + bars[i].get_width()/2, bars[i].get_height() + 0.1,
                f'k={k_val}', ha='center', va='bottom', fontsize=10, fontweight='bold')
        
        ax.set_title('Optimal k by Different Methods')
        ax.set_xlabel('Method')
        ax.set_ylabel('Optimal k')
        ax.grid(True, alpha=0.3)
        
        # 6. Elbow Confidence Scores
        ax = axes[1, 2]
        elbow_methods = ['Knee', 'Derivative', 'Variance']
        elbow_confidences = [elbow_knee['confidence'], elbow_derivative['confidence'], elbow_variance['confidence']]
        elbow_k_vals = [elbow_knee['elbow_k'], elbow_derivative['elbow_k'], elbow_variance['elbow_k']]
        
        bars = ax.bar(elbow_methods, elbow_confidences, color=['red', 'orange', 'purple'], alpha=0.7)
        for i, (method, conf, k_val) in enumerate(zip(elbow_methods, elbow_confidences, elbow_k_vals)):
            ax.text(bars[i].get_x() + bars[i].get_width()/2, bars[i].get_height() + max(elbow_confidences)*0.02,
                f'k={k_val}', ha='center', va='bottom', fontsize=9, fontweight='bold')
        
        ax.set_title('Elbow Method Confidence Scores')
        ax.set_xlabel('Elbow Method')
        ax.set_ylabel('Confidence Score')
        ax.grid(True, alpha=0.3)
        
        # ìµœê³  ì‹ ë¢°ë„ ë°©ë²• ê°•ì¡°
        best_method_idx = np.argmax(elbow_confidences)
        bars[best_method_idx].set_edgecolor('black')
        bars[best_method_idx].set_linewidth(3)
        
        plt.suptitle(f'Layer {layer_idx}: Comprehensive Metrics + Elbow Method Comparison', 
                    fontsize=16, y=0.98)
        plt.tight_layout()
        plt.savefig(output_dir / f'layer_{layer_idx}_all_metrics_with_elbow.png', 
                dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_detailed_elbow_analysis(self, results, output_dir):
        """Elbow method ìƒì„¸ ë¶„ì„ í”Œë¡¯"""
        k_values = results['k_values']
        layer_idx = results['layer_idx']
        wcss_scores = results['elbow_analysis']['wcss_scores']
        
        elbow_knee = results['elbow_analysis']['knee_method']
        elbow_derivative = results['elbow_analysis']['derivative_method']
        elbow_variance = results['elbow_analysis']['variance_method']
        
        # 2x2 ì„œë¸Œí”Œë¡¯
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # 1. Knee Method Visualization
        ax = axes[0, 0]
        ax.plot(k_values, wcss_scores, 'bo-', linewidth=2, markersize=8, label='WCSS')
        
        # Knee point ê°•ì¡°
        knee_k = elbow_knee['elbow_k']
        knee_idx = k_values.index(knee_k)
        ax.plot(knee_k, wcss_scores[knee_idx], 'rs', markersize=15, markerfacecolor='red', 
                markeredgecolor='darkred', markeredgewidth=2, label=f'Knee Point (k={knee_k})')
        
        # ì§ì„  ê·¸ë¦¬ê¸° (ì²« ì ê³¼ ë§ˆì§€ë§‰ ì )
        ax.plot([k_values[0], k_values[-1]], [wcss_scores[0], wcss_scores[-1]], 
                'r--', alpha=0.5, linewidth=2, label='Reference Line')
        
        # ê±°ë¦¬ ì‹œê°í™” (knee pointì—ì„œ)
        if 'all_distances' in elbow_knee:
            distances = elbow_knee['all_distances']
            ax2 = ax.twinx()
            ax2.plot(k_values, distances, 'g^-', alpha=0.6, markersize=6, label='Distance to Line')
            ax2.set_ylabel('Distance to Reference Line', color='green')
            ax2.tick_params(axis='y', labelcolor='green')
        
        ax.set_title('Knee Method Analysis')
        ax.set_xlabel('Number of Clusters (k)')
        ax.set_ylabel('WCSS')
        ax.legend(loc='upper right')
        ax.grid(True, alpha=0.3)
        
        # 2. Derivative Method Visualization
        ax = axes[0, 1]
        ax.plot(k_values, wcss_scores, 'bo-', linewidth=2, markersize=8, label='WCSS')
        
        # Derivative elbow point
        deriv_k = elbow_derivative['elbow_k']
        deriv_idx = k_values.index(deriv_k)
        ax.plot(deriv_k, wcss_scores[deriv_idx], 'rs', markersize=15, markerfacecolor='orange', 
                markeredgecolor='darkorange', markeredgewidth=2, label=f'Derivative Elbow (k={deriv_k})')
        
        # 1ì°¨, 2ì°¨ ë¯¸ë¶„ ì‹œê°í™”
        if 'first_derivative' in elbow_derivative and 'second_derivative' in elbow_derivative:
            first_deriv = elbow_derivative['first_derivative']
            second_deriv = elbow_derivative['second_derivative']
            
            ax2 = ax.twinx()
            k_first = k_values[1:]  # 1ì°¨ ë¯¸ë¶„ì€ í•˜ë‚˜ ì ìŒ
            k_second = k_values[2:]  # 2ì°¨ ë¯¸ë¶„ì€ ë‘˜ ì ìŒ
            
            ax2.plot(k_first, first_deriv, 'g^-', alpha=0.6, markersize=4, label='1st Derivative')
            ax2.plot(k_second, second_deriv, 'mv-', alpha=0.6, markersize=4, label='2nd Derivative')
            ax2.set_ylabel('Derivative Values', color='green')
            ax2.tick_params(axis='y', labelcolor='green')
            ax2.legend(loc='lower right')
        
        ax.set_title('Derivative Method Analysis')
        ax.set_xlabel('Number of Clusters (k)')
        ax.set_ylabel('WCSS')
        ax.legend(loc='upper right')
        ax.grid(True, alpha=0.3)
        
        # 3. Variance Method Visualization
        ax = axes[1, 0]
        ax.plot(k_values, wcss_scores, 'bo-', linewidth=2, markersize=8, label='WCSS')
        
        # Variance elbow point
        var_k = elbow_variance['elbow_k']
        var_idx = k_values.index(var_k)
        ax.plot(var_k, wcss_scores[var_idx], 'rs', markersize=15, markerfacecolor='purple', 
                markeredgecolor='indigo', markeredgewidth=2, label=f'Variance Elbow (k={var_k})')
        
        # ë¶„ì‚° ì‹œê°í™”
        if 'variances' in elbow_variance:
            variances = elbow_variance['variances']
            window_size = 3  # ê¸°ë³¸ê°’ (ì‹¤ì œ ê³„ì‚°ì—ì„œ ì‚¬ìš©ëœ ê°’ê³¼ ë§ì¶°ì•¼ í•¨)
            k_variance = k_values[window_size:-window_size]
            
            ax2 = ax.twinx()
            ax2.plot(k_variance, variances, 'g^-', alpha=0.6, markersize=6, label='Slope Variance')
            ax2.set_ylabel('Slope Variance', color='green')
            ax2.tick_params(axis='y', labelcolor='green')
            ax2.legend(loc='lower right')
        
        ax.set_title('Variance Method Analysis')
        ax.set_xlabel('Number of Clusters (k)')
        ax.set_ylabel('WCSS')
        ax.legend(loc='upper right')
        ax.grid(True, alpha=0.3)
        
        # 4. Method Comparison Summary
        ax = axes[1, 1]
        ax.axis('off')
        
        # ìš”ì•½ í…ìŠ¤íŠ¸
        summary_text = f"Elbow Method Analysis Summary\n\n"
        summary_text += f"Knee Method:\n"
        summary_text += f"  Optimal k: {elbow_knee['elbow_k']}\n"
        summary_text += f"  Confidence: {elbow_knee['confidence']:.4f}\n"
        summary_text += f"  WCSS: {elbow_knee['elbow_wcss']:.2f}\n\n"
        
        summary_text += f"Derivative Method:\n"
        summary_text += f"  Optimal k: {elbow_derivative['elbow_k']}\n"
        summary_text += f"  Confidence: {elbow_derivative['confidence']:.4f}\n"
        summary_text += f"  WCSS: {elbow_derivative['elbow_wcss']:.2f}\n\n"
        
        summary_text += f"Variance Method:\n"
        summary_text += f"  Optimal k: {elbow_variance['elbow_k']}\n"
        summary_text += f"  Confidence: {elbow_variance['confidence']:.4f}\n"
        summary_text += f"  WCSS: {elbow_variance['elbow_wcss']:.2f}\n\n"
        
        # ìµœê³  ë°©ë²•
        best_method = results['best_elbow_method']
        best_k = results['best_k_elbow']
        summary_text += f"ğŸ† BEST METHOD: {best_method.upper()}\n"
        summary_text += f"ğŸ¯ RECOMMENDED k: {best_k}\n\n"
        
        summary_text += f"Method Interpretations:\n"
        summary_text += f"â€¢ Knee: Maximum distance from reference line\n"
        summary_text += f"â€¢ Derivative: Maximum curvature change\n"
        summary_text += f"â€¢ Variance: Slope stabilization point\n"
        summary_text += f"â€¢ Higher confidence = more reliable"
        
        ax.text(0.1, 0.9, summary_text, transform=ax.transAxes, fontsize=11,
                verticalalignment='top', fontfamily='monospace',
                bbox=dict(boxstyle="round,pad=0.5", facecolor="lightyellow", alpha=0.8))
        
        plt.suptitle(f'Layer {layer_idx}: Detailed Elbow Method Analysis', 
                    fontsize=16, y=0.98)
        plt.tight_layout()
        plt.savefig(output_dir / f'layer_{layer_idx}_detailed_elbow_analysis.png', 
                dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_all_optimal_clustering_comparison(self, results, flattened_maps, labels, output_dir):
        """ëª¨ë“  ìµœì  k (Silhouette, CH, DB, Elbow)ì— ëŒ€í•œ í´ëŸ¬ìŠ¤í„° ë¶„í¬ ì‹œê°í™”"""
        layer_idx = results['layer_idx']
        best_k_sil = results['best_k_silhouette']
        best_k_ch = results['best_k_calinski_harabasz']
        best_k_db = results['best_k_davies_bouldin']
        best_k_elbow = results['best_k_elbow']
        
        # t-SNE ì°¨ì› ì¶•ì†Œ
        perplexity = min(30, len(flattened_maps)-1, max(1, len(flattened_maps)//3))
        tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity)
        tsne_embeddings = tsne.fit_transform(flattened_maps)
        
        # 2x3 ì„œë¸Œí”Œë¡¯ (Elbow ì¶”ê°€)
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        
        # 1. Silhouette ìµœì  k
        self._plot_single_clustering_result(
            tsne_embeddings, flattened_maps, labels, best_k_sil, 
            f'Silhouette Optimal (k={best_k_sil})', axes[0, 0]
        )
        
        # 2. Calinski-Harabasz ìµœì  k
        self._plot_single_clustering_result(
            tsne_embeddings, flattened_maps, labels, best_k_ch,
            f'Calinski-Harabasz Optimal (k={best_k_ch})', axes[0, 1]
        )
        
        # 3. Davies-Bouldin ìµœì  k
        self._plot_single_clustering_result(
            tsne_embeddings, flattened_maps, labels, best_k_db,
            f'Davies-Bouldin Optimal (k={best_k_db})', axes[0, 2]
        )
        
        # 4. Elbow Method ìµœì  k (NEW!)
        self._plot_single_clustering_result(
            tsne_embeddings, flattened_maps, labels, best_k_elbow,
            f'Elbow Method Optimal (k={best_k_elbow})', axes[1, 0]
        )
        
        # 5. ì‹¤ì œ ë¼ë²¨
        ax = axes[1, 1]
        unique_labels = np.unique(labels)
        label_colors = plt.cm.Set1(np.linspace(0, 1, len(unique_labels)))
        
        for i, label in enumerate(unique_labels):
            mask = labels == label
            marker = 'o' if label == 0 else 's'
            ax.scatter(tsne_embeddings[mask, 0], tsne_embeddings[mask, 1], 
                    c=[label_colors[i]], label=f'True Label {int(label)}', 
                    alpha=0.7, s=50, marker=marker)
        
        ax.set_title('True Labels')
        ax.set_xlabel('t-SNE Dimension 1')
        ax.set_ylabel('t-SNE Dimension 2')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 6. ë©”íŠ¸ë¦­ ë¹„êµ ìš”ì•½
        ax = axes[1, 2]
        ax.axis('off')
        
        # ëª¨ë“  ìµœì  k ë¹„êµ
        methods_k = {
            'Silhouette': best_k_sil,
            'Calinski-H': best_k_ch,
            'Davies-B': best_k_db,
            'Elbow': best_k_elbow
        }
        
        # ê° kê°’ì— ëŒ€í•œ ëª¨ë“  ë©”íŠ¸ë¦­ ìŠ¤ì½”ì–´ ê³„ì‚°
        comparison_text = f"Optimal k Comparison\n\n"
        
        for method, k_val in methods_k.items():
            k_metrics = results['results_by_k'][k_val]['metrics']
            sil_score = k_metrics['silhouette']['average_score']
            ch_score = k_metrics['calinski_harabasz']['score']
            db_score = k_metrics['davies_bouldin']['score']
            wcss = k_metrics['variance_analysis']['wcss']
            
            comparison_text += f"{method} (k={k_val}):\n"
            comparison_text += f"  Silhouette: {sil_score:.3f}\n"
            comparison_text += f"  Calinski-H: {ch_score:.1f}\n"
            comparison_text += f"  Davies-B: {db_score:.3f}\n"
            comparison_text += f"  WCSS: {wcss:.1f}\n\n"
        
        # ë©”íŠ¸ë¦­ ì¼ì¹˜ë„
        unique_ks = len(set(methods_k.values()))
        comparison_text += f"Method Agreement:\n"
        comparison_text += f"  Unique k values: {unique_ks}/4\n"
        
        if unique_ks == 1:
            comparison_text += f"  ğŸ¯ Perfect agreement!\n"
        elif unique_ks == 2:
            comparison_text += f"  âœ… Good agreement\n"
        elif unique_ks == 3:
            comparison_text += f"  âš ï¸ Mixed results\n"
        else:
            comparison_text += f"  âŒ No agreement\n"
        
        # ì¶”ì²œì‚¬í•­
        comparison_text += f"\nRecommendation:\n"
        most_common_k = max(set(methods_k.values()), key=list(methods_k.values()).count)
        comparison_text += f"Most common k: {most_common_k}\n"
        comparison_text += f"Elbow suggests: k={best_k_elbow}\n"
        
        # Elbow vs ë‹¤ë¥¸ ë©”íŠ¸ë¦­ ë¹„êµ
        if best_k_elbow == best_k_sil:
            comparison_text += f"âœ… Elbow agrees with Silhouette"
        else:
            comparison_text += f"âš ï¸ Elbow differs from Silhouette"
        
        ax.text(0.1, 0.9, comparison_text, transform=ax.transAxes, fontsize=10,
                verticalalignment='top', fontfamily='monospace',
                bbox=dict(boxstyle="round,pad=0.5", facecolor="lightgreen", alpha=0.8))
        
        plt.suptitle(f'Layer {layer_idx}: All Optimal Clustering Methods Comparison', 
                    fontsize=16, y=0.98)
        plt.tight_layout()
        plt.savefig(output_dir / f'layer_{layer_idx}_all_optimal_clustering_comparison.png', 
                dpi=300, bbox_inches='tight')
        plt.close()

    def _create_cross_layer_comparison_with_elbow(self, metrics_comparison, all_results, output_dir):
        """Elbow methodê°€ í¬í•¨ëœ ë ˆì´ì–´ê°„ ë©”íŠ¸ë¦­ ë¹„êµ ì‹œê°í™”"""
        layers = metrics_comparison['layers']
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        
        # 1. ë©”íŠ¸ë¦­ë³„ ìµœì  k ë¹„êµ (Elbow ì¶”ê°€)
        ax = axes[0, 0]
        sil_ks = [metrics_comparison['silhouette'][layer]['best_k'] for layer in layers]
        ch_ks = [metrics_comparison['calinski_harabasz'][layer]['best_k'] for layer in layers]
        db_ks = [metrics_comparison['davies_bouldin'][layer]['best_k'] for layer in layers]
        elbow_ks = [metrics_comparison['elbow'][layer]['best_k'] for layer in layers]
        
        x = np.arange(len(layers))
        width = 0.2
        
        ax.bar(x - 1.5*width, sil_ks, width, label='Silhouette', alpha=0.8)
        ax.bar(x - 0.5*width, ch_ks, width, label='Calinski-Harabasz', alpha=0.8)
        ax.bar(x + 0.5*width, db_ks, width, label='Davies-Bouldin', alpha=0.8)
        ax.bar(x + 1.5*width, elbow_ks, width, label='Elbow', alpha=0.8, color='red')
        
        ax.set_xlabel('Layer')
        ax.set_ylabel('Optimal k')
        ax.set_title('Optimal k by Different Metrics (Including Elbow)')
        ax.set_xticks(x)
        ax.set_xticklabels([f'Layer {layer}' for layer in layers])
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 2. Silhouette vs Elbow ìƒê´€ê´€ê³„
        ax = axes[0, 1]
        ax.scatter(sil_ks, elbow_ks, s=100, alpha=0.7, c=layers, cmap='viridis')
        for i, layer in enumerate(layers):
            ax.annotate(f'L{layer}', (sil_ks[i], elbow_ks[i]), xytext=(5, 5), 
                    textcoords='offset points', fontsize=10)
        
        ax.set_xlabel('Silhouette Optimal k')
        ax.set_ylabel('Elbow Optimal k')
        ax.set_title('Optimal k Correlation: Silhouette vs Elbow')
        ax.grid(True, alpha=0.3)
        
        # ëŒ€ê°ì„  ì°¸ì¡°ì„ 
        min_k = min(min(sil_ks), min(elbow_ks))
        max_k = max(max(sil_ks), max(elbow_ks))
        ax.plot([min_k, max_k], [min_k, max_k], 'r--', alpha=0.5, label='Perfect Agreement')
        ax.legend()
        
        # 3. Elbow Method Performance by Layer
        ax = axes[0, 2]
        elbow_confidences = [metrics_comparison['elbow'][layer]['confidence'] for layer in layers]
        elbow_methods = [metrics_comparison['elbow'][layer]['method'] for layer in layers]
        
        bars = ax.bar(layers, elbow_confidences, alpha=0.7, color='red')
        for i, (layer, conf, method, k_val) in enumerate(zip(layers, elbow_confidences, elbow_methods, elbow_ks)):
            ax.text(bars[i].get_x() + bars[i].get_width()/2, bars[i].get_height() + max(elbow_confidences)*0.02,
                f'{method}\nk={k_val}', ha='center', va='bottom', fontsize=9, fontweight='bold')
        
        ax.set_xlabel('Layer')
        ax.set_ylabel('Elbow Confidence Score')
        ax.set_title('Elbow Method Confidence by Layer')
        ax.grid(True, alpha=0.3)
        
        # 4. Method Agreement Analysis
        ax = axes[1, 0]
        
        # ê° ë ˆì´ì–´ë³„ ë©”íŠ¸ë¦­ ì¼ì¹˜ë„ ê³„ì‚°
        agreement_scores = []
        for layer in layers:
            layer_ks = [sil_ks[layers.index(layer)], ch_ks[layers.index(layer)], 
                    db_ks[layers.index(layer)], elbow_ks[layers.index(layer)]]
            unique_ks = len(set(layer_ks))
            agreement_score = (4 - unique_ks + 1) / 4  # 1.0 = perfect agreement, 0.25 = no agreement
            agreement_scores.append(agreement_score)
        
        bars = ax.bar(layers, agreement_scores, alpha=0.7, color='green')
        for i, (layer, score) in enumerate(zip(layers, agreement_scores)):
            ax.text(bars[i].get_x() + bars[i].get_width()/2, bars[i].get_height() + 0.02,
                f'{score:.2f}', ha='center', va='bottom', fontsize=10, fontweight='bold')
        
        ax.set_xlabel('Layer')
        ax.set_ylabel('Method Agreement Score')
        ax.set_title('Cross-Method Agreement by Layer')
        ax.set_ylim(0, 1.1)
        ax.grid(True, alpha=0.3)
        
        # 5. Silhouette Score vs Elbow Method
        ax = axes[1, 1]
        sil_scores = [metrics_comparison['silhouette'][layer]['best_score'] for layer in layers]
        
        # ìƒ‰ìƒì€ elbow confidenceë¡œ
        scatter = ax.scatter(sil_scores, elbow_ks, s=100, c=elbow_confidences, 
                            cmap='Reds', alpha=0.7, edgecolors='black')
        
        for i, layer in enumerate(layers):
            ax.annotate(f'L{layer}', (sil_scores[i], elbow_ks[i]), xytext=(5, 5), 
                    textcoords='offset points', fontsize=10)
        
        ax.set_xlabel('Best Silhouette Score')
        ax.set_ylabel('Elbow Optimal k')
        ax.set_title('Silhouette Quality vs Elbow Recommendation')
        ax.grid(True, alpha=0.3)
        
        # ì»¬ëŸ¬ë°”
        cbar = plt.colorbar(scatter, ax=ax)
        cbar.set_label('Elbow Confidence')
        
        # 6. ì¢…í•© ìš”ì•½ (Elbow í¬í•¨)
        ax = axes[1, 2]
        ax.axis('off')
        
        summary_text = "Comprehensive Analysis Summary\n(Including Elbow Method)\n\n"
        summary_text += f"Layers analyzed: {len(layers)}\n"
        summary_text += f"Metrics compared: 4 (Sil, CH, DB, Elbow)\n\n"
        
        # ì „ì²´ ë©”íŠ¸ë¦­ ì¼ì¹˜ë„ ë¶„ì„
        all_ks = sil_ks + ch_ks + db_ks + elbow_ks
        complete_agreement = sum(1 for i in range(len(layers)) 
                            if len(set([sil_ks[i], ch_ks[i], db_ks[i], elbow_ks[i]])) == 1)
        
        summary_text += f"Complete agreement: {complete_agreement}/{len(layers)} layers\n"
        summary_text += f"Avg agreement score: {np.mean(agreement_scores):.2f}\n\n"
        
        # Elbow vs Silhouette ì¼ì¹˜ë„
        elbow_sil_agreement = sum(1 for i in range(len(layers)) if sil_ks[i] == elbow_ks[i])
        summary_text += f"Elbow-Silhouette agreement: {elbow_sil_agreement}/{len(layers)}\n\n"
        
        # ìµœê³  ì„±ëŠ¥ ë ˆì´ì–´ë“¤
        best_sil_layer = layers[np.argmax(sil_scores)]
        best_elbow_conf_layer = layers[np.argmax(elbow_confidences)]
        best_agreement_layer = layers[np.argmax(agreement_scores)]
        
        summary_text += f"Best Silhouette: Layer {best_sil_layer}\n"
        summary_text += f"Most confident Elbow: Layer {best_elbow_conf_layer}\n"
        summary_text += f"Best agreement: Layer {best_agreement_layer}\n\n"
        
        # ìµœì¢… ì¶”ì²œ
        most_common_k = max(set(all_ks), key=all_ks.count)
        summary_text += f"ğŸ¯ FINAL RECOMMENDATIONS:\n"
        summary_text += f"Most frequent k: {most_common_k}\n"
        
        if elbow_sil_agreement >= len(layers) // 2:
            summary_text += f"âœ… Elbow & Silhouette agree\n"
            summary_text += f"Recommended: Use Elbow method"
        else:
            summary_text += f"âš ï¸ Mixed results across methods\n"
            summary_text += f"Recommended: Layer {best_agreement_layer}"
        
        ax.text(0.1, 0.9, summary_text, transform=ax.transAxes, fontsize=10,
                verticalalignment='top', fontfamily='monospace',
                bbox=dict(boxstyle="round,pad=0.5", facecolor="lightcyan", alpha=0.8))
        
        plt.suptitle('Cross-Layer Comprehensive Analysis (with Elbow Method)', 
                    fontsize=16, y=0.98)
        plt.tight_layout()
        plt.savefig(output_dir / 'comprehensive_cross_layer_analysis_with_elbow.png', 
                dpi=300, bbox_inches='tight')
        plt.close()

    # ê¸°ì¡´ _generate_comprehensive_summary ë©”ì„œë“œë¥¼ ìˆ˜ì •
    def _generate_comprehensive_summary_with_elbow(self, all_results, output_dir):
        """Elbow methodê°€ í¬í•¨ëœ ì „ì²´ ë ˆì´ì–´ ì¢…í•© ìš”ì•½"""
        layers = sorted([int(k.split('_')[1]) for k in all_results.keys()])
        
        # ë©”íŠ¸ë¦­ë³„ ìµœì  k ìˆ˜ì§‘ (Elbow ì¶”ê°€)
        metrics_comparison = {
            'silhouette': {},
            'calinski_harabasz': {},
            'davies_bouldin': {},
            'elbow': {},  # NEW!
            'layers': layers
        }
        
        for layer in layers:
            layer_key = f'layer_{layer}'
            result = all_results[layer_key]
            
            metrics_comparison['silhouette'][layer] = {
                'best_k': result['best_k_silhouette'],
                'best_score': result['best_silhouette_score']
            }
            metrics_comparison['calinski_harabasz'][layer] = {
                'best_k': result['best_k_calinski_harabasz'],
                'best_score': max([result['results_by_k'][k]['metrics']['calinski_harabasz']['score'] 
                                for k in result['k_values']])
            }
            metrics_comparison['davies_bouldin'][layer] = {
                'best_k': result['best_k_davies_bouldin'],
                'best_score': min([result['results_by_k'][k]['metrics']['davies_bouldin']['score'] 
                                for k in result['k_values']])
            }
            metrics_comparison['elbow'][layer] = {
                'best_k': result['best_k_elbow'],
                'method': result['best_elbow_method'],
                'confidence': max([result['elbow_analysis']['knee_method']['confidence'],
                                result['elbow_analysis']['derivative_method']['confidence'],
                                result['elbow_analysis']['variance_method']['confidence']])
            }
        
        # ì¢…í•© ë¹„êµ ì‹œê°í™” (Elbow í¬í•¨)
        self._create_cross_layer_comparison_with_elbow(metrics_comparison, all_results, output_dir)
        
        # ì¢…í•© ìš”ì•½ JSON ì €ì¥
        with open(output_dir / 'comprehensive_summary_with_elbow.json', 'w') as f:
            json.dump(metrics_comparison, f, indent=2)
        
        # Elbow í¬í•¨ ì¶”ì²œì‚¬í•­ ë¡œê·¸ ì¶œë ¥
        self._log_recommendations_with_elbow(metrics_comparison)

    def _log_recommendations_with_elbow(self, metrics_comparison):
        """Elbow methodê°€ í¬í•¨ëœ ì¶”ì²œì‚¬í•­ ë¡œê·¸ ì¶œë ¥"""
        layers = metrics_comparison['layers']
        
        logger.info("\n" + "="*80)
        logger.info("ğŸ¯ COMPREHENSIVE ANALYSIS RECOMMENDATIONS (WITH ELBOW METHOD)")
        logger.info("="*80)
        
        # ì‹¤ë£¨ì—£ ê¸°ì¤€ ìµœê³  ì„±ëŠ¥ ë ˆì´ì–´
        sil_scores = [metrics_comparison['silhouette'][layer]['best_score'] for layer in layers]
        best_sil_layer = layers[np.argmax(sil_scores)]
        best_sil_score = max(sil_scores)
        
        # Elbow ì‹ ë¢°ë„ ê¸°ì¤€ ìµœê³  ë ˆì´ì–´
        elbow_confidences = [metrics_comparison['elbow'][layer]['confidence'] for layer in layers]
        best_elbow_layer = layers[np.argmax(elbow_confidences)]
        best_elbow_confidence = max(elbow_confidences)
        
        logger.info(f"ğŸ“Š Best performing layer (Silhouette): Layer {best_sil_layer} (score: {best_sil_score:.4f})")
        logger.info(f"ğŸ”¥ Most confident Elbow layer: Layer {best_elbow_layer} (confidence: {best_elbow_confidence:.4f})")
        
        # ë©”íŠ¸ë¦­ë³„ ìµœì  k ì¼ì¹˜ë„ ë¶„ì„
        sil_ks = [metrics_comparison['silhouette'][layer]['best_k'] for layer in layers]
        ch_ks = [metrics_comparison['calinski_harabasz'][layer]['best_k'] for layer in layers]
        db_ks = [metrics_comparison['davies_bouldin'][layer]['best_k'] for layer in layers]
        elbow_ks = [metrics_comparison['elbow'][layer]['best_k'] for layer in layers]
        
        # ì™„ì „ ì¼ì¹˜ (ëª¨ë“  ë©”íŠ¸ë¦­ì´ ê°™ì€ k)
        complete_agreement = sum(1 for i in range(len(layers)) 
                            if len(set([sil_ks[i], ch_ks[i], db_ks[i], elbow_ks[i]])) == 1)
        
        # Elbow-Silhouette ì¼ì¹˜
        elbow_sil_agreement = sum(1 for i in range(len(layers)) if sil_ks[i] == elbow_ks[i])
        
        logger.info(f"ğŸ” Complete metric agreement: {complete_agreement}/{len(layers)} layers")
        logger.info(f"ğŸ¤ Elbow-Silhouette agreement: {elbow_sil_agreement}/{len(layers)} layers")
        
        # ê°€ì¥ ì¼ë°˜ì ì¸ ìµœì  k
        all_ks = sil_ks + ch_ks + db_ks + elbow_ks
        most_common_k = max(set(all_ks), key=all_ks.count)
        logger.info(f"ğŸ”¢ Most frequent optimal k across all metrics: {most_common_k}")
        
        # ë©”íŠ¸ë¦­ë³„ ìµœì  k ìš”ì•½
        logger.info(f"\nğŸ“ˆ Optimal k by metric:")
        for layer in layers:
            sil_k = metrics_comparison['silhouette'][layer]['best_k']
            ch_k = metrics_comparison['calinski_harabasz'][layer]['best_k']
            db_k = metrics_comparison['davies_bouldin'][layer]['best_k']
            elbow_k = metrics_comparison['elbow'][layer]['best_k']
            elbow_method = metrics_comparison['elbow'][layer]['method']
            logger.info(f"   Layer {layer}: Silhouette={sil_k}, CH={ch_k}, DB={db_k}, Elbow={elbow_k}({elbow_method})")
        
        # Elbow method ìƒì„¸ ë¶„ì„
        logger.info(f"\nğŸ”¥ ELBOW METHOD ANALYSIS:")
        for layer in layers:
            elbow_k = metrics_comparison['elbow'][layer]['best_k']
            elbow_method = metrics_comparison['elbow'][layer]['method']
            elbow_confidence = metrics_comparison['elbow'][layer]['confidence']
            logger.info(f"   Layer {layer}: k={elbow_k}, method={elbow_method}, confidence={elbow_confidence:.4f}")
        
        # ìµœì¢… ì¶”ì²œì‚¬í•­
        logger.info(f"\nğŸ¯ FINAL RECOMMENDATIONS:")
        
        if complete_agreement > 0:
            perfect_layers = [i for i in range(len(layers)) 
                            if len(set([sil_ks[i], ch_ks[i], db_ks[i], elbow_ks[i]])) == 1]
            logger.info(f"âœ… Layers with perfect agreement: {[layers[i] for i in perfect_layers]}")
            logger.info(f"âœ… Use k={sil_ks[perfect_layers[0]]} for these layers")
        
        if elbow_sil_agreement >= len(layers) // 2:
            logger.info(f"âœ… Elbow method mostly agrees with Silhouette - RELIABLE RESULTS")
            logger.info(f"ğŸ¯ PRIMARY RECOMMENDATION: Use Elbow method results")
        else:
            logger.info(f"âš ï¸ Mixed results between Elbow and Silhouette methods")
            logger.info(f"ğŸ¯ RECOMMENDATION: Focus on Layer {best_sil_layer} (best Silhouette)")
        
        # íŠ¹ë³„í•œ ì¼€ì´ìŠ¤ë“¤
        if best_sil_layer == best_elbow_layer:
            logger.info(f"ğŸŒŸ Layer {best_sil_layer} shows both best Silhouette AND most confident Elbow!")
        
        logger.info(f"ğŸ”¢ Conservative choice: k={most_common_k} (most frequent across all methods)")
        logger.info("="*80)

    # ë©”ì¸ ë¶„ì„ í•¨ìˆ˜ë„ ìˆ˜ì • í•„ìš”
    def analyze_all_layers_with_elbow(self, data_loader, k_range=(2, 15), output_dir=None):
        """
        ëª¨ë“  ë ˆì´ì–´ì— ëŒ€í•´ Elbow methodê°€ í¬í•¨ëœ ì¢…í•©ì ì¸ ë©”íŠ¸ë¦­ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        """
        if output_dir:
            output_dir = Path(output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)
        
        # Attention maps ì¶”ì¶œ
        logger.info("Extracting attention maps...")
        attention_data = self.extract_attention_maps(data_loader)
        
        # ëª¨ë“  ë ˆì´ì–´ ë¶„ì„ (Elbow í¬í•¨)
        all_results = {}
        for layer_idx in range(len(self.model.layers)):
            logger.info(f"\n{'='*60}")
            logger.info(f"Analyzing Layer {layer_idx} (WITH ELBOW METHOD)")
            logger.info(f"{'='*60}")
            
            layer_output_dir = output_dir / f'layer_{layer_idx}' if output_dir else None
            results = self.perform_comprehensive_analysis_with_elbow(  # ìƒˆë¡œìš´ í•¨ìˆ˜ ì‚¬ìš©
                attention_data, 
                layer_idx, 
                k_range=k_range,
                output_dir=layer_output_dir
            )
            all_results[f'layer_{layer_idx}'] = results
        
        # ì „ì²´ ìš”ì•½ ìƒì„± (Elbow í¬í•¨)
        if output_dir:
            self._generate_comprehensive_summary_with_elbow(all_results, output_dir)
        
        return all_results
    def _plot_detailed_silhouette_analysis(self, results, flattened_maps, output_dir):
        """ìƒì„¸ ì‹¤ë£¨ì—£ ë¶„ì„ (ê¸°ì¡´ ìŠ¤íƒ€ì¼ê³¼ ë™ì¼)"""
        layer_idx = results['layer_idx']
        best_k = results['best_k_silhouette']
        
        # ìµœì  kë¡œ í´ëŸ¬ìŠ¤í„°ë§
        np.random.seed(42)
        kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=10)
        cluster_labels = kmeans.fit_predict(flattened_maps)
        
        # ì‹¤ë£¨ì—£ ë¶„ì„
        silhouette_avg = silhouette_score(flattened_maps, cluster_labels)
        sample_silhouette_values = silhouette_samples(flattened_maps, cluster_labels)
        
        # ì‹¤ë£¨ì—£ í”Œë¡¯ ìƒì„±
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # 1. ì‹¤ë£¨ì—£ í”Œë¡¯
        y_lower = 10
        colors = plt.cm.nipy_spectral(np.linspace(0, 1, best_k))
        
        for i in range(best_k):
            ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]
            ith_cluster_silhouette_values.sort()
            
            size_cluster_i = ith_cluster_silhouette_values.shape[0]
            y_upper = y_lower + size_cluster_i
            
            ax1.fill_betweenx(np.arange(y_lower, y_upper),
                             0, ith_cluster_silhouette_values,
                             facecolor=colors[i], edgecolor=colors[i], alpha=0.7)
            
            ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))
            y_lower = y_upper + 10
        
        ax1.set_xlabel('Silhouette Coefficient Values')
        ax1.set_ylabel('Cluster Label')
        ax1.set_title(f'Silhouette Plot (k={best_k})')
        
        # í‰ê·  ì‹¤ë£¨ì—£ ìŠ¤ì½”ì–´ ë¼ì¸
        ax1.axvline(x=silhouette_avg, color="red", linestyle="--", 
                   label=f'Average Score: {silhouette_avg:.3f}')
        ax1.legend()
        
        # 2. í´ëŸ¬ìŠ¤í„°ë³„ í‰ê·  ì‹¤ë£¨ì—£ ìŠ¤ì½”ì–´
        cluster_avg_scores = []
        cluster_sizes = []
        
        for i in range(best_k):
            cluster_mask = cluster_labels == i
            cluster_sizes.append(np.sum(cluster_mask))
            cluster_avg_scores.append(np.mean(sample_silhouette_values[cluster_mask]))
        
        x_pos = np.arange(best_k)
        bars = ax2.bar(x_pos, cluster_avg_scores, color=colors, alpha=0.7)
        ax2.axhline(y=silhouette_avg, color="red", linestyle="--", 
                   label=f'Overall Average: {silhouette_avg:.3f}')
        
        # í´ëŸ¬ìŠ¤í„° í¬ê¸° ì •ë³´ ì¶”ê°€
        for i, (bar, size) in enumerate(zip(bars, cluster_sizes)):
            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'n={size}', ha='center', va='bottom', fontsize=9)
        
        ax2.set_xlabel('Cluster')
        ax2.set_ylabel('Average Silhouette Score')
        ax2.set_title('Average Silhouette Score per Cluster')
        ax2.set_xticks(x_pos)
        ax2.set_xticklabels([f'C{i}' for i in range(best_k)])
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        plt.suptitle(f'Layer {layer_idx}: Detailed Silhouette Analysis (k={best_k})', 
                    fontsize=16, y=1.02)
        plt.tight_layout()
        plt.savefig(output_dir / f'layer_{layer_idx}_detailed_silhouette.png', 
                   dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_optimal_clustering_comparison(self, results, flattened_maps, labels, output_dir):
        """ìµœì  kì— ëŒ€í•œ í´ëŸ¬ìŠ¤í„° ë¶„í¬ ì‹œê°í™”"""
        layer_idx = results['layer_idx']
        best_k_sil = results['best_k_silhouette']
        best_k_ch = results['best_k_calinski_harabasz']
        best_k_db = results['best_k_davies_bouldin']
        
        # t-SNE ì°¨ì› ì¶•ì†Œ
        perplexity = min(30, len(flattened_maps)-1, max(1, len(flattened_maps)//3))
        tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity)
        tsne_embeddings = tsne.fit_transform(flattened_maps)
        
        # ê° ë©”íŠ¸ë¦­ì˜ ìµœì  kë¡œ í´ëŸ¬ìŠ¤í„°ë§
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # 1. Silhouette ìµœì  k
        self._plot_single_clustering_result(
            tsne_embeddings, flattened_maps, labels, best_k_sil, 
            f'Silhouette Optimal (k={best_k_sil})', axes[0, 0]
        )
        
        # 2. Calinski-Harabasz ìµœì  k
        self._plot_single_clustering_result(
            tsne_embeddings, flattened_maps, labels, best_k_ch,
            f'Calinski-Harabasz Optimal (k={best_k_ch})', axes[0, 1]
        )
        
        # 3. Davies-Bouldin ìµœì  k
        self._plot_single_clustering_result(
            tsne_embeddings, flattened_maps, labels, best_k_db,
            f'Davies-Bouldin Optimal (k={best_k_db})', axes[1, 0]
        )
        
        # 4. ì‹¤ì œ ë¼ë²¨
        ax = axes[1, 1]
        unique_labels = np.unique(labels)
        label_colors = plt.cm.Set1(np.linspace(0, 1, len(unique_labels)))
        
        for i, label in enumerate(unique_labels):
            mask = labels == label
            marker = 'o' if label == 0 else 's'
            ax.scatter(tsne_embeddings[mask, 0], tsne_embeddings[mask, 1], 
                       c=[label_colors[i]], label=f'True Label {int(label)}', 
                       alpha=0.7, s=50, marker=marker)
        
        ax.set_title('True Labels')
        ax.set_xlabel('t-SNE Dimension 1')
        ax.set_ylabel('t-SNE Dimension 2')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        plt.suptitle(f'Layer {layer_idx}: Optimal Clustering Comparison', 
                    fontsize=16, y=0.98)
        plt.tight_layout()
        plt.savefig(output_dir / f'layer_{layer_idx}_optimal_clustering_comparison.png', 
                   dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_single_clustering_result(self, tsne_embeddings, flattened_maps, labels, k, title, ax):
        """ë‹¨ì¼ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ í”Œë¡¯"""
        # í´ëŸ¬ìŠ¤í„°ë§
        np.random.seed(42)
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        cluster_labels = kmeans.fit_predict(flattened_maps)
        
        # ì‹œê°í™”
        colors = plt.cm.tab10(np.linspace(0, 1, k))
        for i in range(k):
            mask = cluster_labels == i
            ax.scatter(tsne_embeddings[mask, 0], tsne_embeddings[mask, 1], 
                       c=[colors[i]], label=f'Cluster {i}', alpha=0.7, s=50)
        
        ax.set_title(title)
        ax.set_xlabel('t-SNE Dimension 1')
        ax.set_ylabel('t-SNE Dimension 2')
        if k <= 10:  # ë„ˆë¬´ ë§ì€ í´ëŸ¬ìŠ¤í„°ëŠ” ë²”ë¡€ ìƒëµ
            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)
        ax.grid(True, alpha=0.3)

    def analyze_all_layers(self, data_loader, k_range=(2, 15), output_dir=None):
        """
        ëª¨ë“  ë ˆì´ì–´ì— ëŒ€í•´ ì¢…í•©ì ì¸ ë©”íŠ¸ë¦­ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        Args:
            data_loader: ë°ì´í„°ë¡œë”
            k_range (tuple): í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ ë²”ìœ„
            output_dir (str, optional): ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        
        Returns:
            dict: ëª¨ë“  ë ˆì´ì–´ì˜ ë¶„ì„ ê²°ê³¼
        """
        if output_dir:
            output_dir = Path(output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)
        
        # Attention maps ì¶”ì¶œ
        logger.info("Extracting attention maps...")
        attention_data = self.extract_attention_maps(data_loader)
        
        # ëª¨ë“  ë ˆì´ì–´ ë¶„ì„
        all_results = {}
        for layer_idx in range(len(self.model.layers)):
            logger.info(f"\n{'='*60}")
            logger.info(f"Analyzing Layer {layer_idx}")
            logger.info(f"{'='*60}")
            
            layer_output_dir = output_dir / f'layer_{layer_idx}' if output_dir else None
            results = self.perform_comprehensive_analysis(
                attention_data, 
                layer_idx, 
                k_range=k_range,
                output_dir=layer_output_dir
            )
            all_results[f'layer_{layer_idx}'] = results
        
        # ì „ì²´ ìš”ì•½ ìƒì„±
        if output_dir:
            self._generate_comprehensive_summary(all_results, output_dir)
        
        return all_results

    def _generate_comprehensive_summary(self, all_results, output_dir):
        """ì „ì²´ ë ˆì´ì–´ ì¢…í•© ìš”ì•½"""
        layers = sorted([int(k.split('_')[1]) for k in all_results.keys()])
        
        # ë©”íŠ¸ë¦­ë³„ ìµœì  k ìˆ˜ì§‘
        metrics_comparison = {
            'silhouette': {},
            'calinski_harabasz': {},
            'davies_bouldin': {},
            'layers': layers
        }
        
        for layer in layers:
            layer_key = f'layer_{layer}'
            result = all_results[layer_key]
            
            metrics_comparison['silhouette'][layer] = {
                'best_k': result['best_k_silhouette'],
                'best_score': result['best_silhouette_score']
            }
            metrics_comparison['calinski_harabasz'][layer] = {
                'best_k': result['best_k_calinski_harabasz'],
                'best_score': max([result['results_by_k'][k]['metrics']['calinski_harabasz']['score'] 
                                 for k in result['k_values']])
            }
            metrics_comparison['davies_bouldin'][layer] = {
                'best_k': result['best_k_davies_bouldin'],
                'best_score': min([result['results_by_k'][k]['metrics']['davies_bouldin']['score'] 
                                 for k in result['k_values']])
            }
        
        # ì¢…í•© ë¹„êµ ì‹œê°í™”
        self._create_cross_layer_comparison_with_elbow(metrics_comparison, all_results, output_dir)
        
        # ì¢…í•© ìš”ì•½ JSON ì €ì¥
        with open(output_dir / 'comprehensive_summary.json', 'w') as f:
            json.dump(metrics_comparison, f, indent=2)
        
        # ì¶”ì²œì‚¬í•­ ë¡œê·¸ ì¶œë ¥
        self._log_recommendations(metrics_comparison)

    def _create_cross_layer_comparison(self, metrics_comparison, all_results, output_dir):
        """ë ˆì´ì–´ê°„ ë©”íŠ¸ë¦­ ë¹„êµ ì‹œê°í™”"""
        layers = metrics_comparison['layers']
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        
        # 1. ë©”íŠ¸ë¦­ë³„ ìµœì  k ë¹„êµ
        ax = axes[0, 0]
        sil_ks = [metrics_comparison['silhouette'][layer]['best_k'] for layer in layers]
        ch_ks = [metrics_comparison['calinski_harabasz'][layer]['best_k'] for layer in layers]
        db_ks = [metrics_comparison['davies_bouldin'][layer]['best_k'] for layer in layers]
        
        x = np.arange(len(layers))
        width = 0.25
        
        ax.bar(x - width, sil_ks, width, label='Silhouette', alpha=0.8)
        ax.bar(x, ch_ks, width, label='Calinski-Harabasz', alpha=0.8)
        ax.bar(x + width, db_ks, width, label='Davies-Bouldin', alpha=0.8)
        
        ax.set_xlabel('Layer')
        ax.set_ylabel('Optimal k')
        ax.set_title('Optimal k by Different Metrics')
        ax.set_xticks(x)
        ax.set_xticklabels([f'Layer {layer}' for layer in layers])
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 2. Silhouette ìŠ¤ì½”ì–´ ë¹„êµ
        ax = axes[0, 1]
        sil_scores = [metrics_comparison['silhouette'][layer]['best_score'] for layer in layers]
        ax.plot(layers, sil_scores, 'bo-', linewidth=2, markersize=8)
        for layer, score in zip(layers, sil_scores):
            ax.annotate(f'{score:.3f}', (layer, score), textcoords="offset points", 
                       xytext=(0,10), ha='center', fontsize=9)
        ax.set_xlabel('Layer')
        ax.set_ylabel('Best Silhouette Score')
        ax.set_title('Best Silhouette Score by Layer')
        ax.grid(True, alpha=0.3)
        
        # 3. Within/Between Variance ë¹„êµ
        ax = axes[0, 2]
        for layer in layers:
            layer_key = f'layer_{layer}'
            best_k = all_results[layer_key]['best_k_silhouette']
            variance_data = all_results[layer_key]['results_by_k'][best_k]['metrics']['variance_analysis']
            
            wcss = variance_data['wcss']
            bcss = variance_data['bcss']
            ratio = variance_data['bcss_wcss_ratio']
            
            ax.bar(layer - 0.2, wcss, 0.4, label='WCSS' if layer == layers[0] else "", alpha=0.7, color='red')
            ax.bar(layer + 0.2, bcss, 0.4, label='BCSS' if layer == layers[0] else "", alpha=0.7, color='blue')
        
        ax.set_xlabel('Layer')
        ax.set_ylabel('Sum of Squares')
        ax.set_title('WCSS vs BCSS by Layer (at optimal k)')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 4. ë©”íŠ¸ë¦­ ìƒê´€ê´€ê³„
        ax = axes[1, 0]
        
        # ì‹¤ë£¨ì—£ vs Calinski-Harabasz ìµœì  k ë¹„êµ
        ax.scatter(sil_ks, ch_ks, s=100, alpha=0.7, c=layers, cmap='viridis')
        for i, layer in enumerate(layers):
            ax.annotate(f'L{layer}', (sil_ks[i], ch_ks[i]), xytext=(5, 5), 
                       textcoords='offset points', fontsize=10)
        
        ax.set_xlabel('Silhouette Optimal k')
        ax.set_ylabel('Calinski-Harabasz Optimal k')
        ax.set_title('Optimal k Correlation: Silhouette vs CH')
        ax.grid(True, alpha=0.3)
        
        # ëŒ€ê°ì„  ì°¸ì¡°ì„ 
        min_k = min(min(sil_ks), min(ch_ks))
        max_k = max(max(sil_ks), max(ch_ks))
        ax.plot([min_k, max_k], [min_k, max_k], 'r--', alpha=0.5, label='Perfect Agreement')
        ax.legend()
        
        # 5. BCSS/WCSS ë¹„ìœ¨ ë¹„êµ
        ax = axes[1, 1]
        ratios = []
        for layer in layers:
            layer_key = f'layer_{layer}'
            best_k = all_results[layer_key]['best_k_silhouette']
            ratio = all_results[layer_key]['results_by_k'][best_k]['metrics']['variance_analysis']['bcss_wcss_ratio']
            ratios.append(ratio)
        
        bars = ax.bar(layers, ratios, alpha=0.7, color='green')
        for i, (layer, ratio) in enumerate(zip(layers, ratios)):
            ax.text(bars[i].get_x() + bars[i].get_width()/2, bars[i].get_height() + 0.01,
                   f'{ratio:.2f}', ha='center', va='bottom', fontsize=10)
        
        ax.set_xlabel('Layer')
        ax.set_ylabel('BCSS/WCSS Ratio')
        ax.set_title('Cluster Separation Quality by Layer')
        ax.grid(True, alpha=0.3)
        
        # 6. ìš”ì•½ í…ìŠ¤íŠ¸
        ax = axes[1, 2]
        ax.axis('off')
        
        summary_text = "Comprehensive Analysis Summary\n\n"
        summary_text += f"Layers analyzed: {len(layers)}\n"
        summary_text += f"Metrics compared: 3 (Silhouette, CH, DB)\n\n"
        
        # ë©”íŠ¸ë¦­ ì¼ì¹˜ë„ ë¶„ì„
        agreement_count = sum(1 for i in range(len(layers)) 
                            if sil_ks[i] == ch_ks[i] == db_ks[i])
        summary_text += f"Complete metric agreement: {agreement_count}/{len(layers)} layers\n\n"
        
        # ìµœê³  ì„±ëŠ¥ ë ˆì´ì–´
        best_sil_layer = layers[np.argmax(sil_scores)]
        best_ratio_layer = layers[np.argmax(ratios)]
        
        summary_text += f"Best Silhouette: Layer {best_sil_layer} ({max(sil_scores):.3f})\n"
        summary_text += f"Best BCSS/WCSS: Layer {best_ratio_layer} ({max(ratios):.3f})\n\n"
        
        # ì¶”ì²œì‚¬í•­
        summary_text += "Recommendations:\n"
        if agreement_count > len(layers) / 2:
            summary_text += "â€¢ High metric agreement - reliable clustering\n"
        else:
            summary_text += "â€¢ Mixed metric results - consider ensemble\n"
        
        most_common_k = max(set(sil_ks), key=sil_ks.count)
        summary_text += f"â€¢ Most common optimal k: {most_common_k}\n"
        summary_text += f"â€¢ Focus on Layer {best_sil_layer} for best clustering"
        
        ax.text(0.1, 0.9, summary_text, transform=ax.transAxes, fontsize=11,
                verticalalignment='top', fontfamily='monospace',
                bbox=dict(boxstyle="round,pad=0.5", facecolor="lightcyan", alpha=0.8))
        
        plt.suptitle('Cross-Layer Comprehensive Clustering Analysis', 
                    fontsize=16, y=0.98)
        plt.tight_layout()
        plt.savefig(output_dir / 'comprehensive_cross_layer_analysis.png', 
                   dpi=300, bbox_inches='tight')
        plt.close()

    def _log_recommendations(self, metrics_comparison):
        """ì¶”ì²œì‚¬í•­ ë¡œê·¸ ì¶œë ¥"""
        layers = metrics_comparison['layers']
        
        logger.info("\n" + "="*80)
        logger.info("ğŸ¯ COMPREHENSIVE ANALYSIS RECOMMENDATIONS")
        logger.info("="*80)
        
        # ì‹¤ë£¨ì—£ ê¸°ì¤€ ìµœê³  ì„±ëŠ¥ ë ˆì´ì–´
        sil_scores = [metrics_comparison['silhouette'][layer]['best_score'] for layer in layers]
        best_sil_layer = layers[np.argmax(sil_scores)]
        best_sil_score = max(sil_scores)
        
        logger.info(f"ğŸ“Š Best performing layer (Silhouette): Layer {best_sil_layer} (score: {best_sil_score:.4f})")
        
        # ë©”íŠ¸ë¦­ë³„ ìµœì  k ì¼ì¹˜ë„ ë¶„ì„
        sil_ks = [metrics_comparison['silhouette'][layer]['best_k'] for layer in layers]
        ch_ks = [metrics_comparison['calinski_harabasz'][layer]['best_k'] for layer in layers]
        db_ks = [metrics_comparison['davies_bouldin'][layer]['best_k'] for layer in layers]
        
        agreement_count = sum(1 for i in range(len(layers)) if sil_ks[i] == ch_ks[i] == db_ks[i])
        logger.info(f"ğŸ” Metric agreement: {agreement_count}/{len(layers)} layers show consistent optimal k")
        
        # ê°€ì¥ ì¼ë°˜ì ì¸ ìµœì  k
        all_ks = sil_ks + ch_ks + db_ks
        most_common_k = max(set(all_ks), key=all_ks.count)
        logger.info(f"ğŸ”¢ Most frequent optimal k across all metrics: {most_common_k}")
        
        # ë©”íŠ¸ë¦­ë³„ ìµœì  k ìš”ì•½
        logger.info(f"\nğŸ“ˆ Optimal k by metric:")
        for layer in layers:
            sil_k = metrics_comparison['silhouette'][layer]['best_k']
            ch_k = metrics_comparison['calinski_harabasz'][layer]['best_k']
            db_k = metrics_comparison['davies_bouldin'][layer]['best_k']
            logger.info(f"   Layer {layer}: Silhouette={sil_k}, CH={ch_k}, DB={db_k}")
        
        # ì‹¤ë£¨ì—£ ê²€ì¦
        logger.info(f"\nâœ… SILHOUETTE VERIFICATION:")
        for layer in layers:
            sil_score = metrics_comparison['silhouette'][layer]['best_score']
            sil_k = metrics_comparison['silhouette'][layer]['best_k']
            logger.info(f"   Layer {layer}: k={sil_k}, score={sil_score:.4f}")
        
        logger.info("="*80)


def main():
    parser = argparse.ArgumentParser(description='Comprehensive Clustering Metrics Analysis')
    parser.add_argument('--checkpoint_dir', type=str, required=True,
                       help='Path to model checkpoint')
    parser.add_argument('--mode', type=str, choices=['Full', 'Few'], default='Full',
                       help='Which model to use (Full or Few)')
    parser.add_argument('--min_k', type=int, default=2,
                       help='Minimum number of clusters to test (default: 2)')
    parser.add_argument('--max_k', type=int, default=50,
                       help='Maximum number of clusters to test (default: 15)')
    parser.add_argument('--output_dir', type=str, default=None,
                       help='Output directory for results')
    parser.add_argument('--layer_idx', type=int, default=None,
                       help='Specific layer to analyze (if not specified, analyze all layers)')
    
    args = parser.parse_args()
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    if args.output_dir is None:
        checkpoint_dir = Path(args.checkpoint_dir)
        path_parts = checkpoint_dir.parts
        
        # visualization í´ë” êµ¬ì¡°ì— ë§ê²Œ ì„¤ì •
        for i, part in enumerate(path_parts):
            if part == 'checkpoints':
                viz_parts = list(path_parts)
                viz_parts[i] = 'visualization'
                viz_path = Path(*viz_parts[:-1])  # best_model_epoch_XX.pt ì œì™¸
                args.output_dir = viz_path / 'comprehensive_metrics_analysis'
                break
        
        if args.output_dir is None:
            args.output_dir = checkpoint_dir / 'comprehensive_metrics_analysis'
    
    # Comprehensive Analyzer ì´ˆê¸°í™”
    analyzer = ComprehensiveClusteringAnalyzer(args.checkpoint_dir)
    
    # ë°ì´í„°ë¡œë” ì„ íƒ
    if args.mode == 'Full':
        #data_loader = analyzer.train_loader
        data_loader = analyzer.combined_loader
        logger.info("Using Full dataset loader")
    else:
        data_loader = analyzer.train_loader_few if hasattr(analyzer, 'train_loader_few') else analyzer.test_loader
        logger.info("Using Few-shot dataset loader")
    
    k_range = (args.min_k, args.max_k)
    
    if args.layer_idx is not None:
        # íŠ¹ì • ë ˆì´ì–´ë§Œ ë¶„ì„
        logger.info(f"Analyzing only Layer {args.layer_idx}")
        
        # Attention maps ì¶”ì¶œ
        attention_data = analyzer.extract_attention_maps(data_loader)
        
        # íŠ¹ì • ë ˆì´ì–´ ë¶„ì„
        layer_output_dir = Path(args.output_dir) / f'layer_{args.layer_idx}'
        results = analyzer.perform_comprehensive_analysis(
            attention_data, 
            args.layer_idx, 
            k_range=k_range,
            output_dir=layer_output_dir
        )
        
        logger.info(f"\nğŸ¯ Results for Layer {args.layer_idx}:")
        logger.info(f"   Silhouette optimal k: {results['best_k_silhouette']} (score: {results['best_silhouette_score']:.4f})")
        logger.info(f"   Calinski-Harabasz optimal k: {results['best_k_calinski_harabasz']}")
        logger.info(f"   Davies-Bouldin optimal k: {results['best_k_davies_bouldin']}")
        
    else:
        # ëª¨ë“  ë ˆì´ì–´ ë¶„ì„
        logger.info("Analyzing all layers with comprehensive metrics + ELBOW METHOD")
        all_results = analyzer.analyze_all_layers_with_elbow(
            data_loader, 
            k_range=k_range,
            output_dir=args.output_dir
        )
    
    logger.info(f"\nâœ… Comprehensive metrics analysis completed! Results saved to {args.output_dir}")


if __name__ == "__main__":
    main()
"""
Comprehensive Clustering Metrics Analysis

ê¸°ì¡´ ì‹¤ë£¨ì—£ ë¶„ì„ê³¼ ë™ì¼í•œ ê²°ê³¼ë¥¼ ë³´ì¥í•˜ë©´ì„œ 
within/between variance ë“± ë‹¤ì–‘í•œ í´ëŸ¬ìŠ¤í„°ë§ ë©”íŠ¸ë¦­ì„ ë¶„ì„í•©ë‹ˆë‹¤.

Usage:
    python analysis3.py --checkpoint_dir /path/to/checkpoint.pt --mode Full
"""

import os
# CUDA deterministic ì„¤ì •ì„ ê°€ì¥ ë¨¼ì € ì„¤ì •
os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'

import torch
import argparse
import numpy as np
import logging
from pathlib import Path
import json
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, silhouette_samples, calinski_harabasz_score, davies_bouldin_score
from sklearn.manifold import TSNE
import seaborn as sns
from scipy.spatial.distance import cdist

# ê¸°ì¡´ ëª¨ë“ˆë“¤ import
from models.TabularFLM import Model
from dataset.data_dataloaders import prepare_embedding_dataloaders, get_few_shot_embedding_samples
from utils.util import setup_logger, fix_seed

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def ensure_deterministic():
    """ì™„ì „í•œ deterministic ì„¤ì •"""
    # Random seeds
    np.random.seed(42)
    torch.manual_seed(42)
    torch.cuda.manual_seed(42)
    torch.cuda.manual_seed_all(42)
    
    # CUDA deterministic
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    torch.use_deterministic_algorithms(True)
    
    # Environment variables
    os.environ['PYTHONHASHSEED'] = '42'
    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'
    
    logger.info("âœ… Deterministic mode enabled")

class ComprehensiveClusteringAnalyzer:
    def __init__(self, checkpoint_dir, device='cuda'):
        """
        Args:
            checkpoint_dir (str): ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ
            device (str): 'cuda' ë˜ëŠ” 'cpu'
        """
        # Deterministic ì„¤ì • ë¨¼ì €
        ensure_deterministic()
        
        self.checkpoint_dir = checkpoint_dir
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        
        # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
        self.checkpoint = torch.load(checkpoint_dir, map_location=self.device)
        self.args = self.checkpoint['args']
        
        logger.info(f"Loaded checkpoint from {checkpoint_dir}")
        logger.info(f"Checkpoint epoch: {self.checkpoint['epoch']}, Val AUC: {self.checkpoint['val_auc']:.4f}")
        
        # ëª¨ë¸ ì´ˆê¸°í™” ë° ë¡œë“œ
        self._load_model()
        
        # ë°ì´í„°ë¡œë” ì¤€ë¹„
        self._prepare_dataloaders()
        
    def _load_model(self):
        """ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ ë¡œë“œ"""
        experiment_id = "comprehensive_analysis"
        mode = "analysis"
        
        self.model = Model(
            self.args, 
            self.args.input_dim, 
            self.args.hidden_dim, 
            self.args.output_dim, 
            self.args.num_layers, 
            self.args.dropout_rate, 
            self.args.llm_model,
            experiment_id,
            mode
        ).to(self.device)
        
        # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
        self.model.load_state_dict(self.checkpoint['model_state_dict'])
        self.model.eval()
        
        logger.info("Model loaded and set to evaluation mode")
    
    def _prepare_dataloaders(self):
        """ë°ì´í„°ë¡œë” ì¤€ë¹„ (deterministic)"""
        fix_seed(self.args.random_seed)
        
        # ì „ì²´ ë°ì´í„°ì…‹ ë¡œë” ì¤€ë¹„
        results = prepare_embedding_dataloaders(self.args, self.args.source_dataset_name)
        self.train_loader, self.val_loader, self.test_loader = results['loaders']
        self.num_classes = results['num_classes']
        
        # Few-shot ë¡œë” ì¤€ë¹„ (í•„ìš”í•œ ê²½ìš°)
        if hasattr(self.args, 'few_shot') and self.args.few_shot > 0:
            self.train_loader_few = get_few_shot_embedding_samples(self.train_loader, self.args)
        
        logger.info(f"Dataloaders prepared for dataset: {self.args.source_dataset_name}")
    
    def extract_attention_maps(self, data_loader):
        """
        ë°ì´í„°ë¡œë”ì—ì„œ attention maps ì¶”ì¶œ (deterministic)
        
        Args:
            data_loader: ë°ì´í„°ë¡œë”
            
        Returns:
            dict: ë ˆì´ì–´ë³„ attention mapsì™€ ë©”íƒ€ë°ì´í„°
        """
        attention_data = {
            'layer_0': [],
            'layer_1': [], 
            'layer_2': [],
            'labels': [],
            'sample_ids': [],
            'feature_names': None
        }
        
        sample_count = 0
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(data_loader):
                # ë°°ì¹˜ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
                batch_on_device = {
                    k: v.to(self.device) if isinstance(v, torch.Tensor) else v
                    for k, v in batch.items()
                }
                
                # ëª¨ë¸ forward (attention weights ì¶”ì¶œ)
                pred, attention_weights = self._extract_attention_from_model(batch_on_device)
                
                # Feature names ì¶”ì¶œ (ì²« ë²ˆì§¸ ë°°ì¹˜ì—ì„œë§Œ)
                if attention_data['feature_names'] is None:
                    feature_names = self.model.extract_feature_names(batch_on_device)
                    attention_data['feature_names'] = ["CLS"] + feature_names
                
                # ë°°ì¹˜ í¬ê¸° í™•ì¸
                batch_size = attention_weights[0].shape[0]
                
                for sample_idx in range(batch_size):
                    # ê° ë ˆì´ì–´ë³„ attention map ì €ì¥
                    for layer_idx, layer_attention in enumerate(attention_weights):
                        # Multi-head attentionì„ í‰ê· ë‚´ì–´ ë‹¨ì¼ attention mapìœ¼ë¡œ ë³€í™˜
                        attention_map = layer_attention[sample_idx].mean(dim=0)  # [seq_len, seq_len]
                        attention_numpy = attention_map.detach().cpu().numpy()
                        attention_data[f'layer_{layer_idx}'].append(attention_numpy)
                    
                    # ë¼ë²¨ê³¼ ìƒ˜í”Œ ID ì €ì¥
                    if 'y' in batch:
                        label = batch['y'][sample_idx].item()
                    else:
                        label = -1  # ë¼ë²¨ì´ ì—†ëŠ” ê²½ìš°
                    attention_data['labels'].append(label)
                    
                    # ìƒ˜í”Œ ID (ì‹¤ì œ ë°ì´í„°ì…‹ì˜ ì¸ë±ìŠ¤ ë˜ëŠ” ì¹´ìš´í„°)
                    if 'sample_ids' in batch:
                        sample_id = batch['sample_ids'][sample_idx]
                    else:
                        sample_id = sample_count
                    attention_data['sample_ids'].append(sample_id)
                    
                    sample_count += 1
                
                if batch_idx % 10 == 0:
                    logger.info(f"Processed {sample_count} samples...")
        
        logger.info(f"Extracted attention maps for {sample_count} samples")
        return attention_data
    
    def _extract_attention_from_model(self, batch):
        """
        ëª¨ë¸ì—ì„œ attention weightsì™€ ì˜ˆì¸¡ê°’ì„ ì¶”ì¶œ
        """
        # ëª¨ë¸ì˜ predict ë¡œì§ì„ ë³µì‚¬í•˜ë˜ attention_weightsë„ ë°˜í™˜
        label_description_embeddings = batch['label_description_embeddings'].to(self.device)
        desc_embeddings = [] 
        name_value_embeddings = [] 
        
        if all(k in batch for k in ['cat_name_value_embeddings', 'cat_desc_embeddings']):
            cat_name_value_embeddings = batch['cat_name_value_embeddings'].to(self.device).squeeze(-2)
            cat_desc_embeddings = batch['cat_desc_embeddings'].to(self.device).squeeze(-2)
            
            name_value_embeddings.append(cat_name_value_embeddings)
            desc_embeddings.append(cat_desc_embeddings)
            
        if all(k in batch for k in ['num_prompt_embeddings', 'num_desc_embeddings']):
            num_prompt_embeddings = batch['num_prompt_embeddings'].to(self.device).squeeze(-2)
            num_desc_embeddings = batch['num_desc_embeddings'].to(self.device).squeeze(-2)
            name_value_embeddings.append(num_prompt_embeddings)
            desc_embeddings.append(num_desc_embeddings)
            
        if not desc_embeddings or not name_value_embeddings:
            raise ValueError("No categorical or numerical features found in batch")

        desc_embeddings = torch.cat(desc_embeddings, dim = 1)
        name_value_embeddings = torch.cat(name_value_embeddings, dim = 1)
        
        # [CLS] Token ì¶”ê°€
        attention_weights = [] 
        cls_token = self.model.cls.expand(name_value_embeddings.size(0), -1, -1)
        name_value_embeddings = torch.cat([cls_token, name_value_embeddings], dim=1)
        x = name_value_embeddings
        
        # Graph Attention Layers
        for i, layer in enumerate(self.model.layers):
            norm_x = self.model.layer_norms[i](x)
            attn_output, attn_weights = layer(desc_embeddings, norm_x)
            attention_weights.append(attn_weights)
            x = x + attn_output
        
        # ì˜ˆì¸¡ê°’ ê³„ì‚°
        pred = x[:, 0, :]
        pred = self.model.predictor(pred)

        return pred, attention_weights

    def calculate_within_between_variance(self, data, cluster_labels):
        """
        Within-cluster Sum of Squares (WCSS)ì™€ Between-cluster Sum of Squares (BCSS) ê³„ì‚°
        
        Args:
            data: í´ëŸ¬ìŠ¤í„°ë§ ë°ì´í„° [n_samples, n_features]
            cluster_labels: í´ëŸ¬ìŠ¤í„° í• ë‹¹ ë¼ë²¨ [n_samples]
            
        Returns:
            dict: WCSS, BCSS, Total SS, ë¹„ìœ¨ ë“±ì˜ ë©”íŠ¸ë¦­
        """
        n_samples = len(data)
        k = len(np.unique(cluster_labels))
        
        # ì „ì²´ ë°ì´í„°ì˜ ì¤‘ì‹¬ì  (Grand Centroid)
        grand_centroid = np.mean(data, axis=0)
        
        # Total Sum of Squares (TSS)
        tss = np.sum((data - grand_centroid) ** 2)
        
        # Within-cluster Sum of Squares (WCSS)
        wcss = 0
        cluster_centroids = []
        cluster_sizes = []
        
        for cluster_id in np.unique(cluster_labels):
            cluster_mask = cluster_labels == cluster_id
            cluster_data = data[cluster_mask]
            cluster_centroid = np.mean(cluster_data, axis=0)
            cluster_centroids.append(cluster_centroid)
            cluster_sizes.append(len(cluster_data))
            
            # í´ëŸ¬ìŠ¤í„° ë‚´ ë¶„ì‚° ê³„ì‚°
            cluster_wcss = np.sum((cluster_data - cluster_centroid) ** 2)
            wcss += cluster_wcss
        
        cluster_centroids = np.array(cluster_centroids)
        cluster_sizes = np.array(cluster_sizes)
        
        # Between-cluster Sum of Squares (BCSS)
        bcss = 0
        for i, centroid in enumerate(cluster_centroids):
            bcss += cluster_sizes[i] * np.sum((centroid - grand_centroid) ** 2)
        
        # ê²€ì¦: TSS = WCSS + BCSS (ë°˜ë“œì‹œ ì„±ë¦½í•´ì•¼ í•¨)
        tss_check = wcss + bcss
        
        return {
            'wcss': float(wcss),
            'bcss': float(bcss),
            'tss': float(tss),
            'tss_check': float(tss_check),
            'bcss_wcss_ratio': float(bcss / wcss) if wcss > 0 else float('inf'),
            'explained_variance_ratio': float(bcss / tss) if tss > 0 else 0.0,
            'n_clusters': int(k),
            'n_samples': int(n_samples),
            'cluster_sizes': cluster_sizes.tolist(),
            'verification_error': float(abs(tss - tss_check))
        }

    def calculate_comprehensive_metrics(self, data, cluster_labels):
        """
        ëª¨ë“  í´ëŸ¬ìŠ¤í„°ë§ ë©”íŠ¸ë¦­ì„ ì¢…í•©ì ìœ¼ë¡œ ê³„ì‚°
        
        Args:
            data: í´ëŸ¬ìŠ¤í„°ë§ ë°ì´í„°
            cluster_labels: í´ëŸ¬ìŠ¤í„° í• ë‹¹ ë¼ë²¨
            
        Returns:
            dict: ëª¨ë“  ë©”íŠ¸ë¦­ ê²°ê³¼
        """
        metrics = {}
        
        # 1. Silhouette Metrics
        silhouette_avg = silhouette_score(data, cluster_labels)
        silhouette_samples_scores = silhouette_samples(data, cluster_labels)
        
        metrics['silhouette'] = {
            'average_score': float(silhouette_avg),
            'sample_scores': silhouette_samples_scores.tolist(),
            'min_score': float(np.min(silhouette_samples_scores)),
            'max_score': float(np.max(silhouette_samples_scores)),
            'std_score': float(np.std(silhouette_samples_scores))
        }
        
        # 2. Within/Between Variance Analysis
        variance_metrics = self.calculate_within_between_variance(data, cluster_labels)
        metrics['variance_analysis'] = variance_metrics
        
        # 3. Calinski-Harabasz Index (ë¶„ì‚°ë¹„ ê¸°ì¤€)
        ch_score = calinski_harabasz_score(data, cluster_labels)
        metrics['calinski_harabasz'] = {
            'score': float(ch_score),
            'interpretation': 'higher_is_better'
        }
        
        # 4. Davies-Bouldin Index
        db_score = davies_bouldin_score(data, cluster_labels)
        metrics['davies_bouldin'] = {
            'score': float(db_score),
            'interpretation': 'lower_is_better'
        }
        
        # 5. Inertia (K-means WCSS)
        kmeans_temp = KMeans(n_clusters=len(np.unique(cluster_labels)), random_state=42, n_init=1)
        kmeans_temp.fit(data)
        metrics['inertia'] = {
            'score': float(kmeans_temp.inertia_),
            'interpretation': 'lower_is_better'
        }
        
        # 6. Dunn Index (ìµœì†Œ inter-cluster distance / ìµœëŒ€ intra-cluster distance)
        dunn_score = self._calculate_dunn_index(data, cluster_labels)
        metrics['dunn_index'] = {
            'score': float(dunn_score),
            'interpretation': 'higher_is_better'
        }
        
        # 7. í´ëŸ¬ìŠ¤í„°ë³„ í†µê³„
        cluster_stats = self._calculate_cluster_statistics(data, cluster_labels)
        metrics['cluster_statistics'] = cluster_stats
        
        return metrics

    def _calculate_dunn_index(self, data, cluster_labels):
        """Dunn Index ê³„ì‚°"""
        unique_labels = np.unique(cluster_labels)
        
        # Inter-cluster distances (í´ëŸ¬ìŠ¤í„° ê°„ ìµœì†Œ ê±°ë¦¬)
        inter_cluster_distances = []
        for i in range(len(unique_labels)):
            for j in range(i + 1, len(unique_labels)):
                cluster_i = data[cluster_labels == unique_labels[i]]
                cluster_j = data[cluster_labels == unique_labels[j]]
                
                # ë‘ í´ëŸ¬ìŠ¤í„° ê°„ ëª¨ë“  ì ë“¤ì˜ ìµœì†Œ ê±°ë¦¬
                distances = cdist(cluster_i, cluster_j, metric='euclidean')
                min_distance = np.min(distances)
                inter_cluster_distances.append(min_distance)
        
        # Intra-cluster distances (í´ëŸ¬ìŠ¤í„° ë‚´ ìµœëŒ€ ê±°ë¦¬)
        intra_cluster_distances = []
        for label in unique_labels:
            cluster_data = data[cluster_labels == label]
            if len(cluster_data) > 1:
                distances = cdist(cluster_data, cluster_data, metric='euclidean')
                # ëŒ€ê°ì„  ì œì™¸í•˜ê³  ìµœëŒ€ ê±°ë¦¬
                np.fill_diagonal(distances, 0)
                max_distance = np.max(distances)
                intra_cluster_distances.append(max_distance)
        
        if len(inter_cluster_distances) == 0 or len(intra_cluster_distances) == 0:
            return 0.0
        
        min_inter = np.min(inter_cluster_distances)
        max_intra = np.max(intra_cluster_distances)
        
        return min_inter / max_intra if max_intra > 0 else 0.0

    def _calculate_cluster_statistics(self, data, cluster_labels):
        """í´ëŸ¬ìŠ¤í„°ë³„ ì„¸ë¶€ í†µê³„ ê³„ì‚°"""
        unique_labels = np.unique(cluster_labels)
        cluster_stats = {}
        
        for label in unique_labels:
            cluster_data = data[cluster_labels == label]
            centroid = np.mean(cluster_data, axis=0)
            
            # í´ëŸ¬ìŠ¤í„° ë‚´ ê±°ë¦¬ë“¤
            if len(cluster_data) > 1:
                distances_to_centroid = np.linalg.norm(cluster_data - centroid, axis=1)
                intra_cluster_distances = cdist(cluster_data, cluster_data, metric='euclidean')
                np.fill_diagonal(intra_cluster_distances, np.inf)  # ìê¸° ìì‹  ì œì™¸
                
                cluster_stats[f'cluster_{label}'] = {
                    'size': int(len(cluster_data)),
                    'centroid': centroid.tolist(),
                    'mean_distance_to_centroid': float(np.mean(distances_to_centroid)),
                    'max_distance_to_centroid': float(np.max(distances_to_centroid)),
                    'std_distance_to_centroid': float(np.std(distances_to_centroid)),
                    'min_intra_distance': float(np.min(intra_cluster_distances)),
                    'mean_intra_distance': float(np.mean(intra_cluster_distances[intra_cluster_distances != np.inf])),
                    'max_intra_distance': float(np.max(intra_cluster_distances[intra_cluster_distances != np.inf]))
                }
            else:
                cluster_stats[f'cluster_{label}'] = {
                    'size': 1,
                    'centroid': centroid.tolist(),
                    'mean_distance_to_centroid': 0.0,
                    'max_distance_to_centroid': 0.0,
                    'std_distance_to_centroid': 0.0,
                    'min_intra_distance': 0.0,
                    'mean_intra_distance': 0.0,
                    'max_intra_distance': 0.0
                }
        
        return cluster_stats

    def perform_comprehensive_analysis(self, attention_data, layer_idx, k_range=(2, 15), output_dir=None):
        """
        íŠ¹ì • ë ˆì´ì–´ì— ëŒ€í•´ ì¢…í•©ì ì¸ í´ëŸ¬ìŠ¤í„°ë§ ë©”íŠ¸ë¦­ ë¶„ì„ ìˆ˜í–‰
        
        Args:
            attention_data (dict): attention maps ë°ì´í„°
            layer_idx (int): ë¶„ì„í•  ë ˆì´ì–´ ì¸ë±ìŠ¤
            k_range (tuple): í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ ë²”ìœ„ (min_k, max_k)
            output_dir (str, optional): ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        
        Returns:
            dict: ì¢…í•© ë¶„ì„ ê²°ê³¼
        """
        if output_dir:
            output_dir = Path(output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)
        
        # íŠ¹ì • ë ˆì´ì–´ì˜ attention maps ì¶”ì¶œ
        attention_maps = np.stack(attention_data[f'layer_{layer_idx}'])
        labels = np.array(attention_data['labels'])
        feature_names = attention_data['feature_names']
        
        logger.info(f"Performing comprehensive analysis on layer {layer_idx} with {len(attention_maps)} samples")
        logger.info(f"Testing cluster range: {k_range[0]} to {k_range[1]}")
        
        # í‰íƒ„í™” (ë²¡í„°í™”)
        flattened_maps = attention_maps.reshape(len(attention_maps), -1)
        
        min_k, max_k = k_range
        k_values = list(range(min_k, max_k + 1))
        
        # ê° kê°’ì— ëŒ€í•´ ëª¨ë“  ë©”íŠ¸ë¦­ ê³„ì‚°
        comprehensive_results = {
            'layer_idx': layer_idx,
            'k_values': k_values,
            'feature_names': feature_names,
            'results_by_k': {}
        }
        
        for k in k_values:
            logger.info(f"Testing k={k}...")
            
            # Deterministic K-means
            np.random.seed(42)  # KMeans ë‚´ë¶€ ì´ˆê¸°í™”ë¥¼ ìœ„í•œ ì¶”ê°€ ì‹œë“œ
            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10, algorithm='lloyd')
            cluster_labels = kmeans.fit_predict(flattened_maps)
            
            # ëª¨ë“  ë©”íŠ¸ë¦­ ê³„ì‚°
            all_metrics = self.calculate_comprehensive_metrics(flattened_maps, cluster_labels)
            
            # ê²°ê³¼ ì €ì¥
            comprehensive_results['results_by_k'][k] = {
                'cluster_assignments': cluster_labels.tolist(),
                'metrics': all_metrics,
                'kmeans_centers': kmeans.cluster_centers_.tolist()
            }
            
            # ì£¼ìš” ë©”íŠ¸ë¦­ ë¡œê·¸ ì¶œë ¥
            silhouette = all_metrics['silhouette']['average_score']
            ch_score = all_metrics['calinski_harabasz']['score']
            db_score = all_metrics['davies_bouldin']['score']
            wcss = all_metrics['variance_analysis']['wcss']
            bcss = all_metrics['variance_analysis']['bcss']
            
            logger.info(f"k={k}: Silhouette={silhouette:.4f}, CH={ch_score:.2f}, DB={db_score:.4f}, WCSS={wcss:.2f}, BCSS={bcss:.2f}")
        
        # ìµœì  k ê²°ì • (ì‹¤ë£¨ì—£ ê¸°ì¤€ìœ¼ë¡œ ê¸°ì¡´ê³¼ ë™ì¼)
        silhouette_scores = [comprehensive_results['results_by_k'][k]['metrics']['silhouette']['average_score'] for k in k_values]
        best_k_idx = np.argmax(silhouette_scores)
        best_k = k_values[best_k_idx]
        best_score = silhouette_scores[best_k_idx]
        
        comprehensive_results['best_k_silhouette'] = best_k
        comprehensive_results['best_silhouette_score'] = best_score
        
        # ë‹¤ë¥¸ ë©”íŠ¸ë¦­ ê¸°ì¤€ ìµœì  kë„ ê³„ì‚°
        ch_scores = [comprehensive_results['results_by_k'][k]['metrics']['calinski_harabasz']['score'] for k in k_values]
        db_scores = [comprehensive_results['results_by_k'][k]['metrics']['davies_bouldin']['score'] for k in k_values]
        
        comprehensive_results['best_k_calinski_harabasz'] = k_values[np.argmax(ch_scores)]
        comprehensive_results['best_k_davies_bouldin'] = k_values[np.argmin(db_scores)]
        
        logger.info(f"ğŸ¯ Best k for layer {layer_idx}:")
        logger.info(f"   Silhouette: k={comprehensive_results['best_k_silhouette']} (score: {best_score:.4f})")
        logger.info(f"   Calinski-Harabasz: k={comprehensive_results['best_k_calinski_harabasz']} (score: {max(ch_scores):.2f})")
        logger.info(f"   Davies-Bouldin: k={comprehensive_results['best_k_davies_bouldin']} (score: {min(db_scores):.4f})")
        
        # ì‹œê°í™” ìƒì„±
        if output_dir:
            self._create_comprehensive_visualizations(comprehensive_results, flattened_maps, labels, output_dir)
            
            # ê²°ê³¼ JSON ì €ì¥
            results_json = comprehensive_results.copy()
            results_json['feature_names'] = list(feature_names)  # numpy arrayë¥¼ listë¡œ ë³€í™˜
            
            with open(output_dir / f'layer_{layer_idx}_comprehensive_results.json', 'w') as f:
                json.dump(results_json, f, indent=2)
            
            logger.info(f"âœ… Comprehensive analysis results saved to {output_dir}")
        
        return comprehensive_results

    def _create_comprehensive_visualizations(self, results, flattened_maps, labels, output_dir):
        """ì¢…í•©ì ì¸ ì‹œê°í™” ìƒì„±"""
        layer_idx = results['layer_idx']
        k_values = results['k_values']
        
        # 1. ëª¨ë“  ë©”íŠ¸ë¦­ ë¹„êµ í”Œë¡¯
        self._plot_all_metrics_comparison(results, output_dir)
        
        # 2. Within/Between Variance ìƒì„¸ ë¶„ì„
        self._plot_variance_analysis(results, output_dir)
        
        # 3. ì‹¤ë£¨ì—£ ë¶„ì„ ìƒì„¸ (ê¸°ì¡´ê³¼ ë™ì¼í•œ ìŠ¤íƒ€ì¼)
        self._plot_detailed_silhouette_analysis(results, flattened_maps, output_dir)
        
        # 4. ìµœì  kì— ëŒ€í•œ í´ëŸ¬ìŠ¤í„° ë¶„í¬ ì‹œê°í™”
        self._plot_optimal_clustering_comparison(results, flattened_maps, labels, output_dir)

    def _plot_all_metrics_comparison(self, results, output_dir):
        """ëª¨ë“  ë©”íŠ¸ë¦­ ë¹„êµ í”Œë¡¯"""
        k_values = results['k_values']
        layer_idx = results['layer_idx']
        
        # ë©”íŠ¸ë¦­ ë°ì´í„° ì¶”ì¶œ
        silhouette_scores = [results['results_by_k'][k]['metrics']['silhouette']['average_score'] for k in k_values]
        ch_scores = [results['results_by_k'][k]['metrics']['calinski_harabasz']['score'] for k in k_values]
        db_scores = [results['results_by_k'][k]['metrics']['davies_bouldin']['score'] for k in k_values]
        wcss_scores = [results['results_by_k'][k]['metrics']['variance_analysis']['wcss'] for k in k_values]
        bcss_scores = [results['results_by_k'][k]['metrics']['variance_analysis']['bcss'] for k in k_values]
        dunn_scores = [results['results_by_k'][k]['metrics']['dunn_index']['score'] for k in k_values]
        
        # 2x3 ì„œë¸Œí”Œë¡¯
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        
        # 1. Silhouette Score
        ax = axes[0, 0]
        ax.plot(k_values, silhouette_scores, 'bo-', linewidth=2, markersize=8)
        best_k_sil = results['best_k_silhouette']
        best_idx = k_values.index(best_k_sil)
        ax.plot(best_k_sil, silhouette_scores[best_idx], 'ro', markersize=12, markerfacecolor='red')
        ax.set_title('Silhouette Score')
        ax.set_xlabel('Number of Clusters (k)')
        ax.set_ylabel('Silhouette Score')
        ax.grid(True, alpha=0.3)
        ax.axvline(x=best_k_sil, color='red', linestyle='--', alpha=0.7)
        
        # 2. Calinski-Harabasz Index
        ax = axes[0, 1]
        ax.plot(k_values, ch_scores, 'go-', linewidth=2, markersize=8)
        best_k_ch = results['best_k_calinski_harabasz']
        best_idx_ch = k_values.index(best_k_ch)
        ax.plot(best_k_ch, ch_scores[best_idx_ch], 'ro', markersize=12, markerfacecolor='red')
        ax.set_title('Calinski-Harabasz Index')
        ax.set_xlabel('Number of Clusters (k)')
        ax.set_ylabel('CH Score')
        ax.grid(True, alpha=0.3)
        ax.axvline(x=best_k_ch, color='red', linestyle='--', alpha=0.7)
        
        # 3. Davies-Bouldin Index
        ax = axes[0, 2]
        ax.plot(k_values, db_scores, 'mo-', linewidth=2, markersize=8)
        best_k_db = results['best_k_davies_bouldin']
        best_idx_db = k_values.index(best_k_db)
        ax.plot(best_k_db, db_scores[best_idx_db], 'ro', markersize=12, markerfacecolor='red')
        ax.set_title('Davies-Bouldin Index (Lower is Better)')
        ax.set_xlabel('Number of Clusters (k)')
        ax.set_ylabel('DB Score')
        ax.grid(True, alpha=0.3)
        ax.axvline(x=best_k_db, color='red', linestyle='--', alpha=0.7)
        
        # 4. WCSS (Within-cluster Sum of Squares)
        ax = axes[1, 0]
        ax.plot(k_values, wcss_scores, 'co-', linewidth=2, markersize=8)
        ax.set_title('Within-Cluster Sum of Squares (WCSS)')
        ax.set_xlabel('Number of Clusters (k)')
        ax.set_ylabel('WCSS')
        ax.grid(True, alpha=0.3)
        # WCSSëŠ” í•­ìƒ ê°ì†Œí•˜ë¯€ë¡œ íŠ¹ì • ìµœì ì  í‘œì‹œ ì•ˆí•¨
        
        # 5. BCSS (Between-cluster Sum of Squares)
        ax = axes[1, 1]
        ax.plot(k_values, bcss_scores, 'yo-', linewidth=2, markersize=8)
        ax.set_title('Between-Cluster Sum of Squares (BCSS)')
        ax.set_xlabel('Number of Clusters (k)')
        ax.set_ylabel('BCSS')
        ax.grid(True, alpha=0.3)
        
        # 6. Dunn Index
        ax = axes[1, 2]
        ax.plot(k_values, dunn_scores, 'ko-', linewidth=2, markersize=8)
        ax.set_title('Dunn Index (Higher is Better)')
        ax.set_xlabel('Number of Clusters (k)')
        ax.set_ylabel('Dunn Index')
        ax.grid(True, alpha=0.3)
        
        # ì „ì²´ ì œëª©
        plt.suptitle(f'Layer {layer_idx}: Comprehensive Clustering Metrics Comparison', 
                    fontsize=16, y=0.98)
        plt.tight_layout()
        plt.savefig(output_dir / f'layer_{layer_idx}_all_metrics_comparison.png', 
                   dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_variance_analysis(self, results, output_dir):
        """Within/Between Variance ìƒì„¸ ë¶„ì„ í”Œë¡¯"""
        k_values = results['k_values']
        layer_idx = results['layer_idx']
        
        # ë¶„ì‚° ê´€ë ¨ ë°ì´í„° ì¶”ì¶œ
        wcss_scores = [results['results_by_k'][k]['metrics']['variance_analysis']['wcss'] for k in k_values]
        bcss_scores = [results['results_by_k'][k]['metrics']['variance_analysis']['bcss'] for k in k_values]
        tss_scores = [results['results_by_k'][k]['metrics']['variance_analysis']['tss'] for k in k_values]
        bcss_wcss_ratios = [results['results_by_k'][k]['metrics']['variance_analysis']['bcss_wcss_ratio'] for k in k_values]
        explained_variance_ratios = [results['results_by_k'][k]['metrics']['variance_analysis']['explained_variance_ratio'] for k in k_values]
        
        # 2x2 ì„œë¸Œí”Œë¡¯
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # 1. WCSS vs BCSS
        ax = axes[0, 0]
        ax.plot(k_values, wcss_scores, 'b-', label='WCSS (Within)', linewidth=2, marker='o')
        ax.plot(k_values, bcss_scores, 'r-', label='BCSS (Between)', linewidth=2, marker='s')
        ax.plot(k_values, tss_scores, 'g--', label='TSS (Total)', linewidth=2, marker='^')
        ax.set_title('Variance Decomposition: WCSS vs BCSS vs TSS')
        ax.set_xlabel('Number of Clusters (k)')
        ax.set_ylabel('Sum of Squares')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 2. BCSS/WCSS ë¹„ìœ¨
        ax = axes[0, 1]
        ax.plot(k_values, bcss_wcss_ratios, 'mo-', linewidth=2, markersize=8)
        ax.set_title('BCSS/WCSS Ratio (Higher is Better)')
        ax.set_xlabel('Number of Clusters (k)')
        ax.set_ylabel('BCSS/WCSS Ratio')
        ax.grid(True, alpha=0.3)
        
        # ìµœëŒ€ ë¹„ìœ¨ ì§€ì  í‘œì‹œ
        max_ratio_idx = np.argmax(bcss_wcss_ratios)
        max_ratio_k = k_values[max_ratio_idx]
        ax.plot(max_ratio_k, bcss_wcss_ratios[max_ratio_idx], 'ro', markersize=12)
        ax.axvline(x=max_ratio_k, color='red', linestyle='--', alpha=0.7)
        
        # 3. Explained Variance Ratio
        ax = axes[1, 0]
        ax.plot(k_values, explained_variance_ratios, 'co-', linewidth=2, markersize=8)
        ax.set_title('Explained Variance Ratio (BCSS/TSS)')
        ax.set_xlabel('Number of Clusters (k)')
        ax.set_ylabel('Explained Variance Ratio')
        ax.grid(True, alpha=0.3)
        ax.set_ylim(0, 1)
        
        # 4. Variance í†µê³„ ìš”ì•½
        ax = axes[1, 1]
        ax.axis('off')
        
        # í†µê³„ í…ìŠ¤íŠ¸ ìƒì„±
        best_k_sil = results['best_k_silhouette']
        best_k_idx = k_values.index(best_k_sil)
        
        variance_stats = results['results_by_k'][best_k_sil]['metrics']['variance_analysis']
        
        stats_text = f"Variance Analysis Summary (Best k={best_k_sil})\n\n"
        stats_text += f"WCSS (Within-cluster): {variance_stats['wcss']:.2f}\n"
        stats_text += f"BCSS (Between-cluster): {variance_stats['bcss']:.2f}\n"
        stats_text += f"TSS (Total): {variance_stats['tss']:.2f}\n"
        stats_text += f"BCSS/WCSS Ratio: {variance_stats['bcss_wcss_ratio']:.3f}\n"
        stats_text += f"Explained Variance: {variance_stats['explained_variance_ratio']:.3f}\n\n"
        
        # ë‹¤ë¥¸ kê°’ë“¤ê³¼ ë¹„êµ
        max_ratio_k = k_values[np.argmax(bcss_wcss_ratios)]
        max_explained_k = k_values[np.argmax(explained_variance_ratios)]
        
        stats_text += f"Best BCSS/WCSS Ratio: k={max_ratio_k} ({max(bcss_wcss_ratios):.3f})\n"
        stats_text += f"Best Explained Variance: k={max_explained_k} ({max(explained_variance_ratios):.3f})\n\n"
        
        # í•´ì„
        stats_text += "Interpretation:\n"
        stats_text += "â€¢ Higher BCSS/WCSS = Better separation\n"
        stats_text += "â€¢ Higher Explained Variance = Better clustering\n"
        stats_text += "â€¢ WCSS â†“, BCSS â†‘ = Ideal clustering"
        
        ax.text(0.1, 0.9, stats_text, transform=ax.transAxes, fontsize=11,
                verticalalignment='top', fontfamily='monospace',
                bbox=dict(boxstyle="round,pad=0.5", facecolor="lightblue", alpha=0.8))
        
        plt.suptitle(f'Layer {layer_idx}: Within/Between Variance Analysis', 
                    fontsize=16, y=0.98)
        plt.tight_layout()
        plt.savefig(output_dir / f'layer_{layer_idx}_variance_analysis.png', 
                   dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_detailed_silhouette_analysis(self, results, flattened_maps, output_dir):
        """ìƒì„¸ ì‹¤ë£¨ì—£ ë¶„ì„ (ê¸°ì¡´ ìŠ¤íƒ€ì¼ê³¼ ë™ì¼)"""
        layer_idx = results['layer_idx']
        best_k = results['best_k_silhouette']
        
        # ìµœì  kë¡œ í´ëŸ¬ìŠ¤í„°ë§
        np.random.seed(42)
        kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=10)
        cluster_labels = kmeans.fit_predict(flattened_maps)
        
        # ì‹¤ë£¨ì—£ ë¶„ì„
        silhouette_avg = silhouette_score(flattened_maps, cluster_labels)
        sample_silhouette_values = silhouette_samples(flattened_maps, cluster_labels)
        
        # ì‹¤ë£¨ì—£ í”Œë¡¯ ìƒì„±
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # 1. ì‹¤ë£¨ì—£ í”Œë¡¯
        y_lower = 10
        colors = plt.cm.nipy_spectral(np.linspace(0, 1, best_k))
        
        for i in range(best_k):
            ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]
            ith_cluster_silhouette_values.sort()
            
            size_cluster_i = ith_cluster_silhouette_values.shape[0]
            y_upper = y_lower + size_cluster_i
            
            ax1.fill_betweenx(np.arange(y_lower, y_upper),
                             0, ith_cluster_silhouette_values,
                             facecolor=colors[i], edgecolor=colors[i], alpha=0.7)
            
            ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))
            y_lower = y_upper + 10
        
        ax1.set_xlabel('Silhouette Coefficient Values')
        ax1.set_ylabel('Cluster Label')
        ax1.set_title(f'Silhouette Plot (k={best_k})')
        
        # í‰ê·  ì‹¤ë£¨ì—£ ìŠ¤ì½”ì–´ ë¼ì¸
        ax1.axvline(x=silhouette_avg, color="red", linestyle="--", 
                   label=f'Average Score: {silhouette_avg:.3f}')
        ax1.legend()
        
        # 2. í´ëŸ¬ìŠ¤í„°ë³„ í‰ê·  ì‹¤ë£¨ì—£ ìŠ¤ì½”ì–´
        cluster_avg_scores = []
        cluster_sizes = []
        
        for i in range(best_k):
            cluster_mask = cluster_labels == i
            cluster_sizes.append(np.sum(cluster_mask))
            cluster_avg_scores.append(np.mean(sample_silhouette_values[cluster_mask]))
        
        x_pos = np.arange(best_k)
        bars = ax2.bar(x_pos, cluster_avg_scores, color=colors, alpha=0.7)
        ax2.axhline(y=silhouette_avg, color="red", linestyle="--", 
                   label=f'Overall Average: {silhouette_avg:.3f}')
        
        # í´ëŸ¬ìŠ¤í„° í¬ê¸° ì •ë³´ ì¶”ê°€
        for i, (bar, size) in enumerate(zip(bars, cluster_sizes)):
            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'n={size}', ha='center', va='bottom', fontsize=9)
        
        ax2.set_xlabel('Cluster')
        ax2.set_ylabel('Average Silhouette Score')
        ax2.set_title('Average Silhouette Score per Cluster')
        ax2.set_xticks(x_pos)
        ax2.set_xticklabels([f'C{i}' for i in range(best_k)])
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        plt.suptitle(f'Layer {layer_idx}: Detailed Silhouette Analysis (k={best_k})', 
                    fontsize=16, y=1.02)
        plt.tight_layout()
        plt.savefig(output_dir / f'layer_{layer_idx}_detailed_silhouette.png', 
                   dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_optimal_clustering_comparison(self, results, flattened_maps, labels, output_dir):
        """ìµœì  kì— ëŒ€í•œ í´ëŸ¬ìŠ¤í„° ë¶„í¬ ì‹œê°í™”"""
        layer_idx = results['layer_idx']
        best_k_sil = results['best_k_silhouette']
        best_k_ch = results['best_k_calinski_harabasz']
        best_k_db = results['best_k_davies_bouldin']
        
        # t-SNE ì°¨ì› ì¶•ì†Œ
        perplexity = min(30, len(flattened_maps)-1, max(1, len(flattened_maps)//3))
        tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity)
        tsne_embeddings = tsne.fit_transform(flattened_maps)
        
        # ê° ë©”íŠ¸ë¦­ì˜ ìµœì  kë¡œ í´ëŸ¬ìŠ¤í„°ë§
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # 1. Silhouette ìµœì  k
        self._plot_single_clustering_result(
            tsne_embeddings, flattened_maps, labels, best_k_sil, 
            f'Silhouette Optimal (k={best_k_sil})', axes[0, 0]
        )
        
        # 2. Calinski-Harabasz ìµœì  k
        self._plot_single_clustering_result(
            tsne_embeddings, flattened_maps, labels, best_k_ch,
            f'Calinski-Harabasz Optimal (k={best_k_ch})', axes[0, 1]
        )
        
        # 3. Davies-Bouldin ìµœì  k
        self._plot_single_clustering_result(
            tsne_embeddings, flattened_maps, labels, best_k_db,
            f'Davies-Bouldin Optimal (k={best_k_db})', axes[1, 0]
        )
        
        # 4. ì‹¤ì œ ë¼ë²¨
        ax = axes[1, 1]
        unique_labels = np.unique(labels)
        label_colors = plt.cm.Set1(np.linspace(0, 1, len(unique_labels)))
        
        for i, label in enumerate(unique_labels):
            mask = labels == label
            marker = 'o' if label == 0 else 's'
            ax.scatter(tsne_embeddings[mask, 0], tsne_embeddings[mask, 1], 
                       c=[label_colors[i]], label=f'True Label {int(label)}', 
                       alpha=0.7, s=50, marker=marker)
        
        ax.set_title('True Labels')
        ax.set_xlabel('t-SNE Dimension 1')
        ax.set_ylabel('t-SNE Dimension 2')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        plt.suptitle(f'Layer {layer_idx}: Optimal Clustering Comparison', 
                    fontsize=16, y=0.98)
        plt.tight_layout()
        plt.savefig(output_dir / f'layer_{layer_idx}_optimal_clustering_comparison.png', 
                   dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_single_clustering_result(self, tsne_embeddings, flattened_maps, labels, k, title, ax):
        """ë‹¨ì¼ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ í”Œë¡¯"""
        # í´ëŸ¬ìŠ¤í„°ë§
        np.random.seed(42)
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        cluster_labels = kmeans.fit_predict(flattened_maps)
        
        # ì‹œê°í™”
        colors = plt.cm.tab10(np.linspace(0, 1, k))
        for i in range(k):
            mask = cluster_labels == i
            ax.scatter(tsne_embeddings[mask, 0], tsne_embeddings[mask, 1], 
                       c=[colors[i]], label=f'Cluster {i}', alpha=0.7, s=50)
        
        ax.set_title(title)
        ax.set_xlabel('t-SNE Dimension 1')
        ax.set_ylabel('t-SNE Dimension 2')
        if k <= 10:  # ë„ˆë¬´ ë§ì€ í´ëŸ¬ìŠ¤í„°ëŠ” ë²”ë¡€ ìƒëµ
            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)
        ax.grid(True, alpha=0.3)

    def analyze_all_layers(self, data_loader, k_range=(2, 15), output_dir=None):
        """
        ëª¨ë“  ë ˆì´ì–´ì— ëŒ€í•´ ì¢…í•©ì ì¸ ë©”íŠ¸ë¦­ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        Args:
            data_loader: ë°ì´í„°ë¡œë”
            k_range (tuple): í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ ë²”ìœ„
            output_dir (str, optional): ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        
        Returns:
            dict: ëª¨ë“  ë ˆì´ì–´ì˜ ë¶„ì„ ê²°ê³¼
        """
        if output_dir:
            output_dir = Path(output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)
        
        # Attention maps ì¶”ì¶œ
        logger.info("Extracting attention maps...")
        attention_data = self.extract_attention_maps(data_loader)
        
        # ëª¨ë“  ë ˆì´ì–´ ë¶„ì„
        all_results = {}
        for layer_idx in range(len(self.model.layers)):
            logger.info(f"\n{'='*60}")
            logger.info(f"Analyzing Layer {layer_idx}")
            logger.info(f"{'='*60}")
            
            layer_output_dir = output_dir / f'layer_{layer_idx}' if output_dir else None
            results = self.perform_comprehensive_analysis(
                attention_data, 
                layer_idx, 
                k_range=k_range,
                output_dir=layer_output_dir
            )
            all_results[f'layer_{layer_idx}'] = results
        
        # ì „ì²´ ìš”ì•½ ìƒì„±
        if output_dir:
            self._generate_comprehensive_summary(all_results, output_dir)
        
        return all_results

    def _generate_comprehensive_summary(self, all_results, output_dir):
        """ì „ì²´ ë ˆì´ì–´ ì¢…í•© ìš”ì•½"""
        layers = sorted([int(k.split('_')[1]) for k in all_results.keys()])
        
        # ë©”íŠ¸ë¦­ë³„ ìµœì  k ìˆ˜ì§‘
        metrics_comparison = {
            'silhouette': {},
            'calinski_harabasz': {},
            'davies_bouldin': {},
            'layers': layers
        }
        
        for layer in layers:
            layer_key = f'layer_{layer}'
            result = all_results[layer_key]
            
            metrics_comparison['silhouette'][layer] = {
                'best_k': result['best_k_silhouette'],
                'best_score': result['best_silhouette_score']
            }
            metrics_comparison['calinski_harabasz'][layer] = {
                'best_k': result['best_k_calinski_harabasz'],
                'best_score': max([result['results_by_k'][k]['metrics']['calinski_harabasz']['score'] 
                                 for k in result['k_values']])
            }
            metrics_comparison['davies_bouldin'][layer] = {
                'best_k': result['best_k_davies_bouldin'],
                'best_score': min([result['results_by_k'][k]['metrics']['davies_bouldin']['score'] 
                                 for k in result['k_values']])
            }
        
        # ì¢…í•© ë¹„êµ ì‹œê°í™”
        self._create_cross_layer_comparison(metrics_comparison, all_results, output_dir)
        
        # ì¢…í•© ìš”ì•½ JSON ì €ì¥
        with open(output_dir / 'comprehensive_summary.json', 'w') as f:
            json.dump(metrics_comparison, f, indent=2)
        
        # ì¶”ì²œì‚¬í•­ ë¡œê·¸ ì¶œë ¥
        self._log_recommendations(metrics_comparison)

    def _create_cross_layer_comparison(self, metrics_comparison, all_results, output_dir):
        """ë ˆì´ì–´ê°„ ë©”íŠ¸ë¦­ ë¹„êµ ì‹œê°í™”"""
        layers = metrics_comparison['layers']
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        
        # 1. ë©”íŠ¸ë¦­ë³„ ìµœì  k ë¹„êµ
        ax = axes[0, 0]
        sil_ks = [metrics_comparison['silhouette'][layer]['best_k'] for layer in layers]
        ch_ks = [metrics_comparison['calinski_harabasz'][layer]['best_k'] for layer in layers]
        db_ks = [metrics_comparison['davies_bouldin'][layer]['best_k'] for layer in layers]
        
        x = np.arange(len(layers))
        width = 0.25
        
        ax.bar(x - width, sil_ks, width, label='Silhouette', alpha=0.8)
        ax.bar(x, ch_ks, width, label='Calinski-Harabasz', alpha=0.8)
        ax.bar(x + width, db_ks, width, label='Davies-Bouldin', alpha=0.8)
        
        ax.set_xlabel('Layer')
        ax.set_ylabel('Optimal k')
        ax.set_title('Optimal k by Different Metrics')
        ax.set_xticks(x)
        ax.set_xticklabels([f'Layer {layer}' for layer in layers])
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 2. Silhouette ìŠ¤ì½”ì–´ ë¹„êµ
        ax = axes[0, 1]
        sil_scores = [metrics_comparison['silhouette'][layer]['best_score'] for layer in layers]
        ax.plot(layers, sil_scores, 'bo-', linewidth=2, markersize=8)
        for layer, score in zip(layers, sil_scores):
            ax.annotate(f'{score:.3f}', (layer, score), textcoords="offset points", 
                       xytext=(0,10), ha='center', fontsize=9)
        ax.set_xlabel('Layer')
        ax.set_ylabel('Best Silhouette Score')
        ax.set_title('Best Silhouette Score by Layer')
        ax.grid(True, alpha=0.3)
        
        # 3. Within/Between Variance ë¹„êµ
        ax = axes[0, 2]
        for layer in layers:
            layer_key = f'layer_{layer}'
            best_k = all_results[layer_key]['best_k_silhouette']
            variance_data = all_results[layer_key]['results_by_k'][best_k]['metrics']['variance_analysis']
            
            wcss = variance_data['wcss']
            bcss = variance_data['bcss']
            ratio = variance_data['bcss_wcss_ratio']
            
            ax.bar(layer - 0.2, wcss, 0.4, label='WCSS' if layer == layers[0] else "", alpha=0.7, color='red')
            ax.bar(layer + 0.2, bcss, 0.4, label='BCSS' if layer == layers[0] else "", alpha=0.7, color='blue')
        
        ax.set_xlabel('Layer')
        ax.set_ylabel('Sum of Squares')
        ax.set_title('WCSS vs BCSS by Layer (at optimal k)')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 4. ë©”íŠ¸ë¦­ ìƒê´€ê´€ê³„
        ax = axes[1, 0]
        
        # ì‹¤ë£¨ì—£ vs Calinski-Harabasz ìµœì  k ë¹„êµ
        ax.scatter(sil_ks, ch_ks, s=100, alpha=0.7, c=layers, cmap='viridis')
        for i, layer in enumerate(layers):
            ax.annotate(f'L{layer}', (sil_ks[i], ch_ks[i]), xytext=(5, 5), 
                       textcoords='offset points', fontsize=10)
        
        ax.set_xlabel('Silhouette Optimal k')
        ax.set_ylabel('Calinski-Harabasz Optimal k')
        ax.set_title('Optimal k Correlation: Silhouette vs CH')
        ax.grid(True, alpha=0.3)
        
        # ëŒ€ê°ì„  ì°¸ì¡°ì„ 
        min_k = min(min(sil_ks), min(ch_ks))
        max_k = max(max(sil_ks), max(ch_ks))
        ax.plot([min_k, max_k], [min_k, max_k], 'r--', alpha=0.5, label='Perfect Agreement')
        ax.legend()
        
        # 5. BCSS/WCSS ë¹„ìœ¨ ë¹„êµ
        ax = axes[1, 1]
        ratios = []
        for layer in layers:
            layer_key = f'layer_{layer}'
            best_k = all_results[layer_key]['best_k_silhouette']
            ratio = all_results[layer_key]['results_by_k'][best_k]['metrics']['variance_analysis']['bcss_wcss_ratio']
            ratios.append(ratio)
        
        bars = ax.bar(layers, ratios, alpha=0.7, color='green')
        for i, (layer, ratio) in enumerate(zip(layers, ratios)):
            ax.text(bars[i].get_x() + bars[i].get_width()/2, bars[i].get_height() + 0.01,
                   f'{ratio:.2f}', ha='center', va='bottom', fontsize=10)
        
        ax.set_xlabel('Layer')
        ax.set_ylabel('BCSS/WCSS Ratio')
        ax.set_title('Cluster Separation Quality by Layer')
        ax.grid(True, alpha=0.3)
        
        # 6. ìš”ì•½ í…ìŠ¤íŠ¸
        ax = axes[1, 2]
        ax.axis('off')
        
        summary_text = "Comprehensive Analysis Summary\n\n"
        summary_text += f"Layers analyzed: {len(layers)}\n"
        summary_text += f"Metrics compared: 3 (Silhouette, CH, DB)\n\n"
        
        # ë©”íŠ¸ë¦­ ì¼ì¹˜ë„ ë¶„ì„
        agreement_count = sum(1 for i in range(len(layers)) 
                            if sil_ks[i] == ch_ks[i] == db_ks[i])
        summary_text += f"Complete metric agreement: {agreement_count}/{len(layers)} layers\n\n"
        
        # ìµœê³  ì„±ëŠ¥ ë ˆì´ì–´
        best_sil_layer = layers[np.argmax(sil_scores)]
        best_ratio_layer = layers[np.argmax(ratios)]
        
        summary_text += f"Best Silhouette: Layer {best_sil_layer} ({max(sil_scores):.3f})\n"
        summary_text += f"Best BCSS/WCSS: Layer {best_ratio_layer} ({max(ratios):.3f})\n\n"
        
        # ì¶”ì²œì‚¬í•­
        summary_text += "Recommendations:\n"
        if agreement_count > len(layers) / 2:
            summary_text += "â€¢ High metric agreement - reliable clustering\n"
        else:
            summary_text += "â€¢ Mixed metric results - consider ensemble\n"
        
        most_common_k = max(set(sil_ks), key=sil_ks.count)
        summary_text += f"â€¢ Most common optimal k: {most_common_k}\n"
        summary_text += f"â€¢ Focus on Layer {best_sil_layer} for best clustering"
        
        ax.text(0.1, 0.9, summary_text, transform=ax.transAxes, fontsize=11,
                verticalalignment='top', fontfamily='monospace',
                bbox=dict(boxstyle="round,pad=0.5", facecolor="lightcyan", alpha=0.8))
        
        plt.suptitle('Cross-Layer Comprehensive Clustering Analysis', 
                    fontsize=16, y=0.98)
        plt.tight_layout()
        plt.savefig(output_dir / 'comprehensive_cross_layer_analysis.png', 
                   dpi=300, bbox_inches='tight')
        plt.close()

    def _log_recommendations(self, metrics_comparison):
        """ì¶”ì²œì‚¬í•­ ë¡œê·¸ ì¶œë ¥"""
        layers = metrics_comparison['layers']
        
        logger.info("\n" + "="*80)
        logger.info("ğŸ¯ COMPREHENSIVE ANALYSIS RECOMMENDATIONS")
        logger.info("="*80)
        
        # ì‹¤ë£¨ì—£ ê¸°ì¤€ ìµœê³  ì„±ëŠ¥ ë ˆì´ì–´
        sil_scores = [metrics_comparison['silhouette'][layer]['best_score'] for layer in layers]
        best_sil_layer = layers[np.argmax(sil_scores)]
        best_sil_score = max(sil_scores)
        
        logger.info(f"ğŸ“Š Best performing layer (Silhouette): Layer {best_sil_layer} (score: {best_sil_score:.4f})")
        
        # ë©”íŠ¸ë¦­ë³„ ìµœì  k ì¼ì¹˜ë„ ë¶„ì„
        sil_ks = [metrics_comparison['silhouette'][layer]['best_k'] for layer in layers]
        ch_ks = [metrics_comparison['calinski_harabasz'][layer]['best_k'] for layer in layers]
        db_ks = [metrics_comparison['davies_bouldin'][layer]['best_k'] for layer in layers]
        
        agreement_count = sum(1 for i in range(len(layers)) if sil_ks[i] == ch_ks[i] == db_ks[i])
        logger.info(f"ğŸ” Metric agreement: {agreement_count}/{len(layers)} layers show consistent optimal k")
        
        # ê°€ì¥ ì¼ë°˜ì ì¸ ìµœì  k
        all_ks = sil_ks + ch_ks + db_ks
        most_common_k = max(set(all_ks), key=all_ks.count)
        logger.info(f"ğŸ”¢ Most frequent optimal k across all metrics: {most_common_k}")
        
        # ë©”íŠ¸ë¦­ë³„ ìµœì  k ìš”ì•½
        logger.info(f"\nğŸ“ˆ Optimal k by metric:")
        for layer in layers:
            sil_k = metrics_comparison['silhouette'][layer]['best_k']
            ch_k = metrics_comparison['calinski_harabasz'][layer]['best_k']
            db_k = metrics_comparison['davies_bouldin'][layer]['best_k']
            logger.info(f"   Layer {layer}: Silhouette={sil_k}, CH={ch_k}, DB={db_k}")
        
        # ì‹¤ë£¨ì—£ ê²€ì¦
        logger.info(f"\nâœ… SILHOUETTE VERIFICATION:")
        for layer in layers:
            sil_score = metrics_comparison['silhouette'][layer]['best_score']
            sil_k = metrics_comparison['silhouette'][layer]['best_k']
            logger.info(f"   Layer {layer}: k={sil_k}, score={sil_score:.4f}")
        
        logger.info("="*80)


def main():
    parser = argparse.ArgumentParser(description='Comprehensive Clustering Metrics Analysis')
    parser.add_argument('--checkpoint_dir', type=str, required=True,
                       help='Path to model checkpoint')
    parser.add_argument('--mode', type=str, choices=['Full', 'Few'], default='Full',
                       help='Which model to use (Full or Few)')
    parser.add_argument('--min_k', type=int, default=2,
                       help='Minimum number of clusters to test (default: 2)')
    parser.add_argument('--max_k', type=int, default=15,
                       help='Maximum number of clusters to test (default: 15)')
    parser.add_argument('--output_dir', type=str, default=None,
                       help='Output directory for results')
    parser.add_argument('--layer_idx', type=int, default=None,
                       help='Specific layer to analyze (if not specified, analyze all layers)')
    
    args = parser.parse_args()
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    if args.output_dir is None:
        checkpoint_dir = Path(args.checkpoint_dir)
        path_parts = checkpoint_dir.parts
        
        # visualization í´ë” êµ¬ì¡°ì— ë§ê²Œ ì„¤ì •
        for i, part in enumerate(path_parts):
            if part == 'checkpoints':
                viz_parts = list(path_parts)
                viz_parts[i] = 'visualization'
                viz_path = Path(*viz_parts[:-1])  # best_model_epoch_XX.pt ì œì™¸
                args.output_dir = viz_path / 'comprehensive_metrics_analysis'
                break
        
        if args.output_dir is None:
            args.output_dir = checkpoint_dir / 'comprehensive_metrics_analysis'
    
    # Comprehensive Analyzer ì´ˆê¸°í™”
    analyzer = ComprehensiveClusteringAnalyzer(args.checkpoint_dir)
    
    # ë°ì´í„°ë¡œë” ì„ íƒ
    if args.mode == 'Full':
        data_loader = analyzer.train_loader
        logger.info("Using Full dataset loader")
    else:
        data_loader = analyzer.train_loader_few if hasattr(analyzer, 'train_loader_few') else analyzer.test_loader
        logger.info("Using Few-shot dataset loader")
    
    k_range = (args.min_k, args.max_k)
    
    if args.layer_idx is not None:
        # íŠ¹ì • ë ˆì´ì–´ë§Œ ë¶„ì„
        logger.info(f"Analyzing only Layer {args.layer_idx}")
        
        # Attention maps ì¶”ì¶œ
        attention_data = analyzer.extract_attention_maps(data_loader)
        
        # íŠ¹ì • ë ˆì´ì–´ ë¶„ì„
        layer_output_dir = Path(args.output_dir) / f'layer_{args.layer_idx}'
        results = analyzer.perform_comprehensive_analysis(
            attention_data, 
            args.layer_idx, 
            k_range=k_range,
            output_dir=layer_output_dir
        )
        
        logger.info(f"\nğŸ¯ Results for Layer {args.layer_idx}:")
        logger.info(f"   Silhouette optimal k: {results['best_k_silhouette']} (score: {results['best_silhouette_score']:.4f})")
        logger.info(f"   Calinski-Harabasz optimal k: {results['best_k_calinski_harabasz']}")
        logger.info(f"   Davies-Bouldin optimal k: {results['best_k_davies_bouldin']}")
        
    else:
        # ëª¨ë“  ë ˆì´ì–´ ë¶„ì„
        logger.info("Analyzing all layers with comprehensive metrics")
        all_results = analyzer.analyze_all_layers(
            data_loader, 
            k_range=k_range,
            output_dir=args.output_dir
        )
    
    logger.info(f"\nâœ… Comprehensive metrics analysis completed! Results saved to {args.output_dir}")


if __name__ == "__main__":
    main()
"""
Checkpointë³„ Attention Maps ì €ì¥ ìŠ¤í¬ë¦½íŠ¸

ê° checkpointì—ì„œ attention mapsì„ ì¶”ì¶œí•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.
ì €ì¥ ê²½ë¡œ: /storage/personal/eungyeop/experiments/attention_map/{llm_model}/{source_data}/{mode}/{config}/

Usage:
    python save_attention_maps.py --checkpoint_dir /path/to/checkpoint/dir  # ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  .pt íŒŒì¼
    python save_attention_maps.py --checkpoint_dir /path/to/checkpoint/dir --pattern "*Edge-True*"  # íŠ¹ì • íŒ¨í„´ íŒŒì¼ë§Œ
"""

import os
import sys
import argparse
import torch
import numpy as np
import logging
from pathlib import Path
import re
from torch.utils.data import ConcatDataset, DataLoader
import fnmatch

# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ìœ„ì¹˜ (analysis/attentionmap.py)
current_dir = Path(__file__).resolve().parent

# analysis/ì˜ ë¶€ëª¨ ë””ë ‰í† ë¦¬ (ì¦‰, ProtoLLM/)
root_dir = current_dir.parent
sys.path.append(str(root_dir))  # models, dataset, utils ë“±ì´ ìœ„ì¹˜í•œ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì¶”ê°€

from models.TabularFLM import Model
from dataset.data_dataloaders import prepare_embedding_dataloaders, get_few_shot_embedding_samples
from utils.util import setup_logger, fix_seed

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def ensure_deterministic():
    """ì™„ì „í•œ deterministic ì„¤ì •"""
    import random
    random.seed(42)
    np.random.seed(42)
    torch.manual_seed(42)
    torch.cuda.manual_seed(42)
    torch.cuda.manual_seed_all(42)
    
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    torch.use_deterministic_algorithms(True)
    
    os.environ['PYTHONHASHSEED'] = '42'
    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'
    
    logger.info("âœ… Deterministic mode enabled")

def extract_config_from_checkpoint(checkpoint_path):
    """ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ëª…ì—ì„œ ì„¤ì • ì •ë³´ë¥¼ ì¶”ì¶œ"""
    filename = Path(checkpoint_path).stem
    
    # ë‚ ì§œ/ì‹œê°„ íŒ¨í„´ ì œê±° (20250617_173832 í˜•íƒœ)
    filename_clean = re.sub(r'_\d{8}_\d{6}$', '', filename)
    
    # "Embed:carte_desc_Edge:mlp_A:att" í˜•íƒœë¥¼ íŒŒì‹±
    pattern = r'Embed:([^:_]+(?:_[^:_]+)*?)_Edge:([^:_]+)_A:([^:_]+)'
    match = re.match(pattern, filename_clean)
    
    if match:
        embed_type = match.group(1)  # carte, carte_desc, ours, ours2
        edge_attr = match.group(2)   # mlp, True, False
        attn_type = match.group(3)   # att, gat
        
        return {
            'embed_type': embed_type,
            'edge_attr': edge_attr,
            'attn_type': attn_type,
            'config_str': f"Embed-{embed_type}_Edge-{edge_attr}_A-{attn_type}"
        }
    else:
        # íŒ¨í„´ ë§¤ì¹­ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’
        logger.warning(f"Could not parse config from filename: {filename}")
        logger.warning(f"Cleaned filename: {filename_clean}")
        return {
            'embed_type': 'unknown',
            'edge_attr': 'unknown',
            'attn_type': 'unknown',
            'config_str': filename_clean.replace(':', '-')
        }

class AttentionMapExtractor:
    def __init__(self, checkpoint_path, device='cuda'):
        """
        Args:
            checkpoint_path (str): ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ
            device (str): 'cuda' ë˜ëŠ” 'cpu'
        """
        ensure_deterministic()
        
        self.checkpoint_path = checkpoint_path
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        
        # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
        self.checkpoint = torch.load(checkpoint_path, map_location=self.device)
        self.args = self.checkpoint['args']
        
        # ì„¤ì • ì •ë³´ ì¶”ì¶œ
        self.config = extract_config_from_checkpoint(checkpoint_path)
        
        logger.info(f"Loaded checkpoint from {checkpoint_path}")
        logger.info(f"Config: {self.config['config_str']}")
        logger.info(f"Checkpoint epoch: {self.checkpoint['epoch']}, Val AUC: {self.checkpoint.get('val_auc', 'N/A')}")
        
        # ëª¨ë¸ ì´ˆê¸°í™” ë° ë¡œë“œ
        self._load_model()
        
        # ë°ì´í„°ë¡œë” ì¤€ë¹„
        self._prepare_dataloaders()
        
    def _load_model(self):
        """ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ ë¡œë“œ"""
        experiment_id = "attention_extraction"
        mode = "extraction"
        
        self.model = Model(
            self.args, 
            self.args.input_dim, 
            self.args.hidden_dim, 
            self.args.output_dim, 
            self.args.num_layers, 
            self.args.dropout_rate, 
            self.args.llm_model,
            experiment_id,
            mode
        ).to(self.device)
        
        # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
        self.model.load_state_dict(self.checkpoint['model_state_dict'])
        self.model.eval()
        
        logger.info("Model loaded and set to evaluation mode")
    
    def _prepare_dataloaders(self):
        """ë°ì´í„°ë¡œë” ì¤€ë¹„ (deterministic)"""
        fix_seed(self.args.random_seed)
        
        # ì „ì²´ ë°ì´í„°ì…‹ ë¡œë” ì¤€ë¹„
        results = prepare_embedding_dataloaders(self.args, self.args.source_data)
        self.train_loader, self.val_loader, self.test_loader = results['loaders']
        self.num_classes = results['num_classes']
        
        # ì „ì²´ ë°ì´í„°ì…‹ ê²°í•© (ë™ì¼í•œ ìˆœì„œ ë³´ì¥)
        combined_dataset = ConcatDataset([
            self.train_loader.dataset,
            self.val_loader.dataset, 
            self.test_loader.dataset
        ])
        
        self.combined_loader = DataLoader(
            combined_dataset,
            batch_size=self.train_loader.batch_size,
            shuffle=False,  # ìˆœì„œ ê³ ì •
            num_workers=0   # ì¬í˜„ì„± ìœ„í•´ ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤
        )
        
        logger.info(f"Dataloaders prepared for dataset: {self.args.source_data}")
        logger.info(f"Total samples: {len(combined_dataset)}")
    
    def extract_and_save_attention_maps(self, output_base_dir="/storage/personal/eungyeop/experiments/attention_map"):
        """
        Attention mapsì„ ì¶”ì¶œí•˜ì—¬ ìƒ˜í”Œë³„ ê°œë³„ íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            output_base_dir (str): ê¸°ë³¸ ì €ì¥ ë””ë ‰í† ë¦¬
        """
        # ì €ì¥ ê²½ë¡œ ìƒì„±
        output_dir = Path(output_base_dir) / self.args.llm_model / self.args.source_data / "Full" / self.config['config_str']
        output_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"Extracting attention maps to: {output_dir}")
        
        # ë©”íƒ€ë°ì´í„° ì¤€ë¹„
        metadata = {
            'checkpoint_path': str(self.checkpoint_path),
            'config': self.config,
            'num_layers': len(self.model.layers),
            'total_samples': 0,
            'args_dict': vars(self.args),
            'feature_names': None
        }
        
        sample_count = 0
        saved_files = []
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(self.combined_loader):
                # ë°°ì¹˜ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
                batch_on_device = {
                    k: v.to(self.device) if isinstance(v, torch.Tensor) else v
                    for k, v in batch.items()
                }
                
                # ëª¨ë¸ forward (attention weights ì¶”ì¶œ)
                pred, attention_weights = self._extract_attention_from_model(batch_on_device)
                
                # Feature names ì¶”ì¶œ (ì²« ë²ˆì§¸ ë°°ì¹˜ì—ì„œë§Œ)
                if metadata['feature_names'] is None:
                    feature_names = self.model.extract_feature_names(batch_on_device)
                    metadata['feature_names'] = ["CLS"] + feature_names
                
                # ë°°ì¹˜ í¬ê¸° í™•ì¸
                batch_size = attention_weights[0].shape[0]
                
                for sample_idx in range(batch_size):
                    # ë¼ë²¨ ê°€ì ¸ì˜¤ê¸°
                    if 'y' in batch:
                        label = batch['y'][sample_idx].item()
                    else:
                        label = -1  # ë¼ë²¨ì´ ì—†ëŠ” ê²½ìš°
                    
                    # ê° ë ˆì´ì–´ì˜ attention maps ìˆ˜ì§‘
                    sample_attention_maps = {}
                    for layer_idx, layer_attention in enumerate(attention_weights):
                        # Multi-head attentionì„ í‰ê· ë‚´ì–´ ë‹¨ì¼ attention mapìœ¼ë¡œ ë³€í™˜
                        attention_map = layer_attention[sample_idx].mean(dim=0)  # [seq_len, seq_len]
                        attention_numpy = attention_map.detach().cpu().numpy()
                        sample_attention_maps[f'layer_{layer_idx}'] = attention_numpy
                    
                    # ìƒ˜í”Œë³„ íŒŒì¼ë¡œ ì €ì¥
                    sample_filename = f"sample_{sample_count}_label_{label}.npz"
                    sample_filepath = output_dir / sample_filename
                    
                    # ìƒ˜í”Œ ë©”íƒ€ë°ì´í„° í¬í•¨
                    sample_data = {
                        'sample_id': sample_count,
                        'label': label,
                        'batch_idx': batch_idx,
                        'batch_sample_idx': sample_idx,
                        **sample_attention_maps
                    }
                    
                    np.savez_compressed(sample_filepath, **sample_data)
                    saved_files.append(sample_filename)
                    sample_count += 1
                
                if batch_idx % 10 == 0:
                    logger.info(f"Processed {sample_count} samples...")
        
        # ì „ì²´ ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ ë° ì €ì¥
        metadata['total_samples'] = sample_count
        metadata['saved_files'] = saved_files
        
        import json
        metadata_path = output_dir / "metadata.json"
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2, default=str)
        
        logger.info(f"âœ… Attention maps saved successfully!")
        logger.info(f"   Total samples: {sample_count}")
        logger.info(f"   Layers per sample: {len(self.model.layers)}")
        logger.info(f"   Attention map shape: {sample_attention_maps['layer_0'].shape}")
        logger.info(f"   Sample files: {sample_count} .npz files")
        logger.info(f"   Metadata file: {metadata_path}")
        logger.info(f"   Directory: {output_dir}")
        
        return output_dir, metadata_path
    
    def _extract_attention_from_model(self, batch):
        """
        ëª¨ë¸ì—ì„œ attention weightsì™€ ì˜ˆì¸¡ê°’ì„ ì¶”ì¶œ
        """
        # ëª¨ë¸ì˜ predict ë¡œì§ì„ ë³µì‚¬í•˜ë˜ attention_weightsë„ ë°˜í™˜
        label_description_embeddings = batch['label_description_embeddings'].to(self.device)
        desc_embeddings = [] 
        name_value_embeddings = [] 
        
        if all(k in batch for k in ['cat_name_value_embeddings', 'cat_desc_embeddings']):
            cat_name_value_embeddings = batch['cat_name_value_embeddings'].to(self.device).squeeze(-2)
            cat_desc_embeddings = batch['cat_desc_embeddings'].to(self.device).squeeze(-2)
            
            name_value_embeddings.append(cat_name_value_embeddings)
            desc_embeddings.append(cat_desc_embeddings)
            
        if all(k in batch for k in ['num_prompt_embeddings', 'num_desc_embeddings']):
            num_prompt_embeddings = batch['num_prompt_embeddings'].to(self.device).squeeze(-2)
            num_desc_embeddings = batch['num_desc_embeddings'].to(self.device).squeeze(-2)
            name_value_embeddings.append(num_prompt_embeddings)
            desc_embeddings.append(num_desc_embeddings)
            
        if not desc_embeddings or not name_value_embeddings:
            raise ValueError("No categorical or numerical features found in batch")

        desc_embeddings = torch.cat(desc_embeddings, dim = 1)
        name_value_embeddings = torch.cat(name_value_embeddings, dim = 1)
        
        # [CLS] Token ì¶”ê°€
        attention_weights = [] 
        cls_token = self.model.cls.expand(name_value_embeddings.size(0), -1, -1)
        name_value_embeddings = torch.cat([cls_token, name_value_embeddings], dim=1)
        x = name_value_embeddings
        
        # Graph Attention Layers
        for i, layer in enumerate(self.model.layers):
            norm_x = self.model.layer_norms[i](x)
            attn_output, attn_weights = layer(desc_embeddings, norm_x)
            attention_weights.append(attn_weights)
            x = x + attn_output
        
        # ì˜ˆì¸¡ê°’ ê³„ì‚°
        pred = x[:, 0, :]
        pred = self.model.predictor(pred)

        return pred, attention_weights

def find_checkpoint_files(checkpoint_path, pattern="*.pt"):
    """ë””ë ‰í† ë¦¬ ë˜ëŠ” íŒŒì¼ì—ì„œ íŒ¨í„´ì— ë§ëŠ” .pt íŒŒì¼ ì°¾ê¸°"""
    checkpoint_path = Path(checkpoint_path)
    
    # íŒŒì¼ì¸ ê²½ìš° í•´ë‹¹ íŒŒì¼ë§Œ ë°˜í™˜
    if checkpoint_path.is_file() and checkpoint_path.suffix == '.pt':
        if re.search(r'\d{8}_\d{6}', checkpoint_path.stem):  # ë‚ ì§œ íŒ¨í„´ í™•ì¸
            return [checkpoint_path]
        else:
            return []
    
    # ë””ë ‰í† ë¦¬ì¸ ê²½ìš° íŒ¨í„´ì— ë§ëŠ” íŒŒì¼ë“¤ ì°¾ê¸°
    if checkpoint_path.is_dir():
        # ëª¨ë“  .pt íŒŒì¼ ì°¾ê¸°
        pt_files = list(checkpoint_path.rglob("*.pt"))
        
        # íŒŒì¼ëª…ì— ë‚ ì§œê°€ í¬í•¨ëœ ê²ƒë“¤ë§Œ í•„í„°ë§ (ì„ì‹œ íŒŒì¼ ì œì™¸)
        filtered_files = []
        for pt_file in pt_files:
            if re.search(r'\d{8}_\d{6}', pt_file.stem):  # ë‚ ì§œ íŒ¨í„´ì´ ìˆëŠ” íŒŒì¼
                # íŒ¨í„´ ë§¤ì¹­ í™•ì¸
                if fnmatch.fnmatch(pt_file.name, pattern):
                    filtered_files.append(pt_file)
        
        return filtered_files
    
    return []

def main():
    parser = argparse.ArgumentParser(description='Extract and save attention maps from checkpoints')
    parser.add_argument('--checkpoint_dir', type=str, required=True,
                       help='Directory containing checkpoint files OR path to specific checkpoint file')
    parser.add_argument('--pattern', type=str, default="*.pt",
                       help='Pattern to match checkpoint files (e.g., "*Edge-True*", "*gat*")')
    parser.add_argument('--output_dir', type=str, 
                       default="/storage/personal/eungyeop/experiments/attention_map",
                       help='Base output directory for attention maps')
    parser.add_argument('--device', type=str, default='cuda',
                       help='Device to use (cuda or cpu)')
    
    args = parser.parse_args()
    
    # ì²˜ë¦¬í•  checkpoint íŒŒì¼ë“¤ ìˆ˜ì§‘
    checkpoint_files = find_checkpoint_files(args.checkpoint_dir, args.pattern)
    
    if not checkpoint_files:
        checkpoint_path = Path(args.checkpoint_dir)
        if checkpoint_path.is_file():
            logger.error(f"Checkpoint file {args.checkpoint_dir} does not match the expected pattern (must contain date like 20250617_163404)!")
        else:
            logger.error(f"No checkpoint files found in {args.checkpoint_dir} matching pattern '{args.pattern}'!")
        return
    
    logger.info(f"Found {len(checkpoint_files)} checkpoint files matching pattern '{args.pattern}':")
    for i, file in enumerate(checkpoint_files):
        logger.info(f"  {i+1}. {file.name}")
    
    # ê° checkpointì— ëŒ€í•´ attention maps ì¶”ì¶œ
    success_count = 0
    for i, checkpoint_path in enumerate(checkpoint_files):
        logger.info(f"\n{'='*80}")
        logger.info(f"Processing checkpoint {i+1}/{len(checkpoint_files)}: {checkpoint_path}")
        logger.info(f"{'='*80}")
        
        try:
            # Attention map ì¶”ì¶œê¸° ì´ˆê¸°í™”
            extractor = AttentionMapExtractor(str(checkpoint_path), device=args.device)
            
            # Attention maps ì¶”ì¶œ ë° ì €ì¥
            save_path, metadata_path = extractor.extract_and_save_attention_maps(args.output_dir)
            
            success_count += 1
            logger.info(f"âœ… Successfully processed {checkpoint_path}")
            
        except Exception as e:
            logger.error(f"âŒ Failed to process {checkpoint_path}: {str(e)}")
            import traceback
            traceback.print_exc()
            continue
    
    logger.info(f"\nğŸ¯ SUMMARY:")
    logger.info(f"   Total files: {len(checkpoint_files)}")
    logger.info(f"   Successfully processed: {success_count}")
    logger.info(f"   Failed: {len(checkpoint_files) - success_count}")
    logger.info(f"   Pattern used: {args.pattern}")
    logger.info(f"   Output directory: {args.output_dir}")

if __name__ == "__main__":
    main()